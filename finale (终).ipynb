{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finale.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN8JwY0CF-Eu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2a5e39c1-cf9e-4686-e49c-6f95985bc391"
      },
      "source": [
        "!git clone https://github.com/keras-team/keras-tuner"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-tuner'...\n",
            "remote: Enumerating objects: 7099, done.\u001b[K\n",
            "remote: Counting objects: 100% (457/457), done.\u001b[K\n",
            "remote: Compressing objects: 100% (205/205), done.\u001b[K\n",
            "remote: Total 7099 (delta 252), reused 397 (delta 231), pack-reused 6642\u001b[K\n",
            "Receiving objects: 100% (7099/7099), 1.53 MiB | 10.41 MiB/s, done.\n",
            "Resolving deltas: 100% (4957/4957), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGukiOkBGCu6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9f8277e3-1231-4d82-d8e8-c872c06bab8c"
      },
      "source": [
        "cd keras-tuner"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-tuner\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TTqi4-oGEkg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a0ab6c2c-85a4-40ab-ae83-78a6f16887a1"
      },
      "source": [
        "!pip install ."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/keras-tuner\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (1.4.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (2.5.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (5.5.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt-legacy-1.0.3.tar.gz (5.8 kB)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (57.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (5.0.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner==1.0.3) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner==1.0.3) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->keras-tuner==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner==1.0.3) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner==1.0.3) (0.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.3) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.3) (1.24.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (1.32.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (1.34.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (0.4.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (0.36.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (1.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (0.12.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner==1.0.3) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner==1.0.3) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner==1.0.3) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner==1.0.3) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner==1.0.3) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->keras-tuner==1.0.3) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner==1.0.3) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner==1.0.3) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner==1.0.3) (3.5.0)\n",
            "Building wheels for collected packages: keras-tuner, kt-legacy\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.3-py3-none-any.whl size=97186 sha256=9c51a204c30d61bdf4dc5a3e68c67ae44914783de4a5afb997f0d654db6e40e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/f4/56/f120140a3c0706aebedf4471bfee8f02bbce4755424e32e245\n",
            "  Building wheel for kt-legacy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kt-legacy: filename=kt_legacy-1.0.3-py3-none-any.whl size=9568 sha256=431b7ff9335593d97ff558ff950ba70607720391e7f998ed435ca4b184e44fec\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/5c/e0/13003e68c17f403af40b92a24d20171b95fef13b0fdaba833c\n",
            "Successfully built keras-tuner kt-legacy\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.0.3 kt-legacy-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lVg2UNcOGJWQ",
        "outputId": "f79ff83a-fd2d-4fb5-f93b-9d98922fc9f3"
      },
      "source": [
        "# Train a DNN model for prediction\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import kerastuner as kt\n",
        "\n",
        "# upload the data base at the certain path\n",
        "data = pd.read_csv('/content/traincmp.csv')\n",
        "\n",
        "\n",
        "x = data.loc[0:119, ['A','B','C','D','E']]\n",
        "x =np.array(x)\n",
        "x_mean = np.mean(x,axis=0)\n",
        "x_std = np.std(x,axis=0)\n",
        "x = (x-x_mean)/x_std\n",
        "x_test = x[110:119,:]\n",
        "x = x [0:110,:]\n",
        "\n",
        "\n",
        "y = data.loc[0:119, ['target']]\n",
        "y=np.array(y)\n",
        "y_target= y[110:119,:]\n",
        "y_mean = np.mean(y,axis=0)\n",
        "y_std = np.std(y,axis=0)\n",
        "y = (y-y_mean)/y_std\n",
        "y = y [0:110,:]\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(3)\n",
        "np.random.shuffle(x)\n",
        "np.random.seed(3)\n",
        "np.random.shuffle(y)\n",
        "\n",
        "x_train = x[0:100,:]\n",
        "x_val = x[100:110,:]\n",
        "y_train = y[0:100,:]\n",
        "y_val = y[100:110,:]\n",
        "\n",
        "\n",
        "#Define model\n",
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "#Set the input layer\n",
        "  model.add(keras.layers.Flatten(input_shape=(5,1)))\n",
        "#Set dropout rate search space\n",
        "  drop_rate = hp.Choice('drop_rate', \n",
        "                            [0.0, 0.1, 0.2, 0.3, 0.4,])\n",
        "#Set activation function search space\n",
        "  activation = hp.Choice('activation', \n",
        "                            ['relu', 'tanh', 'sigmoid'])\n",
        "#In here, we tuner the number of layers using for loop\n",
        "  for i in range(hp.Int('num_layers', 2 , 5)):\n",
        "    model.add(keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
        "                      min_value=5,\n",
        "                      max_value=50,\n",
        "                      step=1),\n",
        "                activation= activation))\n",
        "  model.add(keras.layers.Dropout(rate=drop_rate))\n",
        "  model.add(keras.layers.Dense(1, activation='linear'))\n",
        "#  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
        "  model.compile(\n",
        "          optimizer= optimizer,\n",
        "          loss='mean_absolute_error',\n",
        "          metrics=['mean_absolute_error'])\n",
        "\n",
        "#          optimizer=tf.keras.optimizers.optimizer(lr=hp_learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
        "\n",
        "  return model\n",
        "tuner = kt.RandomSearch(model_builder,\n",
        "                     objective='val_mean_absolute_error',\n",
        "                     max_trials=5,\n",
        "                     executions_per_trial=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='25524511215752482452452654245298')\n",
        "# represent the search space\n",
        "tuner.search_space_summary()\n",
        "\n",
        "# search the best hyperparameters\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "tuner.search(x_train,y_train,epochs=50,validation_split=0.2,callbacks=[stop_early])\n",
        "\n",
        "# recall the overall hyperparameters\n",
        "tuner.results_summary()\n",
        "\n",
        "# train model with the best hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "\n",
        "history=model.fit(x_train, y_train, batch_size=16, epochs=300, validation_data=(x_val,y_val), validation_freq=1, shuffle=False)\n",
        "\n",
        "\n",
        "# plot the figure illustrating the training loss and validation loss\n",
        "epochs = len(history.history['loss'])\n",
        "plt.plot(range(epochs), history.history['loss'], label='loss')\n",
        "plt.plot(range(epochs), history.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "x = np.array([10,10,65,50,5])\n",
        "x=x.reshape(1,5)\n",
        "y=model(x)\n",
        "print(y)\n",
        "#manifest the model structure\n",
        "model.summary()\n",
        "\n",
        "#extract the best hyperparameters \n",
        "tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 00m 06s]\n",
            "val_mean_absolute_error: 0.5214781761169434\n",
            "\n",
            "Best val_mean_absolute_error So Far: 0.317326158285141\n",
            "Total elapsed time: 00h 00m 40s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Results summary\n",
            "Results in my_dir/25524511215752482452452654245298\n",
            "Showing 10 best trials\n",
            "Objective(name='val_mean_absolute_error', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "drop_rate: 0.4\n",
            "activation: relu\n",
            "num_layers: 4\n",
            "units_0: 38\n",
            "units_1: 41\n",
            "optimizer: rmsprop\n",
            "units_2: 19\n",
            "units_3: 35\n",
            "Score: 0.317326158285141\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "drop_rate: 0.2\n",
            "activation: relu\n",
            "num_layers: 4\n",
            "units_0: 31\n",
            "units_1: 14\n",
            "optimizer: adam\n",
            "units_2: 5\n",
            "units_3: 5\n",
            "Score: 0.3904804786046346\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "drop_rate: 0.2\n",
            "activation: tanh\n",
            "num_layers: 5\n",
            "units_0: 14\n",
            "units_1: 13\n",
            "optimizer: adam\n",
            "units_2: 47\n",
            "units_3: 27\n",
            "units_4: 5\n",
            "Score: 0.4735856056213379\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "drop_rate: 0.4\n",
            "activation: tanh\n",
            "num_layers: 4\n",
            "units_0: 38\n",
            "units_1: 45\n",
            "optimizer: rmsprop\n",
            "units_2: 42\n",
            "units_3: 43\n",
            "units_4: 43\n",
            "Score: 0.49110398689905804\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "drop_rate: 0.1\n",
            "activation: tanh\n",
            "num_layers: 4\n",
            "units_0: 7\n",
            "units_1: 46\n",
            "optimizer: sgd\n",
            "units_2: 48\n",
            "units_3: 43\n",
            "units_4: 37\n",
            "Score: 0.5214781761169434\n",
            "Epoch 1/300\n",
            "7/7 [==============================] - 1s 31ms/step - loss: 0.8360 - mean_absolute_error: 0.8360 - val_loss: 0.9331 - val_mean_absolute_error: 0.9331\n",
            "Epoch 2/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.7579 - mean_absolute_error: 0.7579 - val_loss: 0.8920 - val_mean_absolute_error: 0.8920\n",
            "Epoch 3/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.7189 - mean_absolute_error: 0.7189 - val_loss: 0.8531 - val_mean_absolute_error: 0.8531\n",
            "Epoch 4/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6599 - mean_absolute_error: 0.6599 - val_loss: 0.8069 - val_mean_absolute_error: 0.8069\n",
            "Epoch 5/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.5825 - mean_absolute_error: 0.5825 - val_loss: 0.7551 - val_mean_absolute_error: 0.7551\n",
            "Epoch 6/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5083 - mean_absolute_error: 0.5083 - val_loss: 0.7122 - val_mean_absolute_error: 0.7122\n",
            "Epoch 7/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4622 - mean_absolute_error: 0.4622 - val_loss: 0.6639 - val_mean_absolute_error: 0.6639\n",
            "Epoch 8/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5031 - mean_absolute_error: 0.5031 - val_loss: 0.6306 - val_mean_absolute_error: 0.6306\n",
            "Epoch 9/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4830 - mean_absolute_error: 0.4830 - val_loss: 0.6157 - val_mean_absolute_error: 0.6157\n",
            "Epoch 10/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4724 - mean_absolute_error: 0.4724 - val_loss: 0.5923 - val_mean_absolute_error: 0.5923\n",
            "Epoch 11/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4554 - mean_absolute_error: 0.4554 - val_loss: 0.5583 - val_mean_absolute_error: 0.5583\n",
            "Epoch 12/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4471 - mean_absolute_error: 0.4471 - val_loss: 0.5476 - val_mean_absolute_error: 0.5476\n",
            "Epoch 13/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4121 - mean_absolute_error: 0.4121 - val_loss: 0.5051 - val_mean_absolute_error: 0.5051\n",
            "Epoch 14/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3655 - mean_absolute_error: 0.3655 - val_loss: 0.4786 - val_mean_absolute_error: 0.4786\n",
            "Epoch 15/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3968 - mean_absolute_error: 0.3968 - val_loss: 0.4774 - val_mean_absolute_error: 0.4774\n",
            "Epoch 16/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3896 - mean_absolute_error: 0.3896 - val_loss: 0.4534 - val_mean_absolute_error: 0.4534\n",
            "Epoch 17/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3684 - mean_absolute_error: 0.3684 - val_loss: 0.4263 - val_mean_absolute_error: 0.4263\n",
            "Epoch 18/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3568 - mean_absolute_error: 0.3568 - val_loss: 0.4120 - val_mean_absolute_error: 0.4120\n",
            "Epoch 19/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3224 - mean_absolute_error: 0.3224 - val_loss: 0.4044 - val_mean_absolute_error: 0.4044\n",
            "Epoch 20/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3120 - mean_absolute_error: 0.3120 - val_loss: 0.4576 - val_mean_absolute_error: 0.4576\n",
            "Epoch 21/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3923 - mean_absolute_error: 0.3923 - val_loss: 0.4202 - val_mean_absolute_error: 0.4202\n",
            "Epoch 22/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3223 - mean_absolute_error: 0.3223 - val_loss: 0.3972 - val_mean_absolute_error: 0.3972\n",
            "Epoch 23/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.3475 - mean_absolute_error: 0.3475 - val_loss: 0.3668 - val_mean_absolute_error: 0.3668\n",
            "Epoch 24/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3343 - mean_absolute_error: 0.3343 - val_loss: 0.3647 - val_mean_absolute_error: 0.3647\n",
            "Epoch 25/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3024 - mean_absolute_error: 0.3024 - val_loss: 0.3437 - val_mean_absolute_error: 0.3437\n",
            "Epoch 26/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2906 - mean_absolute_error: 0.2906 - val_loss: 0.4019 - val_mean_absolute_error: 0.4019\n",
            "Epoch 27/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2831 - mean_absolute_error: 0.2831 - val_loss: 0.3509 - val_mean_absolute_error: 0.3509\n",
            "Epoch 28/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2792 - mean_absolute_error: 0.2792 - val_loss: 0.4032 - val_mean_absolute_error: 0.4032\n",
            "Epoch 29/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3034 - mean_absolute_error: 0.3034 - val_loss: 0.3718 - val_mean_absolute_error: 0.3718\n",
            "Epoch 30/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2851 - mean_absolute_error: 0.2851 - val_loss: 0.3630 - val_mean_absolute_error: 0.3630\n",
            "Epoch 31/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2763 - mean_absolute_error: 0.2763 - val_loss: 0.3843 - val_mean_absolute_error: 0.3843\n",
            "Epoch 32/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2540 - mean_absolute_error: 0.2540 - val_loss: 0.3955 - val_mean_absolute_error: 0.3955\n",
            "Epoch 33/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2976 - mean_absolute_error: 0.2976 - val_loss: 0.3296 - val_mean_absolute_error: 0.3296\n",
            "Epoch 34/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2907 - mean_absolute_error: 0.2907 - val_loss: 0.2990 - val_mean_absolute_error: 0.2990\n",
            "Epoch 35/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3217 - mean_absolute_error: 0.3217 - val_loss: 0.3817 - val_mean_absolute_error: 0.3817\n",
            "Epoch 36/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2733 - mean_absolute_error: 0.2733 - val_loss: 0.3392 - val_mean_absolute_error: 0.3392\n",
            "Epoch 37/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2905 - mean_absolute_error: 0.2905 - val_loss: 0.3558 - val_mean_absolute_error: 0.3558\n",
            "Epoch 38/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2552 - mean_absolute_error: 0.2552 - val_loss: 0.3422 - val_mean_absolute_error: 0.3422\n",
            "Epoch 39/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2849 - mean_absolute_error: 0.2849 - val_loss: 0.3575 - val_mean_absolute_error: 0.3575\n",
            "Epoch 40/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2637 - mean_absolute_error: 0.2637 - val_loss: 0.4050 - val_mean_absolute_error: 0.4050\n",
            "Epoch 41/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2180 - mean_absolute_error: 0.2180 - val_loss: 0.2915 - val_mean_absolute_error: 0.2915\n",
            "Epoch 42/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2541 - mean_absolute_error: 0.2541 - val_loss: 0.3464 - val_mean_absolute_error: 0.3464\n",
            "Epoch 43/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2711 - mean_absolute_error: 0.2711 - val_loss: 0.3137 - val_mean_absolute_error: 0.3137\n",
            "Epoch 44/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2606 - mean_absolute_error: 0.2606 - val_loss: 0.3170 - val_mean_absolute_error: 0.3170\n",
            "Epoch 45/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2203 - mean_absolute_error: 0.2203 - val_loss: 0.3647 - val_mean_absolute_error: 0.3647\n",
            "Epoch 46/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2981 - mean_absolute_error: 0.2981 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
            "Epoch 47/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2429 - mean_absolute_error: 0.2429 - val_loss: 0.3226 - val_mean_absolute_error: 0.3226\n",
            "Epoch 48/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2835 - mean_absolute_error: 0.2835 - val_loss: 0.3337 - val_mean_absolute_error: 0.3337\n",
            "Epoch 49/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.2433 - mean_absolute_error: 0.2433 - val_loss: 0.3787 - val_mean_absolute_error: 0.3787\n",
            "Epoch 50/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2798 - mean_absolute_error: 0.2798 - val_loss: 0.2993 - val_mean_absolute_error: 0.2993\n",
            "Epoch 51/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2167 - mean_absolute_error: 0.2167 - val_loss: 0.2841 - val_mean_absolute_error: 0.2841\n",
            "Epoch 52/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2594 - mean_absolute_error: 0.2594 - val_loss: 0.3061 - val_mean_absolute_error: 0.3061\n",
            "Epoch 53/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2470 - mean_absolute_error: 0.2470 - val_loss: 0.3269 - val_mean_absolute_error: 0.3269\n",
            "Epoch 54/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2687 - mean_absolute_error: 0.2687 - val_loss: 0.3453 - val_mean_absolute_error: 0.3453\n",
            "Epoch 55/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.2362 - mean_absolute_error: 0.2362 - val_loss: 0.3338 - val_mean_absolute_error: 0.3338\n",
            "Epoch 56/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2283 - mean_absolute_error: 0.2283 - val_loss: 0.3455 - val_mean_absolute_error: 0.3455\n",
            "Epoch 57/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2295 - mean_absolute_error: 0.2295 - val_loss: 0.2493 - val_mean_absolute_error: 0.2493\n",
            "Epoch 58/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1829 - mean_absolute_error: 0.1829 - val_loss: 0.3275 - val_mean_absolute_error: 0.3275\n",
            "Epoch 59/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1914 - mean_absolute_error: 0.1914 - val_loss: 0.2960 - val_mean_absolute_error: 0.2960\n",
            "Epoch 60/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2352 - mean_absolute_error: 0.2352 - val_loss: 0.3161 - val_mean_absolute_error: 0.3161\n",
            "Epoch 61/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2232 - mean_absolute_error: 0.2232 - val_loss: 0.2785 - val_mean_absolute_error: 0.2785\n",
            "Epoch 62/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2001 - mean_absolute_error: 0.2001 - val_loss: 0.2999 - val_mean_absolute_error: 0.2999\n",
            "Epoch 63/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1915 - mean_absolute_error: 0.1915 - val_loss: 0.2466 - val_mean_absolute_error: 0.2466\n",
            "Epoch 64/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2019 - mean_absolute_error: 0.2019 - val_loss: 0.2616 - val_mean_absolute_error: 0.2616\n",
            "Epoch 65/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2408 - mean_absolute_error: 0.2408 - val_loss: 0.2817 - val_mean_absolute_error: 0.2817\n",
            "Epoch 66/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2531 - mean_absolute_error: 0.2531 - val_loss: 0.2620 - val_mean_absolute_error: 0.2620\n",
            "Epoch 67/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2547 - mean_absolute_error: 0.2547 - val_loss: 0.2506 - val_mean_absolute_error: 0.2506\n",
            "Epoch 68/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2066 - mean_absolute_error: 0.2066 - val_loss: 0.2641 - val_mean_absolute_error: 0.2641\n",
            "Epoch 69/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2123 - mean_absolute_error: 0.2123 - val_loss: 0.2875 - val_mean_absolute_error: 0.2875\n",
            "Epoch 70/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1952 - mean_absolute_error: 0.1952 - val_loss: 0.2807 - val_mean_absolute_error: 0.2807\n",
            "Epoch 71/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2347 - mean_absolute_error: 0.2347 - val_loss: 0.2807 - val_mean_absolute_error: 0.2807\n",
            "Epoch 72/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1941 - mean_absolute_error: 0.1941 - val_loss: 0.2576 - val_mean_absolute_error: 0.2576\n",
            "Epoch 73/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1979 - mean_absolute_error: 0.1979 - val_loss: 0.2845 - val_mean_absolute_error: 0.2845\n",
            "Epoch 74/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2332 - mean_absolute_error: 0.2332 - val_loss: 0.2664 - val_mean_absolute_error: 0.2664\n",
            "Epoch 75/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2288 - mean_absolute_error: 0.2288 - val_loss: 0.2576 - val_mean_absolute_error: 0.2576\n",
            "Epoch 76/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1798 - mean_absolute_error: 0.1798 - val_loss: 0.2407 - val_mean_absolute_error: 0.2407\n",
            "Epoch 77/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1964 - mean_absolute_error: 0.1964 - val_loss: 0.2528 - val_mean_absolute_error: 0.2528\n",
            "Epoch 78/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2385 - mean_absolute_error: 0.2385 - val_loss: 0.2133 - val_mean_absolute_error: 0.2133\n",
            "Epoch 79/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2362 - mean_absolute_error: 0.2362 - val_loss: 0.2419 - val_mean_absolute_error: 0.2419\n",
            "Epoch 80/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2225 - mean_absolute_error: 0.2225 - val_loss: 0.2438 - val_mean_absolute_error: 0.2438\n",
            "Epoch 81/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2217 - mean_absolute_error: 0.2217 - val_loss: 0.2602 - val_mean_absolute_error: 0.2602\n",
            "Epoch 82/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1944 - mean_absolute_error: 0.1944 - val_loss: 0.2338 - val_mean_absolute_error: 0.2338\n",
            "Epoch 83/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1883 - mean_absolute_error: 0.1883 - val_loss: 0.2136 - val_mean_absolute_error: 0.2136\n",
            "Epoch 84/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2487 - mean_absolute_error: 0.2487 - val_loss: 0.2320 - val_mean_absolute_error: 0.2320\n",
            "Epoch 85/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2018 - mean_absolute_error: 0.2018 - val_loss: 0.2405 - val_mean_absolute_error: 0.2405\n",
            "Epoch 86/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2120 - mean_absolute_error: 0.2120 - val_loss: 0.2332 - val_mean_absolute_error: 0.2332\n",
            "Epoch 87/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2045 - mean_absolute_error: 0.2045 - val_loss: 0.2269 - val_mean_absolute_error: 0.2269\n",
            "Epoch 88/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1905 - mean_absolute_error: 0.1905 - val_loss: 0.2684 - val_mean_absolute_error: 0.2684\n",
            "Epoch 89/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1783 - mean_absolute_error: 0.1783 - val_loss: 0.2417 - val_mean_absolute_error: 0.2417\n",
            "Epoch 90/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1968 - mean_absolute_error: 0.1968 - val_loss: 0.2408 - val_mean_absolute_error: 0.2408\n",
            "Epoch 91/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1845 - mean_absolute_error: 0.1845 - val_loss: 0.2378 - val_mean_absolute_error: 0.2378\n",
            "Epoch 92/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2174 - mean_absolute_error: 0.2174 - val_loss: 0.2317 - val_mean_absolute_error: 0.2317\n",
            "Epoch 93/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1791 - mean_absolute_error: 0.1791 - val_loss: 0.2288 - val_mean_absolute_error: 0.2288\n",
            "Epoch 94/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2102 - mean_absolute_error: 0.2102 - val_loss: 0.2913 - val_mean_absolute_error: 0.2913\n",
            "Epoch 95/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1724 - mean_absolute_error: 0.1724 - val_loss: 0.2408 - val_mean_absolute_error: 0.2408\n",
            "Epoch 96/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1748 - mean_absolute_error: 0.1748 - val_loss: 0.2394 - val_mean_absolute_error: 0.2394\n",
            "Epoch 97/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1969 - mean_absolute_error: 0.1969 - val_loss: 0.2430 - val_mean_absolute_error: 0.2430\n",
            "Epoch 98/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1851 - mean_absolute_error: 0.1851 - val_loss: 0.2554 - val_mean_absolute_error: 0.2554\n",
            "Epoch 99/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1715 - mean_absolute_error: 0.1715 - val_loss: 0.2497 - val_mean_absolute_error: 0.2497\n",
            "Epoch 100/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1967 - mean_absolute_error: 0.1967 - val_loss: 0.2749 - val_mean_absolute_error: 0.2749\n",
            "Epoch 101/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1905 - mean_absolute_error: 0.1905 - val_loss: 0.2455 - val_mean_absolute_error: 0.2455\n",
            "Epoch 102/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1764 - mean_absolute_error: 0.1764 - val_loss: 0.2206 - val_mean_absolute_error: 0.2206\n",
            "Epoch 103/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1526 - mean_absolute_error: 0.1526 - val_loss: 0.2236 - val_mean_absolute_error: 0.2236\n",
            "Epoch 104/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1946 - mean_absolute_error: 0.1946 - val_loss: 0.2268 - val_mean_absolute_error: 0.2268\n",
            "Epoch 105/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1825 - mean_absolute_error: 0.1825 - val_loss: 0.2340 - val_mean_absolute_error: 0.2340\n",
            "Epoch 106/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1799 - mean_absolute_error: 0.1799 - val_loss: 0.2336 - val_mean_absolute_error: 0.2336\n",
            "Epoch 107/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1691 - mean_absolute_error: 0.1691 - val_loss: 0.2050 - val_mean_absolute_error: 0.2050\n",
            "Epoch 108/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1771 - mean_absolute_error: 0.1771 - val_loss: 0.2128 - val_mean_absolute_error: 0.2128\n",
            "Epoch 109/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1903 - mean_absolute_error: 0.1903 - val_loss: 0.2002 - val_mean_absolute_error: 0.2002\n",
            "Epoch 110/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1957 - mean_absolute_error: 0.1957 - val_loss: 0.2015 - val_mean_absolute_error: 0.2015\n",
            "Epoch 111/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2038 - mean_absolute_error: 0.2038 - val_loss: 0.2068 - val_mean_absolute_error: 0.2068\n",
            "Epoch 112/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1753 - mean_absolute_error: 0.1753 - val_loss: 0.2213 - val_mean_absolute_error: 0.2213\n",
            "Epoch 113/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1730 - mean_absolute_error: 0.1730 - val_loss: 0.2550 - val_mean_absolute_error: 0.2550\n",
            "Epoch 114/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1688 - mean_absolute_error: 0.1688 - val_loss: 0.2553 - val_mean_absolute_error: 0.2553\n",
            "Epoch 115/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1817 - mean_absolute_error: 0.1817 - val_loss: 0.2362 - val_mean_absolute_error: 0.2362\n",
            "Epoch 116/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1951 - mean_absolute_error: 0.1951 - val_loss: 0.2038 - val_mean_absolute_error: 0.2038\n",
            "Epoch 117/300\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1805 - mean_absolute_error: 0.1805 - val_loss: 0.2336 - val_mean_absolute_error: 0.2336\n",
            "Epoch 118/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1830 - mean_absolute_error: 0.1830 - val_loss: 0.2292 - val_mean_absolute_error: 0.2292\n",
            "Epoch 119/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1828 - mean_absolute_error: 0.1828 - val_loss: 0.2314 - val_mean_absolute_error: 0.2314\n",
            "Epoch 120/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1788 - mean_absolute_error: 0.1788 - val_loss: 0.2362 - val_mean_absolute_error: 0.2362\n",
            "Epoch 121/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1644 - mean_absolute_error: 0.1644 - val_loss: 0.2275 - val_mean_absolute_error: 0.2275\n",
            "Epoch 122/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1755 - mean_absolute_error: 0.1755 - val_loss: 0.2768 - val_mean_absolute_error: 0.2768\n",
            "Epoch 123/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1920 - mean_absolute_error: 0.1920 - val_loss: 0.2431 - val_mean_absolute_error: 0.2431\n",
            "Epoch 124/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1774 - mean_absolute_error: 0.1774 - val_loss: 0.2177 - val_mean_absolute_error: 0.2177\n",
            "Epoch 125/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1705 - mean_absolute_error: 0.1705 - val_loss: 0.2163 - val_mean_absolute_error: 0.2163\n",
            "Epoch 126/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2131 - mean_absolute_error: 0.2131 - val_loss: 0.2257 - val_mean_absolute_error: 0.2257\n",
            "Epoch 127/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1826 - mean_absolute_error: 0.1826 - val_loss: 0.2467 - val_mean_absolute_error: 0.2467\n",
            "Epoch 128/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1912 - mean_absolute_error: 0.1912 - val_loss: 0.2101 - val_mean_absolute_error: 0.2101\n",
            "Epoch 129/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1904 - mean_absolute_error: 0.1904 - val_loss: 0.2266 - val_mean_absolute_error: 0.2266\n",
            "Epoch 130/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1697 - mean_absolute_error: 0.1697 - val_loss: 0.2372 - val_mean_absolute_error: 0.2372\n",
            "Epoch 131/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1549 - mean_absolute_error: 0.1549 - val_loss: 0.2294 - val_mean_absolute_error: 0.2294\n",
            "Epoch 132/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1772 - mean_absolute_error: 0.1772 - val_loss: 0.2270 - val_mean_absolute_error: 0.2270\n",
            "Epoch 133/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1683 - mean_absolute_error: 0.1683 - val_loss: 0.2137 - val_mean_absolute_error: 0.2137\n",
            "Epoch 134/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1925 - mean_absolute_error: 0.1925 - val_loss: 0.2720 - val_mean_absolute_error: 0.2720\n",
            "Epoch 135/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1997 - mean_absolute_error: 0.1997 - val_loss: 0.2236 - val_mean_absolute_error: 0.2236\n",
            "Epoch 136/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1595 - mean_absolute_error: 0.1595 - val_loss: 0.2654 - val_mean_absolute_error: 0.2654\n",
            "Epoch 137/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2017 - mean_absolute_error: 0.2017 - val_loss: 0.2063 - val_mean_absolute_error: 0.2063\n",
            "Epoch 138/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2177 - mean_absolute_error: 0.2177 - val_loss: 0.2094 - val_mean_absolute_error: 0.2094\n",
            "Epoch 139/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2034 - mean_absolute_error: 0.2034 - val_loss: 0.2161 - val_mean_absolute_error: 0.2161\n",
            "Epoch 140/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1807 - mean_absolute_error: 0.1807 - val_loss: 0.2268 - val_mean_absolute_error: 0.2268\n",
            "Epoch 141/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1916 - mean_absolute_error: 0.1916 - val_loss: 0.2142 - val_mean_absolute_error: 0.2142\n",
            "Epoch 142/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1685 - mean_absolute_error: 0.1685 - val_loss: 0.2620 - val_mean_absolute_error: 0.2620\n",
            "Epoch 143/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1509 - mean_absolute_error: 0.1509 - val_loss: 0.1884 - val_mean_absolute_error: 0.1884\n",
            "Epoch 144/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1911 - mean_absolute_error: 0.1911 - val_loss: 0.1901 - val_mean_absolute_error: 0.1901\n",
            "Epoch 145/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1603 - mean_absolute_error: 0.1603 - val_loss: 0.2534 - val_mean_absolute_error: 0.2534\n",
            "Epoch 146/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1568 - mean_absolute_error: 0.1568 - val_loss: 0.2150 - val_mean_absolute_error: 0.2150\n",
            "Epoch 147/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1701 - mean_absolute_error: 0.1701 - val_loss: 0.2143 - val_mean_absolute_error: 0.2143\n",
            "Epoch 148/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1612 - mean_absolute_error: 0.1612 - val_loss: 0.2203 - val_mean_absolute_error: 0.2203\n",
            "Epoch 149/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1716 - mean_absolute_error: 0.1716 - val_loss: 0.2278 - val_mean_absolute_error: 0.2278\n",
            "Epoch 150/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1790 - mean_absolute_error: 0.1790 - val_loss: 0.1914 - val_mean_absolute_error: 0.1914\n",
            "Epoch 151/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1837 - mean_absolute_error: 0.1837 - val_loss: 0.2146 - val_mean_absolute_error: 0.2146\n",
            "Epoch 152/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1617 - mean_absolute_error: 0.1617 - val_loss: 0.1966 - val_mean_absolute_error: 0.1966\n",
            "Epoch 153/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1681 - mean_absolute_error: 0.1681 - val_loss: 0.2241 - val_mean_absolute_error: 0.2241\n",
            "Epoch 154/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1759 - mean_absolute_error: 0.1759 - val_loss: 0.2004 - val_mean_absolute_error: 0.2004\n",
            "Epoch 155/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1676 - mean_absolute_error: 0.1676 - val_loss: 0.2219 - val_mean_absolute_error: 0.2219\n",
            "Epoch 156/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1751 - mean_absolute_error: 0.1751 - val_loss: 0.1990 - val_mean_absolute_error: 0.1990\n",
            "Epoch 157/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1675 - mean_absolute_error: 0.1675 - val_loss: 0.2202 - val_mean_absolute_error: 0.2202\n",
            "Epoch 158/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1884 - mean_absolute_error: 0.1884 - val_loss: 0.1853 - val_mean_absolute_error: 0.1853\n",
            "Epoch 159/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1760 - mean_absolute_error: 0.1760 - val_loss: 0.2219 - val_mean_absolute_error: 0.2219\n",
            "Epoch 160/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1783 - mean_absolute_error: 0.1783 - val_loss: 0.2161 - val_mean_absolute_error: 0.2161\n",
            "Epoch 161/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1695 - mean_absolute_error: 0.1695 - val_loss: 0.2442 - val_mean_absolute_error: 0.2442\n",
            "Epoch 162/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1582 - mean_absolute_error: 0.1582 - val_loss: 0.2832 - val_mean_absolute_error: 0.2832\n",
            "Epoch 163/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2128 - mean_absolute_error: 0.2128 - val_loss: 0.2365 - val_mean_absolute_error: 0.2365\n",
            "Epoch 164/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1811 - mean_absolute_error: 0.1811 - val_loss: 0.2601 - val_mean_absolute_error: 0.2601\n",
            "Epoch 165/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1815 - mean_absolute_error: 0.1815 - val_loss: 0.2245 - val_mean_absolute_error: 0.2245\n",
            "Epoch 166/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1691 - mean_absolute_error: 0.1691 - val_loss: 0.2306 - val_mean_absolute_error: 0.2306\n",
            "Epoch 167/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1878 - mean_absolute_error: 0.1878 - val_loss: 0.2290 - val_mean_absolute_error: 0.2290\n",
            "Epoch 168/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1932 - mean_absolute_error: 0.1932 - val_loss: 0.2794 - val_mean_absolute_error: 0.2794\n",
            "Epoch 169/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1766 - mean_absolute_error: 0.1766 - val_loss: 0.2452 - val_mean_absolute_error: 0.2452\n",
            "Epoch 170/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1655 - mean_absolute_error: 0.1655 - val_loss: 0.2031 - val_mean_absolute_error: 0.2031\n",
            "Epoch 171/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1558 - mean_absolute_error: 0.1558 - val_loss: 0.2388 - val_mean_absolute_error: 0.2388\n",
            "Epoch 172/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1876 - mean_absolute_error: 0.1876 - val_loss: 0.2082 - val_mean_absolute_error: 0.2082\n",
            "Epoch 173/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1599 - mean_absolute_error: 0.1599 - val_loss: 0.2150 - val_mean_absolute_error: 0.2150\n",
            "Epoch 174/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1547 - mean_absolute_error: 0.1547 - val_loss: 0.2242 - val_mean_absolute_error: 0.2242\n",
            "Epoch 175/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1921 - mean_absolute_error: 0.1921 - val_loss: 0.2213 - val_mean_absolute_error: 0.2213\n",
            "Epoch 176/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1664 - mean_absolute_error: 0.1664 - val_loss: 0.1870 - val_mean_absolute_error: 0.1870\n",
            "Epoch 177/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1783 - mean_absolute_error: 0.1783 - val_loss: 0.2290 - val_mean_absolute_error: 0.2290\n",
            "Epoch 178/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1488 - mean_absolute_error: 0.1488 - val_loss: 0.1742 - val_mean_absolute_error: 0.1742\n",
            "Epoch 179/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1596 - mean_absolute_error: 0.1596 - val_loss: 0.1956 - val_mean_absolute_error: 0.1956\n",
            "Epoch 180/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1617 - mean_absolute_error: 0.1617 - val_loss: 0.2420 - val_mean_absolute_error: 0.2420\n",
            "Epoch 181/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1929 - mean_absolute_error: 0.1929 - val_loss: 0.2790 - val_mean_absolute_error: 0.2790\n",
            "Epoch 182/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1461 - mean_absolute_error: 0.1461 - val_loss: 0.1874 - val_mean_absolute_error: 0.1874\n",
            "Epoch 183/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1674 - mean_absolute_error: 0.1674 - val_loss: 0.2233 - val_mean_absolute_error: 0.2233\n",
            "Epoch 184/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1639 - mean_absolute_error: 0.1639 - val_loss: 0.2062 - val_mean_absolute_error: 0.2062\n",
            "Epoch 185/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1573 - mean_absolute_error: 0.1573 - val_loss: 0.2150 - val_mean_absolute_error: 0.2150\n",
            "Epoch 186/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1724 - mean_absolute_error: 0.1724 - val_loss: 0.1885 - val_mean_absolute_error: 0.1885\n",
            "Epoch 187/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1751 - mean_absolute_error: 0.1751 - val_loss: 0.2471 - val_mean_absolute_error: 0.2471\n",
            "Epoch 188/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1473 - mean_absolute_error: 0.1473 - val_loss: 0.2802 - val_mean_absolute_error: 0.2802\n",
            "Epoch 189/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1569 - mean_absolute_error: 0.1569 - val_loss: 0.2058 - val_mean_absolute_error: 0.2058\n",
            "Epoch 190/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1828 - mean_absolute_error: 0.1828 - val_loss: 0.2199 - val_mean_absolute_error: 0.2199\n",
            "Epoch 191/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1608 - mean_absolute_error: 0.1608 - val_loss: 0.2187 - val_mean_absolute_error: 0.2187\n",
            "Epoch 192/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1695 - mean_absolute_error: 0.1695 - val_loss: 0.2087 - val_mean_absolute_error: 0.2087\n",
            "Epoch 193/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1875 - mean_absolute_error: 0.1875 - val_loss: 0.2520 - val_mean_absolute_error: 0.2520\n",
            "Epoch 194/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1572 - mean_absolute_error: 0.1572 - val_loss: 0.2153 - val_mean_absolute_error: 0.2153\n",
            "Epoch 195/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1589 - mean_absolute_error: 0.1589 - val_loss: 0.2130 - val_mean_absolute_error: 0.2130\n",
            "Epoch 196/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2116 - mean_absolute_error: 0.2116 - val_loss: 0.2034 - val_mean_absolute_error: 0.2034\n",
            "Epoch 197/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.2171 - val_mean_absolute_error: 0.2171\n",
            "Epoch 198/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1439 - mean_absolute_error: 0.1439 - val_loss: 0.2322 - val_mean_absolute_error: 0.2322\n",
            "Epoch 199/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1489 - mean_absolute_error: 0.1489 - val_loss: 0.2252 - val_mean_absolute_error: 0.2252\n",
            "Epoch 200/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1563 - mean_absolute_error: 0.1563 - val_loss: 0.2181 - val_mean_absolute_error: 0.2181\n",
            "Epoch 201/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1583 - mean_absolute_error: 0.1583 - val_loss: 0.2165 - val_mean_absolute_error: 0.2165\n",
            "Epoch 202/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1800 - mean_absolute_error: 0.1800 - val_loss: 0.2148 - val_mean_absolute_error: 0.2148\n",
            "Epoch 203/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1346 - mean_absolute_error: 0.1346 - val_loss: 0.1956 - val_mean_absolute_error: 0.1956\n",
            "Epoch 204/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1492 - mean_absolute_error: 0.1492 - val_loss: 0.2609 - val_mean_absolute_error: 0.2609\n",
            "Epoch 205/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1621 - mean_absolute_error: 0.1621 - val_loss: 0.1959 - val_mean_absolute_error: 0.1959\n",
            "Epoch 206/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1709 - mean_absolute_error: 0.1709 - val_loss: 0.2189 - val_mean_absolute_error: 0.2189\n",
            "Epoch 207/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1535 - mean_absolute_error: 0.1535 - val_loss: 0.2191 - val_mean_absolute_error: 0.2191\n",
            "Epoch 208/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1599 - mean_absolute_error: 0.1599 - val_loss: 0.2036 - val_mean_absolute_error: 0.2036\n",
            "Epoch 209/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1947 - mean_absolute_error: 0.1947 - val_loss: 0.2233 - val_mean_absolute_error: 0.2233\n",
            "Epoch 210/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1612 - mean_absolute_error: 0.1612 - val_loss: 0.2160 - val_mean_absolute_error: 0.2160\n",
            "Epoch 211/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1664 - mean_absolute_error: 0.1664 - val_loss: 0.2514 - val_mean_absolute_error: 0.2514\n",
            "Epoch 212/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1438 - mean_absolute_error: 0.1438 - val_loss: 0.2101 - val_mean_absolute_error: 0.2101\n",
            "Epoch 213/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1459 - mean_absolute_error: 0.1459 - val_loss: 0.2052 - val_mean_absolute_error: 0.2052\n",
            "Epoch 214/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1669 - mean_absolute_error: 0.1669 - val_loss: 0.2216 - val_mean_absolute_error: 0.2216\n",
            "Epoch 215/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1564 - mean_absolute_error: 0.1564 - val_loss: 0.1852 - val_mean_absolute_error: 0.1852\n",
            "Epoch 216/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1432 - mean_absolute_error: 0.1432 - val_loss: 0.1881 - val_mean_absolute_error: 0.1881\n",
            "Epoch 217/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1394 - mean_absolute_error: 0.1394 - val_loss: 0.2291 - val_mean_absolute_error: 0.2291\n",
            "Epoch 218/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1946 - mean_absolute_error: 0.1946 - val_loss: 0.2177 - val_mean_absolute_error: 0.2177\n",
            "Epoch 219/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1437 - mean_absolute_error: 0.1437 - val_loss: 0.2207 - val_mean_absolute_error: 0.2207\n",
            "Epoch 220/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1599 - mean_absolute_error: 0.1599 - val_loss: 0.2150 - val_mean_absolute_error: 0.2150\n",
            "Epoch 221/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1671 - mean_absolute_error: 0.1671 - val_loss: 0.2021 - val_mean_absolute_error: 0.2021\n",
            "Epoch 222/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1611 - mean_absolute_error: 0.1611 - val_loss: 0.2268 - val_mean_absolute_error: 0.2268\n",
            "Epoch 223/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1570 - mean_absolute_error: 0.1570 - val_loss: 0.2193 - val_mean_absolute_error: 0.2193\n",
            "Epoch 224/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1632 - mean_absolute_error: 0.1632 - val_loss: 0.2212 - val_mean_absolute_error: 0.2212\n",
            "Epoch 225/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1660 - mean_absolute_error: 0.1660 - val_loss: 0.1944 - val_mean_absolute_error: 0.1944\n",
            "Epoch 226/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1522 - mean_absolute_error: 0.1522 - val_loss: 0.1918 - val_mean_absolute_error: 0.1918\n",
            "Epoch 227/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1677 - mean_absolute_error: 0.1677 - val_loss: 0.2036 - val_mean_absolute_error: 0.2036\n",
            "Epoch 228/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1458 - mean_absolute_error: 0.1458 - val_loss: 0.2416 - val_mean_absolute_error: 0.2416\n",
            "Epoch 229/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1425 - mean_absolute_error: 0.1425 - val_loss: 0.2187 - val_mean_absolute_error: 0.2187\n",
            "Epoch 230/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1616 - mean_absolute_error: 0.1616 - val_loss: 0.2106 - val_mean_absolute_error: 0.2106\n",
            "Epoch 231/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1428 - mean_absolute_error: 0.1428 - val_loss: 0.2324 - val_mean_absolute_error: 0.2324\n",
            "Epoch 232/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1336 - mean_absolute_error: 0.1336 - val_loss: 0.1953 - val_mean_absolute_error: 0.1953\n",
            "Epoch 233/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1671 - mean_absolute_error: 0.1671 - val_loss: 0.2211 - val_mean_absolute_error: 0.2211\n",
            "Epoch 234/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1494 - mean_absolute_error: 0.1494 - val_loss: 0.1949 - val_mean_absolute_error: 0.1949\n",
            "Epoch 235/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1510 - mean_absolute_error: 0.1510 - val_loss: 0.2312 - val_mean_absolute_error: 0.2312\n",
            "Epoch 236/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1628 - mean_absolute_error: 0.1628 - val_loss: 0.2433 - val_mean_absolute_error: 0.2433\n",
            "Epoch 237/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1624 - mean_absolute_error: 0.1624 - val_loss: 0.1918 - val_mean_absolute_error: 0.1918\n",
            "Epoch 238/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1725 - mean_absolute_error: 0.1725 - val_loss: 0.2078 - val_mean_absolute_error: 0.2078\n",
            "Epoch 239/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1354 - mean_absolute_error: 0.1354 - val_loss: 0.2218 - val_mean_absolute_error: 0.2218\n",
            "Epoch 240/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1594 - mean_absolute_error: 0.1594 - val_loss: 0.1886 - val_mean_absolute_error: 0.1886\n",
            "Epoch 241/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1536 - mean_absolute_error: 0.1536 - val_loss: 0.2148 - val_mean_absolute_error: 0.2148\n",
            "Epoch 242/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1961 - mean_absolute_error: 0.1961 - val_loss: 0.1895 - val_mean_absolute_error: 0.1895\n",
            "Epoch 243/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1417 - mean_absolute_error: 0.1417 - val_loss: 0.2592 - val_mean_absolute_error: 0.2592\n",
            "Epoch 244/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1670 - mean_absolute_error: 0.1670 - val_loss: 0.2021 - val_mean_absolute_error: 0.2021\n",
            "Epoch 245/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1642 - mean_absolute_error: 0.1642 - val_loss: 0.1788 - val_mean_absolute_error: 0.1788\n",
            "Epoch 246/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1487 - mean_absolute_error: 0.1487 - val_loss: 0.2066 - val_mean_absolute_error: 0.2066\n",
            "Epoch 247/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1733 - mean_absolute_error: 0.1733 - val_loss: 0.1940 - val_mean_absolute_error: 0.1940\n",
            "Epoch 248/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1423 - mean_absolute_error: 0.1423 - val_loss: 0.2219 - val_mean_absolute_error: 0.2219\n",
            "Epoch 249/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1652 - mean_absolute_error: 0.1652 - val_loss: 0.1938 - val_mean_absolute_error: 0.1938\n",
            "Epoch 250/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1660 - mean_absolute_error: 0.1660 - val_loss: 0.2198 - val_mean_absolute_error: 0.2198\n",
            "Epoch 251/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1453 - mean_absolute_error: 0.1453 - val_loss: 0.2199 - val_mean_absolute_error: 0.2199\n",
            "Epoch 252/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1453 - mean_absolute_error: 0.1453 - val_loss: 0.2544 - val_mean_absolute_error: 0.2544\n",
            "Epoch 253/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1546 - mean_absolute_error: 0.1546 - val_loss: 0.2175 - val_mean_absolute_error: 0.2175\n",
            "Epoch 254/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1712 - mean_absolute_error: 0.1712 - val_loss: 0.2686 - val_mean_absolute_error: 0.2686\n",
            "Epoch 255/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1410 - mean_absolute_error: 0.1410 - val_loss: 0.2462 - val_mean_absolute_error: 0.2462\n",
            "Epoch 256/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1284 - mean_absolute_error: 0.1284 - val_loss: 0.2063 - val_mean_absolute_error: 0.2063\n",
            "Epoch 257/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1336 - mean_absolute_error: 0.1336 - val_loss: 0.1921 - val_mean_absolute_error: 0.1921\n",
            "Epoch 258/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1404 - mean_absolute_error: 0.1404 - val_loss: 0.2089 - val_mean_absolute_error: 0.2089\n",
            "Epoch 259/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1865 - mean_absolute_error: 0.1865 - val_loss: 0.2180 - val_mean_absolute_error: 0.2180\n",
            "Epoch 260/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1627 - mean_absolute_error: 0.1627 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\n",
            "Epoch 261/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1622 - mean_absolute_error: 0.1622 - val_loss: 0.2034 - val_mean_absolute_error: 0.2034\n",
            "Epoch 262/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1584 - mean_absolute_error: 0.1584 - val_loss: 0.2036 - val_mean_absolute_error: 0.2036\n",
            "Epoch 263/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1484 - mean_absolute_error: 0.1484 - val_loss: 0.1927 - val_mean_absolute_error: 0.1927\n",
            "Epoch 264/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1491 - mean_absolute_error: 0.1491 - val_loss: 0.2453 - val_mean_absolute_error: 0.2453\n",
            "Epoch 265/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1654 - mean_absolute_error: 0.1654 - val_loss: 0.2354 - val_mean_absolute_error: 0.2354\n",
            "Epoch 266/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1713 - mean_absolute_error: 0.1713 - val_loss: 0.2073 - val_mean_absolute_error: 0.2073\n",
            "Epoch 267/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1669 - mean_absolute_error: 0.1669 - val_loss: 0.2107 - val_mean_absolute_error: 0.2107\n",
            "Epoch 268/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1429 - mean_absolute_error: 0.1429 - val_loss: 0.2264 - val_mean_absolute_error: 0.2264\n",
            "Epoch 269/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1575 - mean_absolute_error: 0.1575 - val_loss: 0.2145 - val_mean_absolute_error: 0.2145\n",
            "Epoch 270/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1880 - mean_absolute_error: 0.1880 - val_loss: 0.2657 - val_mean_absolute_error: 0.2657\n",
            "Epoch 271/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1534 - mean_absolute_error: 0.1534 - val_loss: 0.1996 - val_mean_absolute_error: 0.1996\n",
            "Epoch 272/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1418 - mean_absolute_error: 0.1418 - val_loss: 0.1995 - val_mean_absolute_error: 0.1995\n",
            "Epoch 273/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1887 - mean_absolute_error: 0.1887 - val_loss: 0.2714 - val_mean_absolute_error: 0.2714\n",
            "Epoch 274/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1475 - mean_absolute_error: 0.1475 - val_loss: 0.2241 - val_mean_absolute_error: 0.2241\n",
            "Epoch 275/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1494 - mean_absolute_error: 0.1494 - val_loss: 0.2485 - val_mean_absolute_error: 0.2485\n",
            "Epoch 276/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1624 - mean_absolute_error: 0.1624 - val_loss: 0.2007 - val_mean_absolute_error: 0.2007\n",
            "Epoch 277/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1414 - mean_absolute_error: 0.1414 - val_loss: 0.2244 - val_mean_absolute_error: 0.2244\n",
            "Epoch 278/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1699 - mean_absolute_error: 0.1699 - val_loss: 0.1961 - val_mean_absolute_error: 0.1961\n",
            "Epoch 279/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1726 - mean_absolute_error: 0.1726 - val_loss: 0.2045 - val_mean_absolute_error: 0.2045\n",
            "Epoch 280/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1507 - mean_absolute_error: 0.1507 - val_loss: 0.1890 - val_mean_absolute_error: 0.1890\n",
            "Epoch 281/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.2095 - val_mean_absolute_error: 0.2095\n",
            "Epoch 282/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1704 - mean_absolute_error: 0.1704 - val_loss: 0.1813 - val_mean_absolute_error: 0.1813\n",
            "Epoch 283/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1349 - mean_absolute_error: 0.1349 - val_loss: 0.2531 - val_mean_absolute_error: 0.2531\n",
            "Epoch 284/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1821 - mean_absolute_error: 0.1821 - val_loss: 0.2051 - val_mean_absolute_error: 0.2051\n",
            "Epoch 285/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1404 - mean_absolute_error: 0.1404 - val_loss: 0.2445 - val_mean_absolute_error: 0.2445\n",
            "Epoch 286/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1498 - mean_absolute_error: 0.1498 - val_loss: 0.2249 - val_mean_absolute_error: 0.2249\n",
            "Epoch 287/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1610 - mean_absolute_error: 0.1610 - val_loss: 0.2213 - val_mean_absolute_error: 0.2213\n",
            "Epoch 288/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1291 - mean_absolute_error: 0.1291 - val_loss: 0.2890 - val_mean_absolute_error: 0.2890\n",
            "Epoch 289/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1831 - mean_absolute_error: 0.1831 - val_loss: 0.2108 - val_mean_absolute_error: 0.2108\n",
            "Epoch 290/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1536 - mean_absolute_error: 0.1536 - val_loss: 0.2209 - val_mean_absolute_error: 0.2209\n",
            "Epoch 291/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1717 - mean_absolute_error: 0.1717 - val_loss: 0.2026 - val_mean_absolute_error: 0.2026\n",
            "Epoch 292/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1471 - mean_absolute_error: 0.1471 - val_loss: 0.2179 - val_mean_absolute_error: 0.2179\n",
            "Epoch 293/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1580 - mean_absolute_error: 0.1580 - val_loss: 0.2330 - val_mean_absolute_error: 0.2330\n",
            "Epoch 294/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1589 - mean_absolute_error: 0.1589 - val_loss: 0.1899 - val_mean_absolute_error: 0.1899\n",
            "Epoch 295/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1388 - mean_absolute_error: 0.1388 - val_loss: 0.2397 - val_mean_absolute_error: 0.2397\n",
            "Epoch 296/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1254 - mean_absolute_error: 0.1254 - val_loss: 0.2282 - val_mean_absolute_error: 0.2282\n",
            "Epoch 297/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1448 - mean_absolute_error: 0.1448 - val_loss: 0.1926 - val_mean_absolute_error: 0.1926\n",
            "Epoch 298/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1452 - mean_absolute_error: 0.1452 - val_loss: 0.2287 - val_mean_absolute_error: 0.2287\n",
            "Epoch 299/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.2023 - val_mean_absolute_error: 0.2023\n",
            "Epoch 300/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1453 - mean_absolute_error: 0.1453 - val_loss: 0.2121 - val_mean_absolute_error: 0.2121\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[-1.439222]], shape=(1, 1), dtype=float32)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 38)                228       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 41)                1599      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 19)                798       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 35)                700       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 35)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 36        \n",
            "=================================================================\n",
            "Total params: 3,361\n",
            "Trainable params: 3,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'drop_rate': 0.4,\n",
              " 'num_layers': 4,\n",
              " 'optimizer': 'rmsprop',\n",
              " 'units_0': 38,\n",
              " 'units_1': 41,\n",
              " 'units_2': 19,\n",
              " 'units_3': 35}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuX7O9EAIm_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4db20d4-0391-41bc-ef2b-1ceb91082807"
      },
      "source": [
        "!pip3 install pygad"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygad\n",
            "  Downloading pygad-2.16.0-py3-none-any.whl (52 kB)\n",
            "\u001b[?25l\r\u001b[K     |                         | 10 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |                   | 20 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |             | 30 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |       | 40 kB 9.6 MB/s eta 0:00:01\r\u001b[K     | | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     || 52 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pygad) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pygad) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->pygad) (1.15.0)\n",
            "Installing collected packages: pygad\n",
            "Successfully installed pygad-2.16.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YukvvS4oIrLA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "649a0836-6f10-4e00-fa49-cc320f7a6756"
      },
      "source": [
        "# Optimization for input features\n",
        "\n",
        "import numpy as np\n",
        "import pygad\n",
        "\n",
        "#initialization\n",
        "function_inputs = [0.5,0.5,0.5,0.5,0.5]\n",
        "\n",
        "#define fitness function\n",
        "def fitness_func(solution, solution_idx):\n",
        "    target = [1.5]\n",
        "    target = abs(y-y_mean)/y_std\n",
        "    output=model(np.array(solution*function_inputs).reshape(1,5)) # model is built in keras.tuner\n",
        "    output = abs(tf.subtract(abs(output), abs(target)))\n",
        "    fitness =((1/output)).numpy()[0]\n",
        "    #fitness =output.numpy()[0]\n",
        "    return fitness\n",
        "\n",
        "# Number of generations.\n",
        "num_generations = 100\n",
        "# Number of solutions to be selected as parents in the mating pool.\n",
        "num_parents_mating = 5 \n",
        "# Number of solutions in the population.\n",
        "sol_per_pop = 10 \n",
        "  \n",
        "# Type of parent selection.\n",
        "parent_selection_type = \"sss\"\n",
        "# Type of the crossover operator.\n",
        "crossover_type = \"single_point\" \n",
        "# Type of the mutation operator.\n",
        "mutation_type = \"random\"\n",
        "\n",
        "last_fitness = 0\n",
        "def callback_generation(ga_instance):\n",
        "    global last_fitness\n",
        "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
        "    print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
        "    print(\"Change     = {change}\".format(change=ga_instance.best_solution()[1] - last_fitness))\n",
        "    last_fitness = ga_instance.best_solution()[1]\n",
        "\n",
        "# Creating an instance of the GA class inside the ga module. Some parameters are initialized within the constructor.\n",
        "ga_instance = pygad.GA(\n",
        "     #Number of generations(iterations).\n",
        "     num_generations=num_generations,\n",
        "     num_parents_mating=num_parents_mating,\n",
        "     fitness_func=fitness_func,\n",
        "     sol_per_pop=sol_per_pop,\n",
        "     #the Number of parameters(the number of genes)\n",
        "     num_genes=5,\n",
        "     gene_space=[np.arange(-1.68,2.88,0.01).tolist(),np.arange(-1.34,1.73,0.01).tolist(),np.arange(-0.88,1.56,0.01).tolist(),np.arange(-0.99,1.32,0.01).tolist(),\n",
        "                 np.arange(-1.26,-0.392,0.01).tolist()],\n",
        "     \n",
        "     parent_selection_type=parent_selection_type,\n",
        "     keep_parents=1,\n",
        "     crossover_type=crossover_type,\n",
        "     mutation_percent_genes=50,\n",
        "     mutation_type=mutation_type,\n",
        "     callback_generation=callback_generation)\n",
        "\n",
        "# Running the GA to optimize the parameters of the function.\n",
        "ga_instance.run()\n",
        "\n",
        "\n",
        "# After the generations complete, some plots are showed that summarize the how the outputs/fitenss values evolve over generations.\n",
        "ga_instance.plot_result()\n",
        "\n",
        "# Returning the details of the best solution.\n",
        "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
        "solution = tf.multiply(solution,x_std)\n",
        "solution = tf.add(solution, x_mean)\n",
        "print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
        "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=1/solution_fitness))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pygad/pygad.py:731: UserWarning: Starting from PyGAD 2.6.0, the callback_generation parameter is deprecated and will be removed in a later release of PyGAD. Please use the on_generation parameter instead.\n",
            "  if not self.suppress_warnings: warnings.warn(\"Starting from PyGAD 2.6.0, the callback_generation parameter is deprecated and will be removed in a later release of PyGAD. Please use the on_generation parameter instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation = 1\n",
            "Fitness    = [3.9200816]\n",
            "Change     = [3.9200816]\n",
            "Generation = 2\n",
            "Fitness    = [3.9200816]\n",
            "Change     = [0.]\n",
            "Generation = 3\n",
            "Fitness    = [3.9200816]\n",
            "Change     = [0.]\n",
            "Generation = 4\n",
            "Fitness    = [4.045193]\n",
            "Change     = [0.12511158]\n",
            "Generation = 5\n",
            "Fitness    = [4.045193]\n",
            "Change     = [0.]\n",
            "Generation = 6\n",
            "Fitness    = [4.1764526]\n",
            "Change     = [0.13125944]\n",
            "Generation = 7\n",
            "Fitness    = [4.1764526]\n",
            "Change     = [0.]\n",
            "Generation = 8\n",
            "Fitness    = [4.1764526]\n",
            "Change     = [0.]\n",
            "Generation = 9\n",
            "Fitness    = [4.1764526]\n",
            "Change     = [0.]\n",
            "Generation = 10\n",
            "Fitness    = [4.1764526]\n",
            "Change     = [0.]\n",
            "Generation = 11\n",
            "Fitness    = [4.1764526]\n",
            "Change     = [0.]\n",
            "Generation = 12\n",
            "Fitness    = [4.1764526]\n",
            "Change     = [0.]\n",
            "Generation = 13\n",
            "Fitness    = [4.250348]\n",
            "Change     = [0.07389545]\n",
            "Generation = 14\n",
            "Fitness    = [4.250348]\n",
            "Change     = [0.]\n",
            "Generation = 15\n",
            "Fitness    = [4.250348]\n",
            "Change     = [0.]\n",
            "Generation = 16\n",
            "Fitness    = [4.250348]\n",
            "Change     = [0.]\n",
            "Generation = 17\n",
            "Fitness    = [4.5567737]\n",
            "Change     = [0.30642557]\n",
            "Generation = 18\n",
            "Fitness    = [4.5567737]\n",
            "Change     = [0.]\n",
            "Generation = 19\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.63507843]\n",
            "Generation = 20\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 21\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 22\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 23\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 24\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 25\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 26\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 27\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 28\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 29\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 30\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 31\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 32\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 33\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 34\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 35\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 36\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 37\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 38\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 39\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 40\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 41\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 42\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 43\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 44\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 45\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 46\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 47\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 48\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 49\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 50\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 51\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 52\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 53\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 54\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 55\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 56\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 57\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 58\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 59\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 60\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 61\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 62\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 63\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 64\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 65\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 66\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 67\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 68\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 69\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 70\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 71\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 72\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 73\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 74\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 75\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 76\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 77\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 78\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 79\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 80\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 81\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 82\n",
            "Fitness    = [5.191852]\n",
            "Change     = [0.]\n",
            "Generation = 83\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.08599854]\n",
            "Generation = 84\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 85\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 86\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 87\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 88\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 89\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 90\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 91\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 92\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 93\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 94\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 95\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 96\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 97\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 98\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 99\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n",
            "Generation = 100\n",
            "Fitness    = [5.2778506]\n",
            "Change     = [0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pygad/pygad.py:3105: UserWarning: Please use the plot_fitness() method instead of plot_result(). The plot_result() method will be removed in the future.\n",
            "  warnings.warn(\"Please use the plot_fitness() method instead of plot_result(). The plot_result() method will be removed in the future.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters of the best solution : [11.62348231  8.10222253 79.02534538 69.614333    4.28675371]\n",
            "Fitness value of the best solution = [0.18947107]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agXzkUOypjH7",
        "outputId": "2b30f959-b0cb-44aa-fa9f-167a3b8eb3c8"
      },
      "source": [
        "new=[5]\n",
        "mean1=tf.divide((new-x_mean[4]),x_std[4])\n",
        "print(mean1)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([-0.39195853], shape=(1,), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJMMv6-sr6DV",
        "outputId": "040ffa50-eeab-423f-d7db-193f1d89bac4"
      },
      "source": [
        "print(x_mean[0])\n",
        "print(x_std[0])\n",
        "print(new-x_mean[0])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.109243697478991\n",
            "0.6583646146487695\n",
            "[-1.1092437]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ditIDNAsmQN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PmR6m3-TolOM",
        "outputId": "25505ef7-5f20-44c2-8911-acc86f00ab96"
      },
      "source": [
        "#group 1\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# upload the data base at the certain path\n",
        "data = pd.read_csv('/content/traincmp.csv')\n",
        "\n",
        "\n",
        "x = data.loc[0:119, ['A','B','C','D','E']]\n",
        "x =np.array(x)\n",
        "x_mean = np.mean(x,axis=0)\n",
        "x_std = np.std(x,axis=0)\n",
        "x = (x-x_mean)/x_std\n",
        "x_test = x[110:119,:]\n",
        "x = x [0:110,:]\n",
        "\n",
        "\n",
        "y = data.loc[0:119, ['target']]\n",
        "y=np.array(y)\n",
        "y_target= y[110:119,:]\n",
        "y_mean = np.mean(y,axis=0)\n",
        "y_std = np.std(y,axis=0)\n",
        "y = (y-y_mean)/y_std\n",
        "y = y [0:110,:]\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(3)\n",
        "np.random.shuffle(x)\n",
        "np.random.seed(3)\n",
        "np.random.shuffle(y)\n",
        "\n",
        "x_train = x[0:100,:]\n",
        "x_val = x[100:110,:]\n",
        "y_train = y[0:100,:]\n",
        "y_val = y[100:110,:]\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(5,1)),\n",
        "        tf.keras.layers.Dense(38, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(41, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(19, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(35, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "#SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
        "#RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)\n",
        "#Adagrad(lr=0.01, epsilon=1e-06)\n",
        "#Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "          loss='mae',\n",
        "          metrics=['mae'])\n",
        "\n",
        "history=model.fit(x_train, y_train, batch_size=16, epochs=300, validation_data=(x_val,y_val), validation_freq=1, shuffle=False)\n",
        "#history=model.fit(x_train, y_train, batch_size=16, epochs=200, validation_split=0.2, validation_freq=1,shuffle=False)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "epochs = len(history.history['loss'])\n",
        "plt.plot(np.arange(len(history.history['loss'])),history.history['loss'],label='training')\n",
        "plt.plot(np.arange(len(history.history['val_loss'])),history.history['val_loss'],label='validation')\n",
        "plt.legend(fontsize=10)\n",
        "plt.title('learning curve',fontsize=15)\n",
        "plt.xlabel('iteration',fontsize=15)\n",
        "plt.ylabel('error',fontsize=15)\n",
        "plt.show()\n",
        "y_test=model(x_test)\n",
        "y_mid= tf.multiply(y_test,y_std)\n",
        "y_test= tf.add(y_mid, y_mean)\n",
        "error= tf.abs(tf.subtract(y_test, y_target))\n",
        "error_percentage = tf.divide(error, y_target)\n",
        "print(error)\n",
        "print(error_percentage)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "7/7 [==============================] - 1s 32ms/step - loss: 0.8240 - mae: 0.8240 - val_loss: 0.9711 - val_mae: 0.9711\n",
            "Epoch 2/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.7710 - mae: 0.7710 - val_loss: 0.9431 - val_mae: 0.9431\n",
            "Epoch 3/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6906 - mae: 0.6906 - val_loss: 0.9131 - val_mae: 0.9131\n",
            "Epoch 4/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6271 - mae: 0.6271 - val_loss: 0.8747 - val_mae: 0.8747\n",
            "Epoch 5/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.5830 - mae: 0.5830 - val_loss: 0.8248 - val_mae: 0.8248\n",
            "Epoch 6/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5727 - mae: 0.5727 - val_loss: 0.8028 - val_mae: 0.8028\n",
            "Epoch 7/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5542 - mae: 0.5542 - val_loss: 0.7886 - val_mae: 0.7886\n",
            "Epoch 8/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5212 - mae: 0.5212 - val_loss: 0.7736 - val_mae: 0.7736\n",
            "Epoch 9/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5170 - mae: 0.5170 - val_loss: 0.7558 - val_mae: 0.7558\n",
            "Epoch 10/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5072 - mae: 0.5072 - val_loss: 0.7275 - val_mae: 0.7275\n",
            "Epoch 11/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4995 - mae: 0.4995 - val_loss: 0.7053 - val_mae: 0.7053\n",
            "Epoch 12/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4528 - mae: 0.4528 - val_loss: 0.6712 - val_mae: 0.6712\n",
            "Epoch 13/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4035 - mae: 0.4035 - val_loss: 0.6328 - val_mae: 0.6328\n",
            "Epoch 14/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3942 - mae: 0.3942 - val_loss: 0.5954 - val_mae: 0.5954\n",
            "Epoch 15/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3733 - mae: 0.3733 - val_loss: 0.5702 - val_mae: 0.5702\n",
            "Epoch 16/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3596 - mae: 0.3596 - val_loss: 0.5807 - val_mae: 0.5807\n",
            "Epoch 17/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3172 - mae: 0.3172 - val_loss: 0.5603 - val_mae: 0.5603\n",
            "Epoch 18/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2773 - mae: 0.2773 - val_loss: 0.5430 - val_mae: 0.5430\n",
            "Epoch 19/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.3159 - mae: 0.3159 - val_loss: 0.5731 - val_mae: 0.5731\n",
            "Epoch 20/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3068 - mae: 0.3068 - val_loss: 0.5480 - val_mae: 0.5480\n",
            "Epoch 21/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.3439 - mae: 0.3439 - val_loss: 0.5011 - val_mae: 0.5011\n",
            "Epoch 22/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.3053 - mae: 0.3053 - val_loss: 0.4814 - val_mae: 0.4814\n",
            "Epoch 23/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.2379 - mae: 0.2379 - val_loss: 0.5075 - val_mae: 0.5075\n",
            "Epoch 24/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2697 - mae: 0.2697 - val_loss: 0.5188 - val_mae: 0.5188\n",
            "Epoch 25/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2628 - mae: 0.2628 - val_loss: 0.4751 - val_mae: 0.4751\n",
            "Epoch 26/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2496 - mae: 0.2496 - val_loss: 0.4509 - val_mae: 0.4509\n",
            "Epoch 27/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.2524 - mae: 0.2524 - val_loss: 0.3948 - val_mae: 0.3948\n",
            "Epoch 28/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2695 - mae: 0.2695 - val_loss: 0.4105 - val_mae: 0.4105\n",
            "Epoch 29/300\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.2906 - mae: 0.2906 - val_loss: 0.4113 - val_mae: 0.4113\n",
            "Epoch 30/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2553 - mae: 0.2553 - val_loss: 0.3973 - val_mae: 0.3973\n",
            "Epoch 31/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2896 - mae: 0.2896 - val_loss: 0.3958 - val_mae: 0.3958\n",
            "Epoch 32/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2533 - mae: 0.2533 - val_loss: 0.4266 - val_mae: 0.4266\n",
            "Epoch 33/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2518 - mae: 0.2518 - val_loss: 0.3984 - val_mae: 0.3984\n",
            "Epoch 34/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2942 - mae: 0.2942 - val_loss: 0.3617 - val_mae: 0.3617\n",
            "Epoch 35/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2659 - mae: 0.2659 - val_loss: 0.4120 - val_mae: 0.4120\n",
            "Epoch 36/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2350 - mae: 0.2350 - val_loss: 0.4256 - val_mae: 0.4256\n",
            "Epoch 37/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2277 - mae: 0.2277 - val_loss: 0.3694 - val_mae: 0.3694\n",
            "Epoch 38/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2349 - mae: 0.2349 - val_loss: 0.4274 - val_mae: 0.4274\n",
            "Epoch 39/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2534 - mae: 0.2534 - val_loss: 0.4451 - val_mae: 0.4451\n",
            "Epoch 40/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2521 - mae: 0.2521 - val_loss: 0.3788 - val_mae: 0.3788\n",
            "Epoch 41/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2158 - mae: 0.2158 - val_loss: 0.3604 - val_mae: 0.3604\n",
            "Epoch 42/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2223 - mae: 0.2223 - val_loss: 0.3630 - val_mae: 0.3630\n",
            "Epoch 43/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2375 - mae: 0.2375 - val_loss: 0.3931 - val_mae: 0.3931\n",
            "Epoch 44/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2555 - mae: 0.2555 - val_loss: 0.3747 - val_mae: 0.3747\n",
            "Epoch 45/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.3152 - val_mae: 0.3152\n",
            "Epoch 46/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2240 - mae: 0.2240 - val_loss: 0.3626 - val_mae: 0.3626\n",
            "Epoch 47/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2268 - mae: 0.2268 - val_loss: 0.4399 - val_mae: 0.4399\n",
            "Epoch 48/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2298 - mae: 0.2298 - val_loss: 0.3512 - val_mae: 0.3512\n",
            "Epoch 49/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2180 - mae: 0.2180 - val_loss: 0.3473 - val_mae: 0.3473\n",
            "Epoch 50/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2383 - mae: 0.2383 - val_loss: 0.3858 - val_mae: 0.3858\n",
            "Epoch 51/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1962 - mae: 0.1962 - val_loss: 0.3641 - val_mae: 0.3641\n",
            "Epoch 52/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2067 - mae: 0.2067 - val_loss: 0.3366 - val_mae: 0.3366\n",
            "Epoch 53/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2132 - mae: 0.2132 - val_loss: 0.3115 - val_mae: 0.3115\n",
            "Epoch 54/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2257 - mae: 0.2257 - val_loss: 0.2938 - val_mae: 0.2938\n",
            "Epoch 55/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2081 - mae: 0.2081 - val_loss: 0.3164 - val_mae: 0.3164\n",
            "Epoch 56/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2098 - mae: 0.2098 - val_loss: 0.3616 - val_mae: 0.3616\n",
            "Epoch 57/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2318 - mae: 0.2318 - val_loss: 0.3777 - val_mae: 0.3777\n",
            "Epoch 58/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1932 - mae: 0.1932 - val_loss: 0.3774 - val_mae: 0.3774\n",
            "Epoch 59/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1856 - mae: 0.1856 - val_loss: 0.3539 - val_mae: 0.3539\n",
            "Epoch 60/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2229 - mae: 0.2229 - val_loss: 0.3393 - val_mae: 0.3393\n",
            "Epoch 61/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1910 - mae: 0.1910 - val_loss: 0.2852 - val_mae: 0.2852\n",
            "Epoch 62/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2234 - mae: 0.2234 - val_loss: 0.2811 - val_mae: 0.2811\n",
            "Epoch 63/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2030 - mae: 0.2030 - val_loss: 0.3269 - val_mae: 0.3269\n",
            "Epoch 64/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2097 - mae: 0.2097 - val_loss: 0.3150 - val_mae: 0.3150\n",
            "Epoch 65/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2103 - mae: 0.2103 - val_loss: 0.3459 - val_mae: 0.3459\n",
            "Epoch 66/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1936 - mae: 0.1936 - val_loss: 0.3124 - val_mae: 0.3124\n",
            "Epoch 67/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1684 - mae: 0.1684 - val_loss: 0.2867 - val_mae: 0.2867\n",
            "Epoch 68/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1968 - mae: 0.1968 - val_loss: 0.3212 - val_mae: 0.3212\n",
            "Epoch 69/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1997 - mae: 0.1997 - val_loss: 0.3137 - val_mae: 0.3137\n",
            "Epoch 70/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1969 - mae: 0.1969 - val_loss: 0.2975 - val_mae: 0.2975\n",
            "Epoch 71/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1710 - mae: 0.1710 - val_loss: 0.2758 - val_mae: 0.2758\n",
            "Epoch 72/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1886 - mae: 0.1886 - val_loss: 0.2781 - val_mae: 0.2781\n",
            "Epoch 73/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2078 - mae: 0.2078 - val_loss: 0.2814 - val_mae: 0.2814\n",
            "Epoch 74/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1564 - mae: 0.1564 - val_loss: 0.2766 - val_mae: 0.2766\n",
            "Epoch 75/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1848 - mae: 0.1848 - val_loss: 0.2903 - val_mae: 0.2903\n",
            "Epoch 76/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1925 - mae: 0.1925 - val_loss: 0.2890 - val_mae: 0.2890\n",
            "Epoch 77/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2191 - mae: 0.2191 - val_loss: 0.2645 - val_mae: 0.2645\n",
            "Epoch 78/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1991 - mae: 0.1991 - val_loss: 0.2690 - val_mae: 0.2690\n",
            "Epoch 79/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1816 - mae: 0.1816 - val_loss: 0.2921 - val_mae: 0.2921\n",
            "Epoch 80/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1854 - mae: 0.1854 - val_loss: 0.2794 - val_mae: 0.2794\n",
            "Epoch 81/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1893 - mae: 0.1893 - val_loss: 0.2686 - val_mae: 0.2686\n",
            "Epoch 82/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2134 - mae: 0.2134 - val_loss: 0.2458 - val_mae: 0.2458\n",
            "Epoch 83/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1668 - mae: 0.1668 - val_loss: 0.2664 - val_mae: 0.2664\n",
            "Epoch 84/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2450 - mae: 0.2450 - val_loss: 0.2669 - val_mae: 0.2669\n",
            "Epoch 85/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2039 - mae: 0.2039 - val_loss: 0.2731 - val_mae: 0.2731\n",
            "Epoch 86/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1824 - mae: 0.1824 - val_loss: 0.2757 - val_mae: 0.2757\n",
            "Epoch 87/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.2603 - val_mae: 0.2603\n",
            "Epoch 88/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1769 - mae: 0.1769 - val_loss: 0.2622 - val_mae: 0.2622\n",
            "Epoch 89/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1820 - mae: 0.1820 - val_loss: 0.2701 - val_mae: 0.2701\n",
            "Epoch 90/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1538 - mae: 0.1538 - val_loss: 0.2597 - val_mae: 0.2597\n",
            "Epoch 91/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1589 - mae: 0.1589 - val_loss: 0.2512 - val_mae: 0.2512\n",
            "Epoch 92/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1658 - mae: 0.1658 - val_loss: 0.2878 - val_mae: 0.2878\n",
            "Epoch 93/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1882 - mae: 0.1882 - val_loss: 0.2625 - val_mae: 0.2625\n",
            "Epoch 94/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1854 - mae: 0.1854 - val_loss: 0.2547 - val_mae: 0.2547\n",
            "Epoch 95/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1717 - mae: 0.1717 - val_loss: 0.2659 - val_mae: 0.2659\n",
            "Epoch 96/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1874 - mae: 0.1874 - val_loss: 0.2594 - val_mae: 0.2594\n",
            "Epoch 97/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1823 - mae: 0.1823 - val_loss: 0.2340 - val_mae: 0.2340\n",
            "Epoch 98/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1572 - mae: 0.1572 - val_loss: 0.2409 - val_mae: 0.2409\n",
            "Epoch 99/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1609 - mae: 0.1609 - val_loss: 0.2876 - val_mae: 0.2876\n",
            "Epoch 100/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2076 - mae: 0.2076 - val_loss: 0.2614 - val_mae: 0.2614\n",
            "Epoch 101/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1647 - mae: 0.1647 - val_loss: 0.2423 - val_mae: 0.2423\n",
            "Epoch 102/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1826 - mae: 0.1826 - val_loss: 0.2298 - val_mae: 0.2298\n",
            "Epoch 103/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1346 - mae: 0.1346 - val_loss: 0.2507 - val_mae: 0.2507\n",
            "Epoch 104/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1692 - mae: 0.1692 - val_loss: 0.2522 - val_mae: 0.2522\n",
            "Epoch 105/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1866 - mae: 0.1866 - val_loss: 0.2554 - val_mae: 0.2554\n",
            "Epoch 106/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1862 - mae: 0.1862 - val_loss: 0.2478 - val_mae: 0.2478\n",
            "Epoch 107/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1834 - mae: 0.1834 - val_loss: 0.2509 - val_mae: 0.2509\n",
            "Epoch 108/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1899 - mae: 0.1899 - val_loss: 0.2335 - val_mae: 0.2335\n",
            "Epoch 109/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1861 - mae: 0.1861 - val_loss: 0.2548 - val_mae: 0.2548\n",
            "Epoch 110/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1633 - mae: 0.1633 - val_loss: 0.2489 - val_mae: 0.2489\n",
            "Epoch 111/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1555 - mae: 0.1555 - val_loss: 0.2503 - val_mae: 0.2503\n",
            "Epoch 112/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1841 - mae: 0.1841 - val_loss: 0.2329 - val_mae: 0.2329\n",
            "Epoch 113/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1747 - mae: 0.1747 - val_loss: 0.2570 - val_mae: 0.2570\n",
            "Epoch 114/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1534 - mae: 0.1534 - val_loss: 0.2408 - val_mae: 0.2408\n",
            "Epoch 115/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1715 - mae: 0.1715 - val_loss: 0.2473 - val_mae: 0.2473\n",
            "Epoch 116/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2113 - mae: 0.2113 - val_loss: 0.2961 - val_mae: 0.2961\n",
            "Epoch 117/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1853 - mae: 0.1853 - val_loss: 0.2609 - val_mae: 0.2609\n",
            "Epoch 118/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1901 - mae: 0.1901 - val_loss: 0.2648 - val_mae: 0.2648\n",
            "Epoch 119/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2005 - mae: 0.2005 - val_loss: 0.2573 - val_mae: 0.2573\n",
            "Epoch 120/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1687 - mae: 0.1687 - val_loss: 0.2575 - val_mae: 0.2575\n",
            "Epoch 121/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1541 - mae: 0.1541 - val_loss: 0.2683 - val_mae: 0.2683\n",
            "Epoch 122/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1588 - mae: 0.1588 - val_loss: 0.2720 - val_mae: 0.2720\n",
            "Epoch 123/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1642 - mae: 0.1642 - val_loss: 0.2522 - val_mae: 0.2522\n",
            "Epoch 124/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1891 - mae: 0.1891 - val_loss: 0.2623 - val_mae: 0.2623\n",
            "Epoch 125/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1700 - mae: 0.1700 - val_loss: 0.2820 - val_mae: 0.2820\n",
            "Epoch 126/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1609 - mae: 0.1609 - val_loss: 0.2642 - val_mae: 0.2642\n",
            "Epoch 127/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1657 - mae: 0.1657 - val_loss: 0.2644 - val_mae: 0.2644\n",
            "Epoch 128/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1727 - mae: 0.1727 - val_loss: 0.2722 - val_mae: 0.2722\n",
            "Epoch 129/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1900 - mae: 0.1900 - val_loss: 0.3168 - val_mae: 0.3168\n",
            "Epoch 130/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1682 - mae: 0.1682 - val_loss: 0.2856 - val_mae: 0.2856\n",
            "Epoch 131/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1628 - mae: 0.1628 - val_loss: 0.2289 - val_mae: 0.2289\n",
            "Epoch 132/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1720 - mae: 0.1720 - val_loss: 0.2253 - val_mae: 0.2253\n",
            "Epoch 133/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1730 - mae: 0.1730 - val_loss: 0.2372 - val_mae: 0.2372\n",
            "Epoch 134/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1789 - mae: 0.1789 - val_loss: 0.2403 - val_mae: 0.2403\n",
            "Epoch 135/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1580 - mae: 0.1580 - val_loss: 0.2264 - val_mae: 0.2264\n",
            "Epoch 136/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1900 - mae: 0.1900 - val_loss: 0.2130 - val_mae: 0.2130\n",
            "Epoch 137/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1923 - mae: 0.1923 - val_loss: 0.2316 - val_mae: 0.2316\n",
            "Epoch 138/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1657 - mae: 0.1657 - val_loss: 0.2690 - val_mae: 0.2690\n",
            "Epoch 139/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1764 - mae: 0.1764 - val_loss: 0.2835 - val_mae: 0.2835\n",
            "Epoch 140/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1667 - mae: 0.1667 - val_loss: 0.2445 - val_mae: 0.2445\n",
            "Epoch 141/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1865 - mae: 0.1865 - val_loss: 0.2457 - val_mae: 0.2457\n",
            "Epoch 142/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1818 - mae: 0.1818 - val_loss: 0.2495 - val_mae: 0.2495\n",
            "Epoch 143/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1670 - mae: 0.1670 - val_loss: 0.2437 - val_mae: 0.2437\n",
            "Epoch 144/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1818 - mae: 0.1818 - val_loss: 0.2529 - val_mae: 0.2529\n",
            "Epoch 145/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1834 - mae: 0.1834 - val_loss: 0.2603 - val_mae: 0.2603\n",
            "Epoch 146/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1809 - mae: 0.1809 - val_loss: 0.2342 - val_mae: 0.2342\n",
            "Epoch 147/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1725 - mae: 0.1725 - val_loss: 0.2417 - val_mae: 0.2417\n",
            "Epoch 148/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2080 - mae: 0.2080 - val_loss: 0.2498 - val_mae: 0.2498\n",
            "Epoch 149/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1627 - mae: 0.1627 - val_loss: 0.2545 - val_mae: 0.2545\n",
            "Epoch 150/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1625 - mae: 0.1625 - val_loss: 0.2231 - val_mae: 0.2231\n",
            "Epoch 151/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1890 - mae: 0.1890 - val_loss: 0.2273 - val_mae: 0.2273\n",
            "Epoch 152/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1611 - mae: 0.1611 - val_loss: 0.2368 - val_mae: 0.2368\n",
            "Epoch 153/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1829 - mae: 0.1829 - val_loss: 0.2309 - val_mae: 0.2309\n",
            "Epoch 154/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1775 - mae: 0.1775 - val_loss: 0.2282 - val_mae: 0.2282\n",
            "Epoch 155/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1828 - mae: 0.1828 - val_loss: 0.2222 - val_mae: 0.2222\n",
            "Epoch 156/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1563 - mae: 0.1563 - val_loss: 0.2379 - val_mae: 0.2379\n",
            "Epoch 157/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1709 - mae: 0.1709 - val_loss: 0.2344 - val_mae: 0.2344\n",
            "Epoch 158/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1939 - mae: 0.1939 - val_loss: 0.2176 - val_mae: 0.2176\n",
            "Epoch 159/300\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1735 - mae: 0.1735 - val_loss: 0.2627 - val_mae: 0.2627\n",
            "Epoch 160/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1428 - mae: 0.1428 - val_loss: 0.2881 - val_mae: 0.2881\n",
            "Epoch 161/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2046 - mae: 0.2046 - val_loss: 0.2244 - val_mae: 0.2244\n",
            "Epoch 162/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1931 - mae: 0.1931 - val_loss: 0.2236 - val_mae: 0.2236\n",
            "Epoch 163/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1995 - mae: 0.1995 - val_loss: 0.2596 - val_mae: 0.2596\n",
            "Epoch 164/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1749 - mae: 0.1749 - val_loss: 0.2634 - val_mae: 0.2634\n",
            "Epoch 165/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1565 - mae: 0.1565 - val_loss: 0.2555 - val_mae: 0.2555\n",
            "Epoch 166/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.2366 - val_mae: 0.2366\n",
            "Epoch 167/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1646 - mae: 0.1646 - val_loss: 0.2413 - val_mae: 0.2413\n",
            "Epoch 168/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1320 - mae: 0.1320 - val_loss: 0.2717 - val_mae: 0.2717\n",
            "Epoch 169/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1843 - mae: 0.1843 - val_loss: 0.2981 - val_mae: 0.2981\n",
            "Epoch 170/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1814 - mae: 0.1814 - val_loss: 0.2533 - val_mae: 0.2533\n",
            "Epoch 171/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1589 - mae: 0.1589 - val_loss: 0.2281 - val_mae: 0.2281\n",
            "Epoch 172/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1274 - mae: 0.1274 - val_loss: 0.2302 - val_mae: 0.2302\n",
            "Epoch 173/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1460 - mae: 0.1460 - val_loss: 0.2330 - val_mae: 0.2330\n",
            "Epoch 174/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1634 - mae: 0.1634 - val_loss: 0.2324 - val_mae: 0.2324\n",
            "Epoch 175/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1949 - mae: 0.1949 - val_loss: 0.2230 - val_mae: 0.2230\n",
            "Epoch 176/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1341 - mae: 0.1341 - val_loss: 0.2361 - val_mae: 0.2361\n",
            "Epoch 177/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1594 - mae: 0.1594 - val_loss: 0.2252 - val_mae: 0.2252\n",
            "Epoch 178/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1507 - mae: 0.1507 - val_loss: 0.2310 - val_mae: 0.2310\n",
            "Epoch 179/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1405 - mae: 0.1405 - val_loss: 0.2565 - val_mae: 0.2565\n",
            "Epoch 180/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2032 - mae: 0.2032 - val_loss: 0.2346 - val_mae: 0.2346\n",
            "Epoch 181/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1506 - mae: 0.1506 - val_loss: 0.2181 - val_mae: 0.2181\n",
            "Epoch 182/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1251 - mae: 0.1251 - val_loss: 0.2148 - val_mae: 0.2148\n",
            "Epoch 183/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1872 - mae: 0.1872 - val_loss: 0.2423 - val_mae: 0.2423\n",
            "Epoch 184/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1258 - mae: 0.1258 - val_loss: 0.2701 - val_mae: 0.2701\n",
            "Epoch 185/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1694 - mae: 0.1694 - val_loss: 0.2364 - val_mae: 0.2364\n",
            "Epoch 186/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1650 - mae: 0.1650 - val_loss: 0.2505 - val_mae: 0.2505\n",
            "Epoch 187/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1493 - mae: 0.1493 - val_loss: 0.2962 - val_mae: 0.2962\n",
            "Epoch 188/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1659 - mae: 0.1659 - val_loss: 0.2719 - val_mae: 0.2719\n",
            "Epoch 189/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1627 - mae: 0.1627 - val_loss: 0.2590 - val_mae: 0.2590\n",
            "Epoch 190/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1553 - mae: 0.1553 - val_loss: 0.2480 - val_mae: 0.2480\n",
            "Epoch 191/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1826 - mae: 0.1826 - val_loss: 0.2338 - val_mae: 0.2338\n",
            "Epoch 192/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1517 - mae: 0.1517 - val_loss: 0.2484 - val_mae: 0.2484\n",
            "Epoch 193/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1764 - mae: 0.1764 - val_loss: 0.2672 - val_mae: 0.2672\n",
            "Epoch 194/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1621 - mae: 0.1621 - val_loss: 0.2385 - val_mae: 0.2385\n",
            "Epoch 195/300\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1544 - mae: 0.1544 - val_loss: 0.2264 - val_mae: 0.2264\n",
            "Epoch 196/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1815 - mae: 0.1815 - val_loss: 0.2543 - val_mae: 0.2543\n",
            "Epoch 197/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1556 - mae: 0.1556 - val_loss: 0.2364 - val_mae: 0.2364\n",
            "Epoch 198/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1709 - mae: 0.1709 - val_loss: 0.2319 - val_mae: 0.2319\n",
            "Epoch 199/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1607 - mae: 0.1607 - val_loss: 0.2374 - val_mae: 0.2374\n",
            "Epoch 200/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1691 - mae: 0.1691 - val_loss: 0.2247 - val_mae: 0.2247\n",
            "Epoch 201/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1482 - mae: 0.1482 - val_loss: 0.2182 - val_mae: 0.2182\n",
            "Epoch 202/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1520 - mae: 0.1520 - val_loss: 0.2207 - val_mae: 0.2207\n",
            "Epoch 203/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1528 - mae: 0.1528 - val_loss: 0.2240 - val_mae: 0.2240\n",
            "Epoch 204/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1888 - mae: 0.1888 - val_loss: 0.2341 - val_mae: 0.2341\n",
            "Epoch 205/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1558 - mae: 0.1558 - val_loss: 0.2385 - val_mae: 0.2385\n",
            "Epoch 206/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1604 - mae: 0.1604 - val_loss: 0.2279 - val_mae: 0.2279\n",
            "Epoch 207/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1544 - mae: 0.1544 - val_loss: 0.2368 - val_mae: 0.2368\n",
            "Epoch 208/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1971 - mae: 0.1971 - val_loss: 0.2346 - val_mae: 0.2346\n",
            "Epoch 209/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1538 - mae: 0.1538 - val_loss: 0.2506 - val_mae: 0.2506\n",
            "Epoch 210/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1713 - mae: 0.1713 - val_loss: 0.2418 - val_mae: 0.2418\n",
            "Epoch 211/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1683 - mae: 0.1683 - val_loss: 0.2282 - val_mae: 0.2282\n",
            "Epoch 212/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1845 - mae: 0.1845 - val_loss: 0.2355 - val_mae: 0.2355\n",
            "Epoch 213/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1613 - mae: 0.1613 - val_loss: 0.2397 - val_mae: 0.2397\n",
            "Epoch 214/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1504 - mae: 0.1504 - val_loss: 0.2377 - val_mae: 0.2377\n",
            "Epoch 215/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1805 - mae: 0.1805 - val_loss: 0.2385 - val_mae: 0.2385\n",
            "Epoch 216/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1636 - mae: 0.1636 - val_loss: 0.2480 - val_mae: 0.2480\n",
            "Epoch 217/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1675 - mae: 0.1675 - val_loss: 0.2389 - val_mae: 0.2389\n",
            "Epoch 218/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1633 - mae: 0.1633 - val_loss: 0.2645 - val_mae: 0.2645\n",
            "Epoch 219/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1792 - mae: 0.1792 - val_loss: 0.2579 - val_mae: 0.2579\n",
            "Epoch 220/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1663 - mae: 0.1663 - val_loss: 0.2663 - val_mae: 0.2663\n",
            "Epoch 221/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1927 - mae: 0.1927 - val_loss: 0.2724 - val_mae: 0.2724\n",
            "Epoch 222/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1504 - mae: 0.1504 - val_loss: 0.2481 - val_mae: 0.2481\n",
            "Epoch 223/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1931 - mae: 0.1931 - val_loss: 0.2412 - val_mae: 0.2412\n",
            "Epoch 224/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1628 - mae: 0.1628 - val_loss: 0.2523 - val_mae: 0.2523\n",
            "Epoch 225/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1573 - mae: 0.1573 - val_loss: 0.2254 - val_mae: 0.2254\n",
            "Epoch 226/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1456 - mae: 0.1456 - val_loss: 0.2517 - val_mae: 0.2517\n",
            "Epoch 227/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1669 - mae: 0.1669 - val_loss: 0.2547 - val_mae: 0.2547\n",
            "Epoch 228/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1454 - mae: 0.1454 - val_loss: 0.2608 - val_mae: 0.2608\n",
            "Epoch 229/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1524 - mae: 0.1524 - val_loss: 0.2425 - val_mae: 0.2425\n",
            "Epoch 230/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1931 - mae: 0.1931 - val_loss: 0.2305 - val_mae: 0.2305\n",
            "Epoch 231/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1666 - mae: 0.1666 - val_loss: 0.2344 - val_mae: 0.2344\n",
            "Epoch 232/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1608 - mae: 0.1608 - val_loss: 0.2216 - val_mae: 0.2216\n",
            "Epoch 233/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1507 - mae: 0.1507 - val_loss: 0.2227 - val_mae: 0.2227\n",
            "Epoch 234/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1583 - mae: 0.1583 - val_loss: 0.2155 - val_mae: 0.2155\n",
            "Epoch 235/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1708 - mae: 0.1708 - val_loss: 0.2315 - val_mae: 0.2315\n",
            "Epoch 236/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1493 - mae: 0.1493 - val_loss: 0.2438 - val_mae: 0.2438\n",
            "Epoch 237/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1458 - mae: 0.1458 - val_loss: 0.2612 - val_mae: 0.2612\n",
            "Epoch 238/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1593 - mae: 0.1593 - val_loss: 0.2801 - val_mae: 0.2801\n",
            "Epoch 239/300\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1906 - mae: 0.1906 - val_loss: 0.2406 - val_mae: 0.2406\n",
            "Epoch 240/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1585 - mae: 0.1585 - val_loss: 0.2448 - val_mae: 0.2448\n",
            "Epoch 241/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1703 - mae: 0.1703 - val_loss: 0.2568 - val_mae: 0.2568\n",
            "Epoch 242/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1759 - mae: 0.1759 - val_loss: 0.2552 - val_mae: 0.2552\n",
            "Epoch 243/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1990 - mae: 0.1990 - val_loss: 0.2194 - val_mae: 0.2194\n",
            "Epoch 244/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1411 - mae: 0.1411 - val_loss: 0.2437 - val_mae: 0.2437\n",
            "Epoch 245/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1865 - mae: 0.1865 - val_loss: 0.2752 - val_mae: 0.2752\n",
            "Epoch 246/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1685 - mae: 0.1685 - val_loss: 0.2755 - val_mae: 0.2755\n",
            "Epoch 247/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1811 - mae: 0.1811 - val_loss: 0.2428 - val_mae: 0.2428\n",
            "Epoch 248/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1411 - mae: 0.1411 - val_loss: 0.2335 - val_mae: 0.2335\n",
            "Epoch 249/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1615 - mae: 0.1615 - val_loss: 0.2268 - val_mae: 0.2268\n",
            "Epoch 250/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1547 - mae: 0.1547 - val_loss: 0.2056 - val_mae: 0.2056\n",
            "Epoch 251/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1541 - mae: 0.1541 - val_loss: 0.2320 - val_mae: 0.2320\n",
            "Epoch 252/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1685 - mae: 0.1685 - val_loss: 0.2602 - val_mae: 0.2602\n",
            "Epoch 253/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1483 - mae: 0.1483 - val_loss: 0.2648 - val_mae: 0.2648\n",
            "Epoch 254/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1652 - mae: 0.1652 - val_loss: 0.2806 - val_mae: 0.2806\n",
            "Epoch 255/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1470 - mae: 0.1470 - val_loss: 0.2678 - val_mae: 0.2678\n",
            "Epoch 256/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1805 - mae: 0.1805 - val_loss: 0.2453 - val_mae: 0.2453\n",
            "Epoch 257/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1840 - mae: 0.1840 - val_loss: 0.2342 - val_mae: 0.2342\n",
            "Epoch 258/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1497 - mae: 0.1497 - val_loss: 0.2323 - val_mae: 0.2323\n",
            "Epoch 259/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1388 - mae: 0.1388 - val_loss: 0.2267 - val_mae: 0.2267\n",
            "Epoch 260/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1455 - mae: 0.1455 - val_loss: 0.2130 - val_mae: 0.2130\n",
            "Epoch 261/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1652 - mae: 0.1652 - val_loss: 0.2020 - val_mae: 0.2020\n",
            "Epoch 262/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1476 - mae: 0.1476 - val_loss: 0.2282 - val_mae: 0.2282\n",
            "Epoch 263/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1694 - mae: 0.1694 - val_loss: 0.2280 - val_mae: 0.2280\n",
            "Epoch 264/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1799 - mae: 0.1799 - val_loss: 0.2374 - val_mae: 0.2374\n",
            "Epoch 265/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1575 - mae: 0.1575 - val_loss: 0.2222 - val_mae: 0.2222\n",
            "Epoch 266/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1349 - mae: 0.1349 - val_loss: 0.2290 - val_mae: 0.2290\n",
            "Epoch 267/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1537 - mae: 0.1537 - val_loss: 0.2082 - val_mae: 0.2082\n",
            "Epoch 268/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1411 - mae: 0.1411 - val_loss: 0.2121 - val_mae: 0.2121\n",
            "Epoch 269/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1676 - mae: 0.1676 - val_loss: 0.2347 - val_mae: 0.2347\n",
            "Epoch 270/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1640 - mae: 0.1640 - val_loss: 0.2076 - val_mae: 0.2076\n",
            "Epoch 271/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1644 - mae: 0.1644 - val_loss: 0.2205 - val_mae: 0.2205\n",
            "Epoch 272/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1837 - mae: 0.1837 - val_loss: 0.2102 - val_mae: 0.2102\n",
            "Epoch 273/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1408 - mae: 0.1408 - val_loss: 0.2111 - val_mae: 0.2111\n",
            "Epoch 274/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1451 - mae: 0.1451 - val_loss: 0.2212 - val_mae: 0.2212\n",
            "Epoch 275/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1555 - mae: 0.1555 - val_loss: 0.2209 - val_mae: 0.2209\n",
            "Epoch 276/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1398 - mae: 0.1398 - val_loss: 0.2189 - val_mae: 0.2189\n",
            "Epoch 277/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1448 - mae: 0.1448 - val_loss: 0.2102 - val_mae: 0.2102\n",
            "Epoch 278/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1645 - mae: 0.1645 - val_loss: 0.2089 - val_mae: 0.2089\n",
            "Epoch 279/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1570 - mae: 0.1570 - val_loss: 0.2158 - val_mae: 0.2158\n",
            "Epoch 280/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1925 - mae: 0.1925 - val_loss: 0.2149 - val_mae: 0.2149\n",
            "Epoch 281/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1549 - mae: 0.1549 - val_loss: 0.2316 - val_mae: 0.2316\n",
            "Epoch 282/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.2469 - val_mae: 0.2469\n",
            "Epoch 283/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1929 - mae: 0.1929 - val_loss: 0.2302 - val_mae: 0.2302\n",
            "Epoch 284/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1562 - mae: 0.1562 - val_loss: 0.2355 - val_mae: 0.2355\n",
            "Epoch 285/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1681 - mae: 0.1681 - val_loss: 0.2658 - val_mae: 0.2658\n",
            "Epoch 286/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1915 - mae: 0.1915 - val_loss: 0.2416 - val_mae: 0.2416\n",
            "Epoch 287/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1235 - mae: 0.1235 - val_loss: 0.2282 - val_mae: 0.2282\n",
            "Epoch 288/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1605 - mae: 0.1605 - val_loss: 0.2455 - val_mae: 0.2455\n",
            "Epoch 289/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1691 - mae: 0.1691 - val_loss: 0.2336 - val_mae: 0.2336\n",
            "Epoch 290/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1387 - mae: 0.1387 - val_loss: 0.2082 - val_mae: 0.2082\n",
            "Epoch 291/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1299 - mae: 0.1299 - val_loss: 0.2055 - val_mae: 0.2055\n",
            "Epoch 292/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1441 - mae: 0.1441 - val_loss: 0.2065 - val_mae: 0.2065\n",
            "Epoch 293/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1443 - mae: 0.1443 - val_loss: 0.2146 - val_mae: 0.2146\n",
            "Epoch 294/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1936 - mae: 0.1936 - val_loss: 0.2339 - val_mae: 0.2339\n",
            "Epoch 295/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1545 - mae: 0.1545 - val_loss: 0.2375 - val_mae: 0.2375\n",
            "Epoch 296/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1639 - mae: 0.1639 - val_loss: 0.2253 - val_mae: 0.2253\n",
            "Epoch 297/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1645 - mae: 0.1645 - val_loss: 0.2235 - val_mae: 0.2235\n",
            "Epoch 298/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1701 - mae: 0.1701 - val_loss: 0.2224 - val_mae: 0.2224\n",
            "Epoch 299/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1138 - mae: 0.1138 - val_loss: 0.2245 - val_mae: 0.2245\n",
            "Epoch 300/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1503 - mae: 0.1503 - val_loss: 0.2094 - val_mae: 0.2094\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_15 (Flatten)         (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 38)                228       \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 41)                1599      \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 19)                798       \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 35)                700       \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 35)                0         \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 1)                 36        \n",
            "=================================================================\n",
            "Total params: 3,361\n",
            "Trainable params: 3,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[2.5887327 ]\n",
            " [0.74105096]\n",
            " [0.6631665 ]\n",
            " [0.46016312]\n",
            " [0.16847605]\n",
            " [0.7316115 ]\n",
            " [0.1498766 ]\n",
            " [0.5800476 ]\n",
            " [0.35225797]], shape=(9, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.15801336]\n",
            " [0.20028403]\n",
            " [0.13718794]\n",
            " [0.10080244]\n",
            " [0.26242372]\n",
            " [0.27016672]\n",
            " [0.09001598]\n",
            " [0.19360735]\n",
            " [0.12231179]], shape=(9, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn5Alh2tiGor",
        "outputId": "9337503c-8362-42e7-82b6-ecff013e830a"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[14.460794 ]\n",
            " [ 3.43695  ]\n",
            " [ 3.9952166]\n",
            " [ 3.7577956]\n",
            " [ 0.727005 ]\n",
            " [ 2.614872 ]\n",
            " [ 1.5745175]\n",
            " [ 3.0763388]\n",
            " [ 2.815491 ]], shape=(9, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11035
        },
        "id": "JXeisI4x6fey",
        "outputId": "a3498cb1-16e5-4535-d263-d56b5855dfd2"
      },
      "source": [
        "#group 2\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# upload the data base at the certain path\n",
        "data = pd.read_csv('/content/traincmp.csv')\n",
        "\n",
        "\n",
        "x = data.loc[0:119, ['A','B','C','D','E']]\n",
        "x =np.array(x)\n",
        "x_mean = np.mean(x,axis=0)\n",
        "x_std = np.std(x,axis=0)\n",
        "x = (x-x_mean)/x_std\n",
        "x_test = x[110:119,:]\n",
        "x = x [0:110,:]\n",
        "\n",
        "\n",
        "y = data.loc[0:119, ['target']]\n",
        "y=np.array(y)\n",
        "y_target= y[110:119,:]\n",
        "y_mean = np.mean(y,axis=0)\n",
        "y_std = np.std(y,axis=0)\n",
        "y = (y-y_mean)/y_std\n",
        "y = y [0:110,:]\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(3)\n",
        "np.random.shuffle(x)\n",
        "np.random.seed(3)\n",
        "np.random.shuffle(y)\n",
        "\n",
        "x_train = x[0:100,:]\n",
        "x_val = x[100:110,:]\n",
        "y_train = y[0:100,:]\n",
        "y_val = y[100:110,:]\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(5,1)),\n",
        "        tf.keras.layers.Dense(38, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(41, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(19, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(35, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "#SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
        "#RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)\n",
        "#Adagrad(lr=0.01, epsilon=1e-06)\n",
        "#Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "          loss='mae',\n",
        "          metrics=['mae'])\n",
        "\n",
        "history=model.fit(x_train, y_train, batch_size=16, epochs=300, validation_data=(x_val,y_val), validation_freq=1, shuffle=False)\n",
        "#history=model.fit(x_train, y_train, batch_size=16, epochs=200, validation_split=0.2, validation_freq=1,shuffle=False)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "epochs = len(history.history['loss'])\n",
        "plt.plot(np.arange(len(history.history['loss'])),history.history['loss'],label='training')\n",
        "plt.plot(np.arange(len(history.history['val_loss'])),history.history['val_loss'],label='validation')\n",
        "plt.legend(fontsize=10)\n",
        "plt.title('learning curve',fontsize=15)\n",
        "plt.xlabel('iteration',fontsize=15)\n",
        "plt.ylabel('error',fontsize=15)\n",
        "plt.show()\n",
        "y_test=model(x_test)\n",
        "y_mid= tf.multiply(y_test,y_std)\n",
        "y_test= tf.add(y_mid, y_mean)\n",
        "error= tf.abs(tf.subtract(y_test, y_target))\n",
        "error_percentage = tf.divide(error, y_target)\n",
        "print(error)\n",
        "print(error_percentage)\n",
        "save_path = r'E:\\model\\test.h5'\n",
        "model.save(save_path)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "7/7 [==============================] - 1s 25ms/step - loss: 0.7939 - mae: 0.7939 - val_loss: 0.9934 - val_mae: 0.9934\n",
            "Epoch 2/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.7591 - mae: 0.7591 - val_loss: 0.9769 - val_mae: 0.9769\n",
            "Epoch 3/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6942 - mae: 0.6942 - val_loss: 0.9495 - val_mae: 0.9495\n",
            "Epoch 4/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6646 - mae: 0.6646 - val_loss: 0.9126 - val_mae: 0.9126\n",
            "Epoch 5/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6076 - mae: 0.6076 - val_loss: 0.8671 - val_mae: 0.8671\n",
            "Epoch 6/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5670 - mae: 0.5670 - val_loss: 0.8346 - val_mae: 0.8346\n",
            "Epoch 7/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5564 - mae: 0.5564 - val_loss: 0.8243 - val_mae: 0.8243\n",
            "Epoch 8/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5251 - mae: 0.5251 - val_loss: 0.7860 - val_mae: 0.7860\n",
            "Epoch 9/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5543 - mae: 0.5543 - val_loss: 0.7645 - val_mae: 0.7645\n",
            "Epoch 10/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4931 - mae: 0.4931 - val_loss: 0.7469 - val_mae: 0.7469\n",
            "Epoch 11/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5032 - mae: 0.5032 - val_loss: 0.7321 - val_mae: 0.7321\n",
            "Epoch 12/300\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.4923 - mae: 0.4923 - val_loss: 0.7394 - val_mae: 0.7394\n",
            "Epoch 13/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4624 - mae: 0.4624 - val_loss: 0.7047 - val_mae: 0.7047\n",
            "Epoch 14/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4571 - mae: 0.4571 - val_loss: 0.6704 - val_mae: 0.6704\n",
            "Epoch 15/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4278 - mae: 0.4278 - val_loss: 0.6786 - val_mae: 0.6786\n",
            "Epoch 16/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4693 - mae: 0.4693 - val_loss: 0.6908 - val_mae: 0.6908\n",
            "Epoch 17/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4348 - mae: 0.4348 - val_loss: 0.6713 - val_mae: 0.6713\n",
            "Epoch 18/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4397 - mae: 0.4397 - val_loss: 0.6512 - val_mae: 0.6512\n",
            "Epoch 19/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4230 - mae: 0.4230 - val_loss: 0.6680 - val_mae: 0.6680\n",
            "Epoch 20/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4100 - mae: 0.4100 - val_loss: 0.6820 - val_mae: 0.6820\n",
            "Epoch 21/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3784 - mae: 0.3784 - val_loss: 0.6866 - val_mae: 0.6866\n",
            "Epoch 22/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4062 - mae: 0.4062 - val_loss: 0.7038 - val_mae: 0.7038\n",
            "Epoch 23/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3623 - mae: 0.3623 - val_loss: 0.7229 - val_mae: 0.7229\n",
            "Epoch 24/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3581 - mae: 0.3581 - val_loss: 0.7235 - val_mae: 0.7235\n",
            "Epoch 25/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3529 - mae: 0.3529 - val_loss: 0.7036 - val_mae: 0.7036\n",
            "Epoch 26/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3278 - mae: 0.3278 - val_loss: 0.6843 - val_mae: 0.6843\n",
            "Epoch 27/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3817 - mae: 0.3817 - val_loss: 0.6438 - val_mae: 0.6438\n",
            "Epoch 28/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3018 - mae: 0.3018 - val_loss: 0.6262 - val_mae: 0.6262\n",
            "Epoch 29/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2912 - mae: 0.2912 - val_loss: 0.6103 - val_mae: 0.6103\n",
            "Epoch 30/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3017 - mae: 0.3017 - val_loss: 0.5517 - val_mae: 0.5517\n",
            "Epoch 31/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3001 - mae: 0.3001 - val_loss: 0.5257 - val_mae: 0.5257\n",
            "Epoch 32/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3154 - mae: 0.3154 - val_loss: 0.5203 - val_mae: 0.5203\n",
            "Epoch 33/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3001 - mae: 0.3001 - val_loss: 0.5639 - val_mae: 0.5639\n",
            "Epoch 34/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2775 - mae: 0.2775 - val_loss: 0.5507 - val_mae: 0.5507\n",
            "Epoch 35/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2844 - mae: 0.2844 - val_loss: 0.5312 - val_mae: 0.5312\n",
            "Epoch 36/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2596 - mae: 0.2596 - val_loss: 0.5256 - val_mae: 0.5256\n",
            "Epoch 37/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2499 - mae: 0.2499 - val_loss: 0.5140 - val_mae: 0.5140\n",
            "Epoch 38/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2440 - mae: 0.2440 - val_loss: 0.4797 - val_mae: 0.4797\n",
            "Epoch 39/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2594 - mae: 0.2594 - val_loss: 0.4591 - val_mae: 0.4591\n",
            "Epoch 40/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2487 - mae: 0.2487 - val_loss: 0.5022 - val_mae: 0.5022\n",
            "Epoch 41/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2536 - mae: 0.2536 - val_loss: 0.4492 - val_mae: 0.4492\n",
            "Epoch 42/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2426 - mae: 0.2426 - val_loss: 0.4028 - val_mae: 0.4028\n",
            "Epoch 43/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2751 - mae: 0.2751 - val_loss: 0.4402 - val_mae: 0.4402\n",
            "Epoch 44/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2546 - mae: 0.2546 - val_loss: 0.4436 - val_mae: 0.4436\n",
            "Epoch 45/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2212 - mae: 0.2212 - val_loss: 0.4374 - val_mae: 0.4374\n",
            "Epoch 46/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.4295 - val_mae: 0.4295\n",
            "Epoch 47/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2528 - mae: 0.2528 - val_loss: 0.4239 - val_mae: 0.4239\n",
            "Epoch 48/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2053 - mae: 0.2053 - val_loss: 0.4287 - val_mae: 0.4287\n",
            "Epoch 49/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2010 - mae: 0.2010 - val_loss: 0.4323 - val_mae: 0.4323\n",
            "Epoch 50/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2491 - mae: 0.2491 - val_loss: 0.4332 - val_mae: 0.4332\n",
            "Epoch 51/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2117 - mae: 0.2117 - val_loss: 0.3884 - val_mae: 0.3884\n",
            "Epoch 52/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1957 - mae: 0.1957 - val_loss: 0.3755 - val_mae: 0.3755\n",
            "Epoch 53/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2362 - mae: 0.2362 - val_loss: 0.3751 - val_mae: 0.3751\n",
            "Epoch 54/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2384 - mae: 0.2384 - val_loss: 0.3764 - val_mae: 0.3764\n",
            "Epoch 55/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2108 - mae: 0.2108 - val_loss: 0.3645 - val_mae: 0.3645\n",
            "Epoch 56/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2306 - mae: 0.2306 - val_loss: 0.3860 - val_mae: 0.3860\n",
            "Epoch 57/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1896 - mae: 0.1896 - val_loss: 0.3574 - val_mae: 0.3574\n",
            "Epoch 58/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2132 - mae: 0.2132 - val_loss: 0.3691 - val_mae: 0.3691\n",
            "Epoch 59/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1937 - mae: 0.1937 - val_loss: 0.3917 - val_mae: 0.3917\n",
            "Epoch 60/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2302 - mae: 0.2302 - val_loss: 0.3580 - val_mae: 0.3580\n",
            "Epoch 61/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1829 - mae: 0.1829 - val_loss: 0.3550 - val_mae: 0.3550\n",
            "Epoch 62/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1973 - mae: 0.1973 - val_loss: 0.3679 - val_mae: 0.3679\n",
            "Epoch 63/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1957 - mae: 0.1957 - val_loss: 0.3597 - val_mae: 0.3597\n",
            "Epoch 64/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1845 - mae: 0.1845 - val_loss: 0.3420 - val_mae: 0.3420\n",
            "Epoch 65/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2287 - mae: 0.2287 - val_loss: 0.3341 - val_mae: 0.3341\n",
            "Epoch 66/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2386 - mae: 0.2386 - val_loss: 0.3674 - val_mae: 0.3674\n",
            "Epoch 67/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2199 - mae: 0.2199 - val_loss: 0.3902 - val_mae: 0.3902\n",
            "Epoch 68/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2142 - mae: 0.2142 - val_loss: 0.3723 - val_mae: 0.3723\n",
            "Epoch 69/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1896 - mae: 0.1896 - val_loss: 0.3340 - val_mae: 0.3340\n",
            "Epoch 70/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2104 - mae: 0.2104 - val_loss: 0.3365 - val_mae: 0.3365\n",
            "Epoch 71/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1887 - mae: 0.1887 - val_loss: 0.3458 - val_mae: 0.3458\n",
            "Epoch 72/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2205 - mae: 0.2205 - val_loss: 0.3569 - val_mae: 0.3569\n",
            "Epoch 73/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1884 - mae: 0.1884 - val_loss: 0.3428 - val_mae: 0.3428\n",
            "Epoch 74/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2456 - mae: 0.2456 - val_loss: 0.3261 - val_mae: 0.3261\n",
            "Epoch 75/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2372 - mae: 0.2372 - val_loss: 0.3250 - val_mae: 0.3250\n",
            "Epoch 76/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1959 - mae: 0.1959 - val_loss: 0.3538 - val_mae: 0.3538\n",
            "Epoch 77/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2251 - mae: 0.2251 - val_loss: 0.3434 - val_mae: 0.3434\n",
            "Epoch 78/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2025 - mae: 0.2025 - val_loss: 0.3258 - val_mae: 0.3258\n",
            "Epoch 79/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1854 - mae: 0.1854 - val_loss: 0.3249 - val_mae: 0.3249\n",
            "Epoch 80/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2083 - mae: 0.2083 - val_loss: 0.3126 - val_mae: 0.3126\n",
            "Epoch 81/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1964 - mae: 0.1964 - val_loss: 0.3150 - val_mae: 0.3150\n",
            "Epoch 82/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2060 - mae: 0.2060 - val_loss: 0.3246 - val_mae: 0.3246\n",
            "Epoch 83/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1736 - mae: 0.1736 - val_loss: 0.3438 - val_mae: 0.3438\n",
            "Epoch 84/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2072 - mae: 0.2072 - val_loss: 0.3244 - val_mae: 0.3244\n",
            "Epoch 85/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1858 - mae: 0.1858 - val_loss: 0.3029 - val_mae: 0.3029\n",
            "Epoch 86/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1907 - mae: 0.1907 - val_loss: 0.2898 - val_mae: 0.2898\n",
            "Epoch 87/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1859 - mae: 0.1859 - val_loss: 0.3018 - val_mae: 0.3018\n",
            "Epoch 88/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2151 - mae: 0.2151 - val_loss: 0.3261 - val_mae: 0.3261\n",
            "Epoch 89/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1859 - mae: 0.1859 - val_loss: 0.3192 - val_mae: 0.3192\n",
            "Epoch 90/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1812 - mae: 0.1812 - val_loss: 0.3210 - val_mae: 0.3210\n",
            "Epoch 91/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1943 - mae: 0.1943 - val_loss: 0.3219 - val_mae: 0.3219\n",
            "Epoch 92/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1874 - mae: 0.1874 - val_loss: 0.3227 - val_mae: 0.3227\n",
            "Epoch 93/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1729 - mae: 0.1729 - val_loss: 0.3479 - val_mae: 0.3479\n",
            "Epoch 94/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1989 - mae: 0.1989 - val_loss: 0.3374 - val_mae: 0.3374\n",
            "Epoch 95/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1952 - mae: 0.1952 - val_loss: 0.3061 - val_mae: 0.3061\n",
            "Epoch 96/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1947 - mae: 0.1947 - val_loss: 0.2960 - val_mae: 0.2960\n",
            "Epoch 97/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1858 - mae: 0.1858 - val_loss: 0.2921 - val_mae: 0.2921\n",
            "Epoch 98/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1857 - mae: 0.1857 - val_loss: 0.3161 - val_mae: 0.3161\n",
            "Epoch 99/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1863 - mae: 0.1863 - val_loss: 0.3741 - val_mae: 0.3741\n",
            "Epoch 100/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1906 - mae: 0.1906 - val_loss: 0.3262 - val_mae: 0.3262\n",
            "Epoch 101/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1820 - mae: 0.1820 - val_loss: 0.2780 - val_mae: 0.2780\n",
            "Epoch 102/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2636 - mae: 0.2636 - val_loss: 0.2778 - val_mae: 0.2778\n",
            "Epoch 103/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2086 - mae: 0.2086 - val_loss: 0.3196 - val_mae: 0.3196\n",
            "Epoch 104/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2216 - mae: 0.2216 - val_loss: 0.3116 - val_mae: 0.3116\n",
            "Epoch 105/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2128 - mae: 0.2128 - val_loss: 0.2880 - val_mae: 0.2880\n",
            "Epoch 106/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1648 - mae: 0.1648 - val_loss: 0.2717 - val_mae: 0.2717\n",
            "Epoch 107/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1969 - mae: 0.1969 - val_loss: 0.2676 - val_mae: 0.2676\n",
            "Epoch 108/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1998 - mae: 0.1998 - val_loss: 0.3022 - val_mae: 0.3022\n",
            "Epoch 109/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1619 - mae: 0.1619 - val_loss: 0.2870 - val_mae: 0.2870\n",
            "Epoch 110/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1803 - mae: 0.1803 - val_loss: 0.2708 - val_mae: 0.2708\n",
            "Epoch 111/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1726 - mae: 0.1726 - val_loss: 0.2903 - val_mae: 0.2903\n",
            "Epoch 112/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1627 - mae: 0.1627 - val_loss: 0.2892 - val_mae: 0.2892\n",
            "Epoch 113/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1727 - mae: 0.1727 - val_loss: 0.2894 - val_mae: 0.2894\n",
            "Epoch 114/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1581 - mae: 0.1581 - val_loss: 0.3031 - val_mae: 0.3031\n",
            "Epoch 115/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1887 - mae: 0.1887 - val_loss: 0.3181 - val_mae: 0.3181\n",
            "Epoch 116/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1945 - mae: 0.1945 - val_loss: 0.3142 - val_mae: 0.3142\n",
            "Epoch 117/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1619 - mae: 0.1619 - val_loss: 0.2837 - val_mae: 0.2837\n",
            "Epoch 118/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1665 - mae: 0.1665 - val_loss: 0.2717 - val_mae: 0.2717\n",
            "Epoch 119/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1652 - mae: 0.1652 - val_loss: 0.2978 - val_mae: 0.2978\n",
            "Epoch 120/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1887 - mae: 0.1887 - val_loss: 0.3142 - val_mae: 0.3142\n",
            "Epoch 121/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1947 - mae: 0.1947 - val_loss: 0.3078 - val_mae: 0.3078\n",
            "Epoch 122/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1868 - mae: 0.1868 - val_loss: 0.3126 - val_mae: 0.3126\n",
            "Epoch 123/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1628 - mae: 0.1628 - val_loss: 0.3268 - val_mae: 0.3268\n",
            "Epoch 124/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1924 - mae: 0.1924 - val_loss: 0.3123 - val_mae: 0.3123\n",
            "Epoch 125/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1882 - mae: 0.1882 - val_loss: 0.2969 - val_mae: 0.2969\n",
            "Epoch 126/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1763 - mae: 0.1763 - val_loss: 0.2888 - val_mae: 0.2888\n",
            "Epoch 127/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2239 - mae: 0.2239 - val_loss: 0.3349 - val_mae: 0.3349\n",
            "Epoch 128/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1973 - mae: 0.1973 - val_loss: 0.3511 - val_mae: 0.3511\n",
            "Epoch 129/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1980 - mae: 0.1980 - val_loss: 0.3153 - val_mae: 0.3153\n",
            "Epoch 130/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1463 - mae: 0.1463 - val_loss: 0.2922 - val_mae: 0.2922\n",
            "Epoch 131/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1874 - mae: 0.1874 - val_loss: 0.3025 - val_mae: 0.3025\n",
            "Epoch 132/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2115 - mae: 0.2115 - val_loss: 0.3075 - val_mae: 0.3075\n",
            "Epoch 133/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2082 - mae: 0.2082 - val_loss: 0.2962 - val_mae: 0.2962\n",
            "Epoch 134/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1863 - mae: 0.1863 - val_loss: 0.2967 - val_mae: 0.2967\n",
            "Epoch 135/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1692 - mae: 0.1692 - val_loss: 0.2908 - val_mae: 0.2908\n",
            "Epoch 136/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1607 - mae: 0.1607 - val_loss: 0.2887 - val_mae: 0.2887\n",
            "Epoch 137/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1769 - mae: 0.1769 - val_loss: 0.3012 - val_mae: 0.3012\n",
            "Epoch 138/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1650 - mae: 0.1650 - val_loss: 0.3113 - val_mae: 0.3113\n",
            "Epoch 139/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1864 - mae: 0.1864 - val_loss: 0.2889 - val_mae: 0.2889\n",
            "Epoch 140/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1904 - mae: 0.1904 - val_loss: 0.2640 - val_mae: 0.2640\n",
            "Epoch 141/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1747 - mae: 0.1747 - val_loss: 0.2655 - val_mae: 0.2655\n",
            "Epoch 142/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1823 - mae: 0.1823 - val_loss: 0.2700 - val_mae: 0.2700\n",
            "Epoch 143/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1874 - mae: 0.1874 - val_loss: 0.2858 - val_mae: 0.2858\n",
            "Epoch 144/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1835 - mae: 0.1835 - val_loss: 0.2667 - val_mae: 0.2667\n",
            "Epoch 145/300\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1805 - mae: 0.1805 - val_loss: 0.2720 - val_mae: 0.2720\n",
            "Epoch 146/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1735 - mae: 0.1735 - val_loss: 0.2791 - val_mae: 0.2791\n",
            "Epoch 147/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1733 - mae: 0.1733 - val_loss: 0.2929 - val_mae: 0.2929\n",
            "Epoch 148/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1655 - mae: 0.1655 - val_loss: 0.2882 - val_mae: 0.2882\n",
            "Epoch 149/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1576 - mae: 0.1576 - val_loss: 0.2913 - val_mae: 0.2913\n",
            "Epoch 150/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1827 - mae: 0.1827 - val_loss: 0.2856 - val_mae: 0.2856\n",
            "Epoch 151/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1982 - mae: 0.1982 - val_loss: 0.2691 - val_mae: 0.2691\n",
            "Epoch 152/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1712 - mae: 0.1712 - val_loss: 0.2716 - val_mae: 0.2716\n",
            "Epoch 153/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1637 - mae: 0.1637 - val_loss: 0.2835 - val_mae: 0.2835\n",
            "Epoch 154/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1663 - mae: 0.1663 - val_loss: 0.2797 - val_mae: 0.2797\n",
            "Epoch 155/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1757 - mae: 0.1757 - val_loss: 0.2918 - val_mae: 0.2918\n",
            "Epoch 156/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2040 - mae: 0.2040 - val_loss: 0.2644 - val_mae: 0.2644\n",
            "Epoch 157/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1718 - mae: 0.1718 - val_loss: 0.2427 - val_mae: 0.2427\n",
            "Epoch 158/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1551 - mae: 0.1551 - val_loss: 0.2491 - val_mae: 0.2491\n",
            "Epoch 159/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1782 - mae: 0.1782 - val_loss: 0.2338 - val_mae: 0.2338\n",
            "Epoch 160/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1667 - mae: 0.1667 - val_loss: 0.2121 - val_mae: 0.2121\n",
            "Epoch 161/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1995 - mae: 0.1995 - val_loss: 0.2211 - val_mae: 0.2211\n",
            "Epoch 162/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1543 - mae: 0.1543 - val_loss: 0.2505 - val_mae: 0.2505\n",
            "Epoch 163/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1508 - mae: 0.1508 - val_loss: 0.2430 - val_mae: 0.2430\n",
            "Epoch 164/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1762 - mae: 0.1762 - val_loss: 0.2399 - val_mae: 0.2399\n",
            "Epoch 165/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1707 - mae: 0.1707 - val_loss: 0.2405 - val_mae: 0.2405\n",
            "Epoch 166/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1782 - mae: 0.1782 - val_loss: 0.2319 - val_mae: 0.2319\n",
            "Epoch 167/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1666 - mae: 0.1666 - val_loss: 0.2555 - val_mae: 0.2555\n",
            "Epoch 168/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1679 - mae: 0.1679 - val_loss: 0.2378 - val_mae: 0.2378\n",
            "Epoch 169/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1727 - mae: 0.1727 - val_loss: 0.2542 - val_mae: 0.2542\n",
            "Epoch 170/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1775 - mae: 0.1775 - val_loss: 0.2495 - val_mae: 0.2495\n",
            "Epoch 171/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1650 - mae: 0.1650 - val_loss: 0.2389 - val_mae: 0.2389\n",
            "Epoch 172/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.2375 - val_mae: 0.2375\n",
            "Epoch 173/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1556 - mae: 0.1556 - val_loss: 0.2758 - val_mae: 0.2758\n",
            "Epoch 174/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1997 - mae: 0.1997 - val_loss: 0.2524 - val_mae: 0.2524\n",
            "Epoch 175/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1703 - mae: 0.1703 - val_loss: 0.2379 - val_mae: 0.2379\n",
            "Epoch 176/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1940 - mae: 0.1940 - val_loss: 0.2258 - val_mae: 0.2258\n",
            "Epoch 177/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1669 - mae: 0.1669 - val_loss: 0.2369 - val_mae: 0.2369\n",
            "Epoch 178/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1618 - mae: 0.1618 - val_loss: 0.2514 - val_mae: 0.2514\n",
            "Epoch 179/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1732 - mae: 0.1732 - val_loss: 0.2468 - val_mae: 0.2468\n",
            "Epoch 180/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1933 - mae: 0.1933 - val_loss: 0.2520 - val_mae: 0.2520\n",
            "Epoch 181/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1773 - mae: 0.1773 - val_loss: 0.2324 - val_mae: 0.2324\n",
            "Epoch 182/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1875 - mae: 0.1875 - val_loss: 0.2329 - val_mae: 0.2329\n",
            "Epoch 183/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1759 - mae: 0.1759 - val_loss: 0.2697 - val_mae: 0.2697\n",
            "Epoch 184/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1869 - mae: 0.1869 - val_loss: 0.2942 - val_mae: 0.2942\n",
            "Epoch 185/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1699 - mae: 0.1699 - val_loss: 0.2858 - val_mae: 0.2858\n",
            "Epoch 186/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1698 - mae: 0.1698 - val_loss: 0.2609 - val_mae: 0.2609\n",
            "Epoch 187/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1564 - mae: 0.1564 - val_loss: 0.2603 - val_mae: 0.2603\n",
            "Epoch 188/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1709 - mae: 0.1709 - val_loss: 0.2643 - val_mae: 0.2643\n",
            "Epoch 189/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1631 - mae: 0.1631 - val_loss: 0.2292 - val_mae: 0.2292\n",
            "Epoch 190/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1370 - mae: 0.1370 - val_loss: 0.2127 - val_mae: 0.2127\n",
            "Epoch 191/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1592 - mae: 0.1592 - val_loss: 0.2432 - val_mae: 0.2432\n",
            "Epoch 192/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1547 - mae: 0.1547 - val_loss: 0.2699 - val_mae: 0.2699\n",
            "Epoch 193/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1905 - mae: 0.1905 - val_loss: 0.2490 - val_mae: 0.2490\n",
            "Epoch 194/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1833 - mae: 0.1833 - val_loss: 0.2238 - val_mae: 0.2238\n",
            "Epoch 195/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1683 - mae: 0.1683 - val_loss: 0.2156 - val_mae: 0.2156\n",
            "Epoch 196/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1716 - mae: 0.1716 - val_loss: 0.2613 - val_mae: 0.2613\n",
            "Epoch 197/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2156 - mae: 0.2156 - val_loss: 0.2666 - val_mae: 0.2666\n",
            "Epoch 198/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1716 - mae: 0.1716 - val_loss: 0.2433 - val_mae: 0.2433\n",
            "Epoch 199/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1390 - mae: 0.1390 - val_loss: 0.2469 - val_mae: 0.2469\n",
            "Epoch 200/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1627 - mae: 0.1627 - val_loss: 0.2497 - val_mae: 0.2497\n",
            "Epoch 201/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1997 - mae: 0.1997 - val_loss: 0.2620 - val_mae: 0.2620\n",
            "Epoch 202/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1712 - mae: 0.1712 - val_loss: 0.2449 - val_mae: 0.2449\n",
            "Epoch 203/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1864 - mae: 0.1864 - val_loss: 0.2405 - val_mae: 0.2405\n",
            "Epoch 204/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1378 - mae: 0.1378 - val_loss: 0.2652 - val_mae: 0.2652\n",
            "Epoch 205/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1625 - mae: 0.1625 - val_loss: 0.2484 - val_mae: 0.2484\n",
            "Epoch 206/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1690 - mae: 0.1690 - val_loss: 0.2564 - val_mae: 0.2564\n",
            "Epoch 207/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2097 - mae: 0.2097 - val_loss: 0.2452 - val_mae: 0.2452\n",
            "Epoch 208/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.2988 - val_mae: 0.2988\n",
            "Epoch 209/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1589 - mae: 0.1589 - val_loss: 0.2582 - val_mae: 0.2582\n",
            "Epoch 210/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1621 - mae: 0.1621 - val_loss: 0.2477 - val_mae: 0.2477\n",
            "Epoch 211/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1298 - mae: 0.1298 - val_loss: 0.2282 - val_mae: 0.2282\n",
            "Epoch 212/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1652 - mae: 0.1652 - val_loss: 0.2236 - val_mae: 0.2236\n",
            "Epoch 213/300\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1541 - mae: 0.1541 - val_loss: 0.2287 - val_mae: 0.2287\n",
            "Epoch 214/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1658 - mae: 0.1658 - val_loss: 0.2352 - val_mae: 0.2352\n",
            "Epoch 215/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2021 - mae: 0.2021 - val_loss: 0.2302 - val_mae: 0.2302\n",
            "Epoch 216/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1414 - mae: 0.1414 - val_loss: 0.2458 - val_mae: 0.2458\n",
            "Epoch 217/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1834 - mae: 0.1834 - val_loss: 0.2459 - val_mae: 0.2459\n",
            "Epoch 218/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1798 - mae: 0.1798 - val_loss: 0.2290 - val_mae: 0.2290\n",
            "Epoch 219/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1497 - mae: 0.1497 - val_loss: 0.2478 - val_mae: 0.2478\n",
            "Epoch 220/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1668 - mae: 0.1668 - val_loss: 0.2391 - val_mae: 0.2391\n",
            "Epoch 221/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1806 - mae: 0.1806 - val_loss: 0.2517 - val_mae: 0.2517\n",
            "Epoch 222/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1562 - mae: 0.1562 - val_loss: 0.2521 - val_mae: 0.2521\n",
            "Epoch 223/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1474 - mae: 0.1474 - val_loss: 0.2939 - val_mae: 0.2939\n",
            "Epoch 224/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2103 - mae: 0.2103 - val_loss: 0.2815 - val_mae: 0.2815\n",
            "Epoch 225/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1335 - mae: 0.1335 - val_loss: 0.2551 - val_mae: 0.2551\n",
            "Epoch 226/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1577 - mae: 0.1577 - val_loss: 0.2500 - val_mae: 0.2500\n",
            "Epoch 227/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1844 - mae: 0.1844 - val_loss: 0.2649 - val_mae: 0.2649\n",
            "Epoch 228/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1837 - mae: 0.1837 - val_loss: 0.2099 - val_mae: 0.2099\n",
            "Epoch 229/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1635 - mae: 0.1635 - val_loss: 0.2377 - val_mae: 0.2377\n",
            "Epoch 230/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1611 - mae: 0.1611 - val_loss: 0.2304 - val_mae: 0.2304\n",
            "Epoch 231/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1594 - mae: 0.1594 - val_loss: 0.2556 - val_mae: 0.2556\n",
            "Epoch 232/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1680 - mae: 0.1680 - val_loss: 0.2450 - val_mae: 0.2450\n",
            "Epoch 233/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1721 - mae: 0.1721 - val_loss: 0.2342 - val_mae: 0.2342\n",
            "Epoch 234/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1959 - mae: 0.1959 - val_loss: 0.2479 - val_mae: 0.2479\n",
            "Epoch 235/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1703 - mae: 0.1703 - val_loss: 0.2525 - val_mae: 0.2525\n",
            "Epoch 236/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1761 - mae: 0.1761 - val_loss: 0.2312 - val_mae: 0.2312\n",
            "Epoch 237/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1940 - mae: 0.1940 - val_loss: 0.2182 - val_mae: 0.2182\n",
            "Epoch 238/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1368 - mae: 0.1368 - val_loss: 0.2591 - val_mae: 0.2591\n",
            "Epoch 239/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1928 - mae: 0.1928 - val_loss: 0.2226 - val_mae: 0.2226\n",
            "Epoch 240/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1776 - mae: 0.1776 - val_loss: 0.1988 - val_mae: 0.1988\n",
            "Epoch 241/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1775 - mae: 0.1775 - val_loss: 0.2036 - val_mae: 0.2036\n",
            "Epoch 242/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1862 - mae: 0.1862 - val_loss: 0.2453 - val_mae: 0.2453\n",
            "Epoch 243/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1809 - mae: 0.1809 - val_loss: 0.2326 - val_mae: 0.2326\n",
            "Epoch 244/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1607 - mae: 0.1607 - val_loss: 0.2500 - val_mae: 0.2500\n",
            "Epoch 245/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1365 - mae: 0.1365 - val_loss: 0.2406 - val_mae: 0.2406\n",
            "Epoch 246/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1658 - mae: 0.1658 - val_loss: 0.2492 - val_mae: 0.2492\n",
            "Epoch 247/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1921 - mae: 0.1921 - val_loss: 0.2282 - val_mae: 0.2282\n",
            "Epoch 248/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1705 - mae: 0.1705 - val_loss: 0.2417 - val_mae: 0.2417\n",
            "Epoch 249/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1773 - mae: 0.1773 - val_loss: 0.2538 - val_mae: 0.2538\n",
            "Epoch 250/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1739 - mae: 0.1739 - val_loss: 0.2675 - val_mae: 0.2675\n",
            "Epoch 251/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1804 - mae: 0.1804 - val_loss: 0.2415 - val_mae: 0.2415\n",
            "Epoch 252/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1774 - mae: 0.1774 - val_loss: 0.2207 - val_mae: 0.2207\n",
            "Epoch 253/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1636 - mae: 0.1636 - val_loss: 0.2342 - val_mae: 0.2342\n",
            "Epoch 254/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1785 - mae: 0.1785 - val_loss: 0.2536 - val_mae: 0.2536\n",
            "Epoch 255/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1649 - mae: 0.1649 - val_loss: 0.2275 - val_mae: 0.2275\n",
            "Epoch 256/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1641 - mae: 0.1641 - val_loss: 0.2163 - val_mae: 0.2163\n",
            "Epoch 257/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1895 - mae: 0.1895 - val_loss: 0.2225 - val_mae: 0.2225\n",
            "Epoch 258/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1532 - mae: 0.1532 - val_loss: 0.2382 - val_mae: 0.2382\n",
            "Epoch 259/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1791 - mae: 0.1791 - val_loss: 0.2430 - val_mae: 0.2430\n",
            "Epoch 260/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1554 - mae: 0.1554 - val_loss: 0.2381 - val_mae: 0.2381\n",
            "Epoch 261/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1330 - mae: 0.1330 - val_loss: 0.2198 - val_mae: 0.2198\n",
            "Epoch 262/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1444 - mae: 0.1444 - val_loss: 0.2221 - val_mae: 0.2221\n",
            "Epoch 263/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1680 - mae: 0.1680 - val_loss: 0.2351 - val_mae: 0.2351\n",
            "Epoch 264/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1409 - mae: 0.1409 - val_loss: 0.2366 - val_mae: 0.2366\n",
            "Epoch 265/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1397 - mae: 0.1397 - val_loss: 0.2613 - val_mae: 0.2613\n",
            "Epoch 266/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1670 - mae: 0.1670 - val_loss: 0.2335 - val_mae: 0.2335\n",
            "Epoch 267/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1650 - mae: 0.1650 - val_loss: 0.2135 - val_mae: 0.2135\n",
            "Epoch 268/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1400 - mae: 0.1400 - val_loss: 0.2133 - val_mae: 0.2133\n",
            "Epoch 269/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1335 - mae: 0.1335 - val_loss: 0.2294 - val_mae: 0.2294\n",
            "Epoch 270/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1492 - mae: 0.1492 - val_loss: 0.2587 - val_mae: 0.2587\n",
            "Epoch 271/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1650 - mae: 0.1650 - val_loss: 0.2406 - val_mae: 0.2406\n",
            "Epoch 272/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1841 - mae: 0.1841 - val_loss: 0.2175 - val_mae: 0.2175\n",
            "Epoch 273/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1519 - mae: 0.1519 - val_loss: 0.2043 - val_mae: 0.2043\n",
            "Epoch 274/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1402 - mae: 0.1402 - val_loss: 0.2131 - val_mae: 0.2131\n",
            "Epoch 275/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1355 - mae: 0.1355 - val_loss: 0.1977 - val_mae: 0.1977\n",
            "Epoch 276/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1872 - mae: 0.1872 - val_loss: 0.1813 - val_mae: 0.1813\n",
            "Epoch 277/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1246 - mae: 0.1246 - val_loss: 0.2084 - val_mae: 0.2084\n",
            "Epoch 278/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1721 - mae: 0.1721 - val_loss: 0.1974 - val_mae: 0.1974\n",
            "Epoch 279/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1745 - mae: 0.1745 - val_loss: 0.2193 - val_mae: 0.2193\n",
            "Epoch 280/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1524 - mae: 0.1524 - val_loss: 0.2560 - val_mae: 0.2560\n",
            "Epoch 281/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1543 - mae: 0.1543 - val_loss: 0.2437 - val_mae: 0.2437\n",
            "Epoch 282/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1513 - mae: 0.1513 - val_loss: 0.2107 - val_mae: 0.2107\n",
            "Epoch 283/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1377 - mae: 0.1377 - val_loss: 0.2014 - val_mae: 0.2014\n",
            "Epoch 284/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1655 - mae: 0.1655 - val_loss: 0.2128 - val_mae: 0.2128\n",
            "Epoch 285/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1564 - mae: 0.1564 - val_loss: 0.1825 - val_mae: 0.1825\n",
            "Epoch 286/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1612 - mae: 0.1612 - val_loss: 0.2118 - val_mae: 0.2118\n",
            "Epoch 287/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1237 - mae: 0.1237 - val_loss: 0.2126 - val_mae: 0.2126\n",
            "Epoch 288/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1843 - mae: 0.1843 - val_loss: 0.2210 - val_mae: 0.2210\n",
            "Epoch 289/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1305 - mae: 0.1305 - val_loss: 0.2101 - val_mae: 0.2101\n",
            "Epoch 290/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1603 - mae: 0.1603 - val_loss: 0.2173 - val_mae: 0.2173\n",
            "Epoch 291/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1539 - mae: 0.1539 - val_loss: 0.2094 - val_mae: 0.2094\n",
            "Epoch 292/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1656 - mae: 0.1656 - val_loss: 0.2190 - val_mae: 0.2190\n",
            "Epoch 293/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1340 - mae: 0.1340 - val_loss: 0.2061 - val_mae: 0.2061\n",
            "Epoch 294/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1391 - mae: 0.1391 - val_loss: 0.2288 - val_mae: 0.2288\n",
            "Epoch 295/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1638 - mae: 0.1638 - val_loss: 0.2088 - val_mae: 0.2088\n",
            "Epoch 296/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1536 - mae: 0.1536 - val_loss: 0.2064 - val_mae: 0.2064\n",
            "Epoch 297/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1505 - mae: 0.1505 - val_loss: 0.2408 - val_mae: 0.2408\n",
            "Epoch 298/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1693 - mae: 0.1693 - val_loss: 0.2196 - val_mae: 0.2196\n",
            "Epoch 299/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1506 - mae: 0.1506 - val_loss: 0.1702 - val_mae: 0.1702\n",
            "Epoch 300/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1735 - val_mae: 0.1735\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_15 (Flatten)         (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 38)                228       \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 41)                1599      \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 19)                798       \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 35)                700       \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 35)                0         \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 1)                 36        \n",
            "=================================================================\n",
            "Total params: 3,361\n",
            "Trainable params: 3,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1.922205  ]\n",
            " [0.26305008]\n",
            " [0.8387835 ]\n",
            " [0.8072045 ]\n",
            " [0.08500499]\n",
            " [0.09312797]\n",
            " [0.09048247]\n",
            " [0.08033872]\n",
            " [0.06450915]], shape=(9, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.11732925]\n",
            " [0.07109462]\n",
            " [0.17351748]\n",
            " [0.17682464]\n",
            " [0.13240652]\n",
            " [0.03438994]\n",
            " [0.05434383]\n",
            " [0.02681533]\n",
            " [0.02239901]], shape=(9, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wbKDcT_W6JJ",
        "outputId": "9e67bd66-9c6e-4f84-e6e2-6eed4ce2b5fc"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[14.460794 ]\n",
            " [ 3.43695  ]\n",
            " [ 3.9952166]\n",
            " [ 3.7577956]\n",
            " [ 0.727005 ]\n",
            " [ 2.614872 ]\n",
            " [ 1.5745175]\n",
            " [ 3.0763388]\n",
            " [ 2.815491 ]], shape=(9, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml6V6JozTZhP"
      },
      "source": [
        "print(y_std)\n",
        "y_test=model(x_test)\n",
        "print(y_test)\n",
        "y_mid= tf.multiply(y_test,y_std)\n",
        "print(y_mid)\n",
        "y_test= tf.add(y_mid, y_mean)\n",
        "print(y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8eDy7zwnDSa"
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4NKtVI5pswZ"
      },
      "source": [
        "model.compiled_metrics_dict.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8gUkx6Vt9tw"
      },
      "source": [
        "x = np.array([10,10,65,50,5],[10,10,80,50,6],[11,8,50,60,5],[10,10,50,60,20],[11,8,50,60,13])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsbab7jeyCjf"
      },
      "source": [
        "test = pd.read_csv('/content/test.csv')\n",
        "x_test = test.loc[0:7, ['A','B','C','D','E']]\n",
        "y_target = test.loc[0:7, ['target']]\n",
        "y_target = np.array(y_target)\n",
        "x_test = np.array(x_test)\n",
        "y_test=model(x_test)\n",
        "error= tf.abs(tf.subtract(y_test, y_target))\n",
        "error_percentage = tf.divide(error, y_target)\n",
        "print(error)\n",
        "print(error_percentage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn_mvACB4VFY"
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ2OS9ACAMfL"
      },
      "source": [
        "\n",
        "x_train = data.loc[0:80, ['A','B','C','D','E']]\n",
        "x_train=np.array(x_train)\n",
        "y_train = data.loc[0:80, ['target']]\n",
        "y_train=np.array(y_train)\n",
        "\n",
        "x_val = data.loc[80:103, ['A','B','C','D','E']]\n",
        "x_val = np.array(x_val)\n",
        "y_val = data.loc[80:103, ['target']]\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "np.random.seed(116)\n",
        "np.random.shuffle(x_train)\n",
        "np.random.seed(116)\n",
        "np.random.shuffle(y_train)\n",
        "tf.random.set_seed(116)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTFYHF6ENKL-"
      },
      "source": [
        "test = pd.read_csv('/content/test.csv')\n",
        "\n",
        "x = data.loc[0:98, ['A','B','C','D','E']]\n",
        "x=np.array(x)\n",
        "y = data.loc[0:98, ['target']]\n",
        "y=np.array(y)\n",
        "\n",
        "\n",
        "np.random.seed(116)\n",
        "np.random.shuffle(x)\n",
        "np.random.seed(116)\n",
        "np.random.shuffle(y)\n",
        "\n",
        "x_train = x[0:80,:]\n",
        "x_val = x[81:95,:]\n",
        "y_train = y[0:80,:]\n",
        "y_val = y[81:95,:]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACa5C3BWOUWP"
      },
      "source": [
        "data = pd.read_csv('/content/traincmp.csv')\n",
        "\n",
        "x = data.loc[0:98, ['A','B','C','D','E']]\n",
        "x=np.array(x)\n",
        "y = data.loc[0:98, ['target']]\n",
        "y=np.array()\n",
        "\n",
        "np.random.seed(116)\n",
        "np.random.shuffle(x)\n",
        "np.random.seed(116)\n",
        "np.random.shuffle(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckmDwEYl-YC3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv('/content/traincmp.csv')\n",
        "\n",
        "x = data.loc[0:120, ['A','B','C','D','E']]\n",
        "x =np.array(x)\n",
        "x_mean = np.mean(x,axis=0)\n",
        "x_std = np.std(x,axis=0)\n",
        "x = (x-x_mean)/x_std\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhmSNT5RPA5O",
        "outputId": "e52662c5-c92f-448e-f0e4-634f61efa436"
      },
      "source": [
        "# Train a DNN model for prediction\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import kerastuner as kt\n",
        "\n",
        "# upload the data base at the certain path\n",
        "data = pd.read_csv('/content/traincmp.csv')\n",
        "\n",
        "\n",
        "x = data.loc[0:119, ['A','B','C','D','E']]\n",
        "a=x.shape\n",
        "print(a)\n",
        "x =np.array(x)\n",
        "x_mean = np.mean(x,axis=0)\n",
        "x_std = np.std(x,axis=0)\n",
        "x = (x-x_mean)/x_std\n",
        "\n",
        "x_test= x[110:118,:]\n",
        "print(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(119, 5)\n",
            "[[-0.16593191 -0.31837456 -0.88224852  1.32470325 -1.1661173 ]\n",
            " [-1.68484708 -1.34233596 -0.88224852 -0.99352744 -1.06934745]\n",
            " [-1.68484708 -1.34233596  0.33853722  1.32470325  0.47897007]\n",
            " [-0.16593191 -0.31837456 -0.88224852  1.32470325  1.54343837]\n",
            " [ 1.35298326 -1.34233596  1.55932296 -0.99352744 -0.68226807]\n",
            " [-0.16593191  1.72954826 -0.88224852  0.16558791 -0.19841884]\n",
            " [-0.16593191  0.70558685 -0.88224852  1.32470325  0.57573992]\n",
            " [-0.16593191 -0.31837456  1.55932296 -0.99352744  1.54343837]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c5RVf4231f1"
      },
      "source": [
        "# Train a DNN model for prediction\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import kerastuner as kt\n",
        "\n",
        "# upload the data base at the certain path\n",
        "data = pd.read_csv('/content/traincmp.csv')\n",
        "\n",
        "\n",
        "x = data.loc[0:119, ['A','B','C','D','E']]\n",
        "x =np.array(x)\n",
        "x_mean = np.mean(x,axis=0)\n",
        "x_std = np.std(x,axis=0)\n",
        "x = (x-x_mean)/x_std\n",
        "\n",
        "y = data.loc[0:119, ['target']]\n",
        "y=np.array(y)\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(5)\n",
        "np.random.shuffle(x)\n",
        "np.random.seed(5)\n",
        "np.random.shuffle(y)\n",
        "\n",
        "x_train = x[0:100,:]\n",
        "x_val = x[100:110,:]\n",
        "y_train = y[0:100,:]\n",
        "y_val = y[100:110,:]\n",
        "\n",
        "\n",
        "#Define model\n",
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "#Set the input layer\n",
        "  model.add(keras.layers.Flatten(input_shape=(5,1)))\n",
        "#Set dropout rate search space\n",
        "  drop_rate = hp.Choice('drop_rate', \n",
        "                            [0.0, 0.1, 0.2, 0.3, 0.4,])\n",
        "#Set activation function search space\n",
        "  activation = hp.Choice('activation', \n",
        "                            ['relu', 'tanh', 'sigmoid'])\n",
        "#In here, we tuner the number of layers using for loop\n",
        "  for i in range(hp.Int('num_layers', 2 , 5)):\n",
        "    model.add(keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
        "                      min_value=5,\n",
        "                      max_value=50,\n",
        "                      step=1),\n",
        "                activation= activation))\n",
        "  model.add(keras.layers.Dropout(rate=drop_rate))\n",
        "  model.add(keras.layers.Dense(1, activation='linear'))\n",
        "#  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
        "  model.compile(\n",
        "          optimizer= optimizer,\n",
        "          loss='mean_absolute_error',\n",
        "          metrics=['mean_absolute_error'])\n",
        "\n",
        "#          optimizer=tf.keras.optimizers.optimizer(lr=hp_learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
        "\n",
        "  return model\n",
        "tuner = kt.RandomSearch(model_builder,\n",
        "                     objective='val_mean_absolute_error',\n",
        "                     max_trials=5,\n",
        "                     executions_per_trial=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='254362112455424535462124698')\n",
        "# represent the search space\n",
        "tuner.search_space_summary()\n",
        "\n",
        "# search the best hyperparameters\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "tuner.search(x_train,y_train,epochs=50,validation_split=0.2,callbacks=[stop_early])\n",
        "\n",
        "# recall the overall hyperparameters\n",
        "tuner.results_summary()\n",
        "\n",
        "# train model with the best hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "\n",
        "history=model.fit(x_train, y_train, batch_size=16, epochs=300, validation_data=(x_val,y_val), validation_freq=1, shuffle=False)\n",
        "\n",
        "\n",
        "# plot the figure illustrating the training loss and validation loss\n",
        "epochs = len(history.history['loss'])\n",
        "plt.plot(range(epochs), history.history['loss'], label='loss')\n",
        "plt.plot(range(epochs), history.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "x = np.array([10,10,65,50,5])\n",
        "x=x.reshape(1,5)\n",
        "y=model(x)\n",
        "print(y)\n",
        "\n",
        "#manifest the model structure\n",
        "model.summary()\n",
        "\n",
        "#extract the best hyperparameters \n",
        "tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6JfmZlw9x7P"
      },
      "source": [
        "x = data.loc[0:119, ['A','B','C','D','E']]\n",
        "x =np.array(x)\n",
        "x_mean = np.mean(x,axis=0)\n",
        "x_std = np.std(x,axis=0)\n",
        "x = (x-x_mean)/x_std\n",
        "x_test=x[110:119,:]\n",
        "y = data.loc[0:119, ['target']]\n",
        "y=np.array(y)\n",
        "y_test=model(x_test)\n",
        "y_target=y[110:119,:]\n",
        "error= tf.abs(tf.subtract(y_test, y_target))\n",
        "error_percentage = tf.divide(error, y_target)\n",
        "print(error)\n",
        "print(error_percentage)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
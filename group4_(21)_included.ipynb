{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "group4-(21)-included.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVDVPDtoIidy77F9JL8vDV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zengxuhe/pyGAD-kerastuner/blob/main/group4_(21)_included.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42uR3nQmyssb",
        "outputId": "5ae5a0fb-6838-48fb-b154-51f5355fa6f2"
      },
      "source": [
        "!git clone https://github.com/keras-team/keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-tuner'...\n",
            "remote: Enumerating objects: 7099, done.\u001b[K\n",
            "remote: Counting objects: 100% (457/457), done.\u001b[K\n",
            "remote: Compressing objects: 100% (205/205), done.\u001b[K\n",
            "remote: Total 7099 (delta 252), reused 397 (delta 231), pack-reused 6642\u001b[K\n",
            "Receiving objects: 100% (7099/7099), 1.53 MiB | 14.46 MiB/s, done.\n",
            "Resolving deltas: 100% (4957/4957), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI-hWiFxyuMC",
        "outputId": "b298b262-28b2-4aff-fe0b-194eaa4590d3"
      },
      "source": [
        "cd keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'keras-tuner'\n",
            "/content/keras-tuner\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnT5iUdIyvoY",
        "outputId": "d6ccebed-baf1-4ce2-8ced-64b6121a29f1"
      },
      "source": [
        "!pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/keras-tuner\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (1.4.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (2.5.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (5.5.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt-legacy-1.0.3.tar.gz (5.8 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (57.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (5.0.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner==1.0.3) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner==1.0.3) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->keras-tuner==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner==1.0.3) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner==1.0.3) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.3) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.3) (1.24.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (1.34.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (1.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (3.17.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (1.32.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (0.4.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner==1.0.3) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner==1.0.3) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner==1.0.3) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner==1.0.3) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner==1.0.3) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->keras-tuner==1.0.3) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner==1.0.3) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner==1.0.3) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner==1.0.3) (3.7.4.3)\n",
            "Building wheels for collected packages: keras-tuner, kt-legacy\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.3-py3-none-any.whl size=97186 sha256=4d1688be5758ac715e75a17bc0cc3762f1507b4b77c7bdcda973d39165bd1c79\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/f4/56/f120140a3c0706aebedf4471bfee8f02bbce4755424e32e245\n",
            "  Building wheel for kt-legacy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kt-legacy: filename=kt_legacy-1.0.3-py3-none-any.whl size=9568 sha256=0dec5c1b68cd803c0f53a2716ebe653e267d526d2352754ea1a13d17ff742878\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/5c/e0/13003e68c17f403af40b92a24d20171b95fef13b0fdaba833c\n",
            "Successfully built keras-tuner kt-legacy\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.0.3 kt-legacy-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m1sWt9r6yxq5",
        "outputId": "2e5983f1-b1c2-46f1-985e-e1039abfa7e5"
      },
      "source": [
        "# Train a DNN model for prediction\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import kerastuner as kt\n",
        "\n",
        "# upload the data base at the certain path\n",
        "data = pd.read_csv('/content/traincmp.csv')\n",
        "\n",
        "\n",
        "x = data.loc[0:119, ['A','B','C','D','E']]\n",
        "x =np.array(x)\n",
        "x_mean = np.mean(x,axis=0)\n",
        "x_std = np.std(x,axis=0)\n",
        "x = (x-x_mean)/x_std\n",
        "x_test = x[110:119,:]\n",
        "x = x [0:110,:]\n",
        "\n",
        "\n",
        "y = data.loc[0:119, ['target']]\n",
        "y=np.array(y)\n",
        "y_target= y[110:119,:]\n",
        "y_mean = np.mean(y,axis=0)\n",
        "y_std = np.std(y,axis=0)\n",
        "y = (y-y_mean)/y_std\n",
        "y = y [0:110,:]\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(3)\n",
        "np.random.shuffle(x)\n",
        "np.random.seed(3)\n",
        "np.random.shuffle(y)\n",
        "\n",
        "x_train = x[0:100,:]\n",
        "x_val = x[100:110,:]\n",
        "y_train = y[0:100,:]\n",
        "y_val = y[100:110,:]\n",
        "\n",
        "\n",
        "#Define model\n",
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "#Set the input layer\n",
        "  model.add(keras.layers.Flatten(input_shape=(5,1)))\n",
        "#Set dropout rate search space\n",
        "  drop_rate = hp.Choice('drop_rate', \n",
        "                            [0.0, 0.1, 0.2, 0.3, 0.4,])\n",
        "#Set activation function search space\n",
        "  activation = hp.Choice('activation', \n",
        "                            ['relu', 'tanh', 'sigmoid'])\n",
        "#In here, we tuner the number of layers using for loop\n",
        "  for i in range(hp.Int('num_layers', 2 , 5)):\n",
        "    model.add(keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
        "                      min_value=5,\n",
        "                      max_value=50,\n",
        "                      step=1),\n",
        "                activation= activation))\n",
        "  model.add(keras.layers.Dropout(rate=drop_rate))\n",
        "  model.add(keras.layers.Dense(1, activation='linear'))\n",
        "#  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
        "  model.compile(\n",
        "          optimizer= optimizer,\n",
        "          loss='mean_absolute_error',\n",
        "          metrics=['mean_absolute_error'])\n",
        "\n",
        "#          optimizer=tf.keras.optimizers.optimizer(lr=hp_learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
        "\n",
        "  return model\n",
        "tuner = kt.RandomSearch(model_builder,\n",
        "                     objective='val_mean_absolute_error',\n",
        "                     max_trials=5,\n",
        "                     executions_per_trial=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='255245112154156315312654245298')\n",
        "# represent the search space\n",
        "tuner.search_space_summary()\n",
        "\n",
        "# search the best hyperparameters\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "tuner.search(x_train,y_train,epochs=50,validation_split=0.2,callbacks=[stop_early])\n",
        "\n",
        "# recall the overall hyperparameters\n",
        "tuner.results_summary()\n",
        "\n",
        "# train model with the best hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "\n",
        "history=model.fit(x_train, y_train, batch_size=16, epochs=300, validation_data=(x_val,y_val), validation_freq=1, shuffle=False)\n",
        "\n",
        "\n",
        "# plot the figure illustrating the training loss and validation loss\n",
        "epochs = len(history.history['loss'])\n",
        "plt.plot(range(epochs), history.history['loss'], label='loss')\n",
        "plt.plot(range(epochs), history.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "x = np.array([10,10,65,50,5])\n",
        "x=x.reshape(1,5)\n",
        "y=model(x)\n",
        "print(y)\n",
        "#manifest the model structure\n",
        "model.summary()\n",
        "\n",
        "#extract the best hyperparameters \n",
        "tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 00m 05s]\n",
            "val_mean_absolute_error: 0.49087435007095337\n",
            "\n",
            "Best val_mean_absolute_error So Far: 0.28988781571388245\n",
            "Total elapsed time: 00h 00m 33s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Results summary\n",
            "Results in my_dir/255245112154156315312654245298\n",
            "Showing 10 best trials\n",
            "Objective(name='val_mean_absolute_error', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "drop_rate: 0.1\n",
            "activation: relu\n",
            "num_layers: 4\n",
            "units_0: 46\n",
            "units_1: 34\n",
            "optimizer: adam\n",
            "units_2: 28\n",
            "units_3: 33\n",
            "Score: 0.28988781571388245\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "drop_rate: 0.0\n",
            "activation: relu\n",
            "num_layers: 2\n",
            "units_0: 40\n",
            "units_1: 26\n",
            "optimizer: adam\n",
            "units_2: 37\n",
            "units_3: 46\n",
            "Score: 0.3273644646008809\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "drop_rate: 0.0\n",
            "activation: tanh\n",
            "num_layers: 4\n",
            "units_0: 33\n",
            "units_1: 21\n",
            "optimizer: adam\n",
            "units_2: 5\n",
            "units_3: 5\n",
            "Score: 0.37996700406074524\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "drop_rate: 0.1\n",
            "activation: tanh\n",
            "num_layers: 3\n",
            "units_0: 30\n",
            "units_1: 24\n",
            "optimizer: sgd\n",
            "units_2: 15\n",
            "units_3: 47\n",
            "Score: 0.46487213174502057\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "drop_rate: 0.3\n",
            "activation: tanh\n",
            "num_layers: 4\n",
            "units_0: 6\n",
            "units_1: 47\n",
            "optimizer: rmsprop\n",
            "units_2: 9\n",
            "units_3: 42\n",
            "Score: 0.49087435007095337\n",
            "Epoch 1/300\n",
            "7/7 [==============================] - 1s 22ms/step - loss: 0.7361 - mean_absolute_error: 0.7361 - val_loss: 0.8917 - val_mean_absolute_error: 0.8917\n",
            "Epoch 2/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6332 - mean_absolute_error: 0.6332 - val_loss: 0.8900 - val_mean_absolute_error: 0.8900\n",
            "Epoch 3/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6274 - mean_absolute_error: 0.6274 - val_loss: 0.8622 - val_mean_absolute_error: 0.8622\n",
            "Epoch 4/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5614 - mean_absolute_error: 0.5614 - val_loss: 0.8303 - val_mean_absolute_error: 0.8303\n",
            "Epoch 5/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5519 - mean_absolute_error: 0.5519 - val_loss: 0.7990 - val_mean_absolute_error: 0.7990\n",
            "Epoch 6/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5133 - mean_absolute_error: 0.5133 - val_loss: 0.7765 - val_mean_absolute_error: 0.7765\n",
            "Epoch 7/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5086 - mean_absolute_error: 0.5086 - val_loss: 0.7596 - val_mean_absolute_error: 0.7596\n",
            "Epoch 8/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4905 - mean_absolute_error: 0.4905 - val_loss: 0.7407 - val_mean_absolute_error: 0.7407\n",
            "Epoch 9/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4745 - mean_absolute_error: 0.4745 - val_loss: 0.7192 - val_mean_absolute_error: 0.7192\n",
            "Epoch 10/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4519 - mean_absolute_error: 0.4519 - val_loss: 0.6862 - val_mean_absolute_error: 0.6862\n",
            "Epoch 11/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4287 - mean_absolute_error: 0.4287 - val_loss: 0.6496 - val_mean_absolute_error: 0.6496\n",
            "Epoch 12/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4302 - mean_absolute_error: 0.4302 - val_loss: 0.6094 - val_mean_absolute_error: 0.6094\n",
            "Epoch 13/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3942 - mean_absolute_error: 0.3942 - val_loss: 0.5838 - val_mean_absolute_error: 0.5838\n",
            "Epoch 14/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3782 - mean_absolute_error: 0.3782 - val_loss: 0.5574 - val_mean_absolute_error: 0.5574\n",
            "Epoch 15/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3506 - mean_absolute_error: 0.3506 - val_loss: 0.5474 - val_mean_absolute_error: 0.5474\n",
            "Epoch 16/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3291 - mean_absolute_error: 0.3291 - val_loss: 0.5337 - val_mean_absolute_error: 0.5337\n",
            "Epoch 17/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.5252 - val_mean_absolute_error: 0.5252\n",
            "Epoch 18/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3062 - mean_absolute_error: 0.3062 - val_loss: 0.5255 - val_mean_absolute_error: 0.5255\n",
            "Epoch 19/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2646 - mean_absolute_error: 0.2646 - val_loss: 0.5121 - val_mean_absolute_error: 0.5121\n",
            "Epoch 20/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2687 - mean_absolute_error: 0.2687 - val_loss: 0.4975 - val_mean_absolute_error: 0.4975\n",
            "Epoch 21/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2421 - mean_absolute_error: 0.2421 - val_loss: 0.4740 - val_mean_absolute_error: 0.4740\n",
            "Epoch 22/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2474 - mean_absolute_error: 0.2474 - val_loss: 0.4986 - val_mean_absolute_error: 0.4986\n",
            "Epoch 23/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2276 - mean_absolute_error: 0.2276 - val_loss: 0.4575 - val_mean_absolute_error: 0.4575\n",
            "Epoch 24/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2511 - mean_absolute_error: 0.2511 - val_loss: 0.4135 - val_mean_absolute_error: 0.4135\n",
            "Epoch 25/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2298 - mean_absolute_error: 0.2298 - val_loss: 0.4336 - val_mean_absolute_error: 0.4336\n",
            "Epoch 26/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2130 - mean_absolute_error: 0.2130 - val_loss: 0.4210 - val_mean_absolute_error: 0.4210\n",
            "Epoch 27/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2112 - mean_absolute_error: 0.2112 - val_loss: 0.3997 - val_mean_absolute_error: 0.3997\n",
            "Epoch 28/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2325 - mean_absolute_error: 0.2325 - val_loss: 0.4181 - val_mean_absolute_error: 0.4181\n",
            "Epoch 29/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1983 - mean_absolute_error: 0.1983 - val_loss: 0.4269 - val_mean_absolute_error: 0.4269\n",
            "Epoch 30/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.2112 - mean_absolute_error: 0.2112 - val_loss: 0.3968 - val_mean_absolute_error: 0.3968\n",
            "Epoch 31/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2021 - mean_absolute_error: 0.2021 - val_loss: 0.4088 - val_mean_absolute_error: 0.4088\n",
            "Epoch 32/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1793 - mean_absolute_error: 0.1793 - val_loss: 0.4094 - val_mean_absolute_error: 0.4094\n",
            "Epoch 33/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1892 - mean_absolute_error: 0.1892 - val_loss: 0.3852 - val_mean_absolute_error: 0.3852\n",
            "Epoch 34/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1736 - mean_absolute_error: 0.1736 - val_loss: 0.3327 - val_mean_absolute_error: 0.3327\n",
            "Epoch 35/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1610 - mean_absolute_error: 0.1610 - val_loss: 0.3456 - val_mean_absolute_error: 0.3456\n",
            "Epoch 36/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1852 - mean_absolute_error: 0.1852 - val_loss: 0.3124 - val_mean_absolute_error: 0.3124\n",
            "Epoch 37/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1822 - mean_absolute_error: 0.1822 - val_loss: 0.3497 - val_mean_absolute_error: 0.3497\n",
            "Epoch 38/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1833 - mean_absolute_error: 0.1833 - val_loss: 0.3594 - val_mean_absolute_error: 0.3594\n",
            "Epoch 39/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1669 - mean_absolute_error: 0.1669 - val_loss: 0.2961 - val_mean_absolute_error: 0.2961\n",
            "Epoch 40/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1856 - mean_absolute_error: 0.1856 - val_loss: 0.2924 - val_mean_absolute_error: 0.2924\n",
            "Epoch 41/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1616 - mean_absolute_error: 0.1616 - val_loss: 0.3260 - val_mean_absolute_error: 0.3260\n",
            "Epoch 42/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1690 - mean_absolute_error: 0.1690 - val_loss: 0.3818 - val_mean_absolute_error: 0.3818\n",
            "Epoch 43/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1638 - mean_absolute_error: 0.1638 - val_loss: 0.3538 - val_mean_absolute_error: 0.3538\n",
            "Epoch 44/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1625 - mean_absolute_error: 0.1625 - val_loss: 0.3542 - val_mean_absolute_error: 0.3542\n",
            "Epoch 45/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1648 - mean_absolute_error: 0.1648 - val_loss: 0.3272 - val_mean_absolute_error: 0.3272\n",
            "Epoch 46/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1737 - mean_absolute_error: 0.1737 - val_loss: 0.3288 - val_mean_absolute_error: 0.3288\n",
            "Epoch 47/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1564 - mean_absolute_error: 0.1564 - val_loss: 0.3400 - val_mean_absolute_error: 0.3400\n",
            "Epoch 48/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1798 - mean_absolute_error: 0.1798 - val_loss: 0.3494 - val_mean_absolute_error: 0.3494\n",
            "Epoch 49/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1438 - mean_absolute_error: 0.1438 - val_loss: 0.3076 - val_mean_absolute_error: 0.3076\n",
            "Epoch 50/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1736 - mean_absolute_error: 0.1736 - val_loss: 0.2787 - val_mean_absolute_error: 0.2787\n",
            "Epoch 51/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1476 - mean_absolute_error: 0.1476 - val_loss: 0.2945 - val_mean_absolute_error: 0.2945\n",
            "Epoch 52/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1634 - mean_absolute_error: 0.1634 - val_loss: 0.2795 - val_mean_absolute_error: 0.2795\n",
            "Epoch 53/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1443 - mean_absolute_error: 0.1443 - val_loss: 0.2858 - val_mean_absolute_error: 0.2858\n",
            "Epoch 54/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1420 - mean_absolute_error: 0.1420 - val_loss: 0.2896 - val_mean_absolute_error: 0.2896\n",
            "Epoch 55/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1583 - mean_absolute_error: 0.1583 - val_loss: 0.2481 - val_mean_absolute_error: 0.2481\n",
            "Epoch 56/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1404 - mean_absolute_error: 0.1404 - val_loss: 0.3052 - val_mean_absolute_error: 0.3052\n",
            "Epoch 57/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1682 - mean_absolute_error: 0.1682 - val_loss: 0.3180 - val_mean_absolute_error: 0.3180\n",
            "Epoch 58/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.3102 - val_mean_absolute_error: 0.3102\n",
            "Epoch 59/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1222 - mean_absolute_error: 0.1222 - val_loss: 0.2795 - val_mean_absolute_error: 0.2795\n",
            "Epoch 60/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1398 - mean_absolute_error: 0.1398 - val_loss: 0.3016 - val_mean_absolute_error: 0.3016\n",
            "Epoch 61/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1209 - mean_absolute_error: 0.1209 - val_loss: 0.3307 - val_mean_absolute_error: 0.3307\n",
            "Epoch 62/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1254 - mean_absolute_error: 0.1254 - val_loss: 0.3307 - val_mean_absolute_error: 0.3307\n",
            "Epoch 63/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1448 - mean_absolute_error: 0.1448 - val_loss: 0.2842 - val_mean_absolute_error: 0.2842\n",
            "Epoch 64/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1267 - mean_absolute_error: 0.1267 - val_loss: 0.2588 - val_mean_absolute_error: 0.2588\n",
            "Epoch 65/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1287 - mean_absolute_error: 0.1287 - val_loss: 0.2881 - val_mean_absolute_error: 0.2881\n",
            "Epoch 66/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1382 - mean_absolute_error: 0.1382 - val_loss: 0.2938 - val_mean_absolute_error: 0.2938\n",
            "Epoch 67/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1398 - mean_absolute_error: 0.1398 - val_loss: 0.2835 - val_mean_absolute_error: 0.2835\n",
            "Epoch 68/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1083 - mean_absolute_error: 0.1083 - val_loss: 0.2706 - val_mean_absolute_error: 0.2706\n",
            "Epoch 69/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1096 - mean_absolute_error: 0.1096 - val_loss: 0.2573 - val_mean_absolute_error: 0.2573\n",
            "Epoch 70/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1076 - mean_absolute_error: 0.1076 - val_loss: 0.2420 - val_mean_absolute_error: 0.2420\n",
            "Epoch 71/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1184 - mean_absolute_error: 0.1184 - val_loss: 0.2496 - val_mean_absolute_error: 0.2496\n",
            "Epoch 72/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1179 - mean_absolute_error: 0.1179 - val_loss: 0.2411 - val_mean_absolute_error: 0.2411\n",
            "Epoch 73/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1207 - mean_absolute_error: 0.1207 - val_loss: 0.2924 - val_mean_absolute_error: 0.2924\n",
            "Epoch 74/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1284 - mean_absolute_error: 0.1284 - val_loss: 0.2473 - val_mean_absolute_error: 0.2473\n",
            "Epoch 75/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1117 - mean_absolute_error: 0.1117 - val_loss: 0.2523 - val_mean_absolute_error: 0.2523\n",
            "Epoch 76/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0980 - mean_absolute_error: 0.0980 - val_loss: 0.2459 - val_mean_absolute_error: 0.2459\n",
            "Epoch 77/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1145 - mean_absolute_error: 0.1145 - val_loss: 0.2322 - val_mean_absolute_error: 0.2322\n",
            "Epoch 78/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1282 - mean_absolute_error: 0.1282 - val_loss: 0.2351 - val_mean_absolute_error: 0.2351\n",
            "Epoch 79/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1056 - mean_absolute_error: 0.1056 - val_loss: 0.2532 - val_mean_absolute_error: 0.2532\n",
            "Epoch 80/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1181 - mean_absolute_error: 0.1181 - val_loss: 0.2489 - val_mean_absolute_error: 0.2489\n",
            "Epoch 81/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1027 - mean_absolute_error: 0.1027 - val_loss: 0.2578 - val_mean_absolute_error: 0.2578\n",
            "Epoch 82/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1072 - mean_absolute_error: 0.1072 - val_loss: 0.2692 - val_mean_absolute_error: 0.2692\n",
            "Epoch 83/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1073 - mean_absolute_error: 0.1073 - val_loss: 0.2383 - val_mean_absolute_error: 0.2383\n",
            "Epoch 84/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1255 - mean_absolute_error: 0.1255 - val_loss: 0.2275 - val_mean_absolute_error: 0.2275\n",
            "Epoch 85/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1221 - mean_absolute_error: 0.1221 - val_loss: 0.2171 - val_mean_absolute_error: 0.2171\n",
            "Epoch 86/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1153 - mean_absolute_error: 0.1153 - val_loss: 0.2208 - val_mean_absolute_error: 0.2208\n",
            "Epoch 87/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1035 - mean_absolute_error: 0.1035 - val_loss: 0.2376 - val_mean_absolute_error: 0.2376\n",
            "Epoch 88/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1256 - mean_absolute_error: 0.1256 - val_loss: 0.2563 - val_mean_absolute_error: 0.2563\n",
            "Epoch 89/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1091 - mean_absolute_error: 0.1091 - val_loss: 0.2374 - val_mean_absolute_error: 0.2374\n",
            "Epoch 90/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1288 - mean_absolute_error: 0.1288 - val_loss: 0.2445 - val_mean_absolute_error: 0.2445\n",
            "Epoch 91/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1016 - mean_absolute_error: 0.1016 - val_loss: 0.2439 - val_mean_absolute_error: 0.2439\n",
            "Epoch 92/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1167 - mean_absolute_error: 0.1167 - val_loss: 0.2221 - val_mean_absolute_error: 0.2221\n",
            "Epoch 93/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1232 - mean_absolute_error: 0.1232 - val_loss: 0.2507 - val_mean_absolute_error: 0.2507\n",
            "Epoch 94/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1000 - mean_absolute_error: 0.1000 - val_loss: 0.2032 - val_mean_absolute_error: 0.2032\n",
            "Epoch 95/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1275 - mean_absolute_error: 0.1275 - val_loss: 0.2124 - val_mean_absolute_error: 0.2124\n",
            "Epoch 96/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1386 - mean_absolute_error: 0.1386 - val_loss: 0.2324 - val_mean_absolute_error: 0.2324\n",
            "Epoch 97/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1135 - mean_absolute_error: 0.1135 - val_loss: 0.1875 - val_mean_absolute_error: 0.1875\n",
            "Epoch 98/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1668 - mean_absolute_error: 0.1668 - val_loss: 0.1892 - val_mean_absolute_error: 0.1892\n",
            "Epoch 99/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1285 - mean_absolute_error: 0.1285 - val_loss: 0.1747 - val_mean_absolute_error: 0.1747\n",
            "Epoch 100/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1185 - mean_absolute_error: 0.1185 - val_loss: 0.2268 - val_mean_absolute_error: 0.2268\n",
            "Epoch 101/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1121 - mean_absolute_error: 0.1121 - val_loss: 0.2015 - val_mean_absolute_error: 0.2015\n",
            "Epoch 102/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1178 - mean_absolute_error: 0.1178 - val_loss: 0.2120 - val_mean_absolute_error: 0.2120\n",
            "Epoch 103/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1127 - mean_absolute_error: 0.1127 - val_loss: 0.2404 - val_mean_absolute_error: 0.2404\n",
            "Epoch 104/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1294 - mean_absolute_error: 0.1294 - val_loss: 0.2099 - val_mean_absolute_error: 0.2099\n",
            "Epoch 105/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1047 - mean_absolute_error: 0.1047 - val_loss: 0.1976 - val_mean_absolute_error: 0.1976\n",
            "Epoch 106/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1025 - mean_absolute_error: 0.1025 - val_loss: 0.1910 - val_mean_absolute_error: 0.1910\n",
            "Epoch 107/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0910 - mean_absolute_error: 0.0910 - val_loss: 0.1811 - val_mean_absolute_error: 0.1811\n",
            "Epoch 108/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1140 - mean_absolute_error: 0.1140 - val_loss: 0.1829 - val_mean_absolute_error: 0.1829\n",
            "Epoch 109/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0949 - mean_absolute_error: 0.0949 - val_loss: 0.2049 - val_mean_absolute_error: 0.2049\n",
            "Epoch 110/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1158 - mean_absolute_error: 0.1158 - val_loss: 0.1868 - val_mean_absolute_error: 0.1868\n",
            "Epoch 111/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0895 - mean_absolute_error: 0.0895 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
            "Epoch 112/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1060 - mean_absolute_error: 0.1060 - val_loss: 0.1798 - val_mean_absolute_error: 0.1798\n",
            "Epoch 113/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1052 - mean_absolute_error: 0.1052 - val_loss: 0.1822 - val_mean_absolute_error: 0.1822\n",
            "Epoch 114/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1151 - mean_absolute_error: 0.1151 - val_loss: 0.2356 - val_mean_absolute_error: 0.2356\n",
            "Epoch 115/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0995 - mean_absolute_error: 0.0995 - val_loss: 0.1862 - val_mean_absolute_error: 0.1862\n",
            "Epoch 116/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0947 - mean_absolute_error: 0.0947 - val_loss: 0.2054 - val_mean_absolute_error: 0.2054\n",
            "Epoch 117/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0986 - mean_absolute_error: 0.0986 - val_loss: 0.2173 - val_mean_absolute_error: 0.2173\n",
            "Epoch 118/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1162 - mean_absolute_error: 0.1162 - val_loss: 0.2054 - val_mean_absolute_error: 0.2054\n",
            "Epoch 119/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1183 - mean_absolute_error: 0.1183 - val_loss: 0.2122 - val_mean_absolute_error: 0.2122\n",
            "Epoch 120/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0906 - mean_absolute_error: 0.0906 - val_loss: 0.2194 - val_mean_absolute_error: 0.2194\n",
            "Epoch 121/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1210 - mean_absolute_error: 0.1210 - val_loss: 0.2044 - val_mean_absolute_error: 0.2044\n",
            "Epoch 122/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0969 - mean_absolute_error: 0.0969 - val_loss: 0.2027 - val_mean_absolute_error: 0.2027\n",
            "Epoch 123/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0969 - mean_absolute_error: 0.0969 - val_loss: 0.1974 - val_mean_absolute_error: 0.1974\n",
            "Epoch 124/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0937 - mean_absolute_error: 0.0937 - val_loss: 0.2002 - val_mean_absolute_error: 0.2002\n",
            "Epoch 125/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0961 - mean_absolute_error: 0.0961 - val_loss: 0.1928 - val_mean_absolute_error: 0.1928\n",
            "Epoch 126/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1033 - mean_absolute_error: 0.1033 - val_loss: 0.1907 - val_mean_absolute_error: 0.1907\n",
            "Epoch 127/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0907 - mean_absolute_error: 0.0907 - val_loss: 0.2203 - val_mean_absolute_error: 0.2203\n",
            "Epoch 128/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0866 - mean_absolute_error: 0.0866 - val_loss: 0.2239 - val_mean_absolute_error: 0.2239\n",
            "Epoch 129/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1031 - mean_absolute_error: 0.1031 - val_loss: 0.2163 - val_mean_absolute_error: 0.2163\n",
            "Epoch 130/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0891 - mean_absolute_error: 0.0891 - val_loss: 0.2093 - val_mean_absolute_error: 0.2093\n",
            "Epoch 131/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1025 - mean_absolute_error: 0.1025 - val_loss: 0.2078 - val_mean_absolute_error: 0.2078\n",
            "Epoch 132/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0793 - mean_absolute_error: 0.0793 - val_loss: 0.2257 - val_mean_absolute_error: 0.2257\n",
            "Epoch 133/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0806 - mean_absolute_error: 0.0806 - val_loss: 0.2095 - val_mean_absolute_error: 0.2095\n",
            "Epoch 134/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1034 - mean_absolute_error: 0.1034 - val_loss: 0.1943 - val_mean_absolute_error: 0.1943\n",
            "Epoch 135/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0904 - mean_absolute_error: 0.0904 - val_loss: 0.2196 - val_mean_absolute_error: 0.2196\n",
            "Epoch 136/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0961 - mean_absolute_error: 0.0961 - val_loss: 0.2180 - val_mean_absolute_error: 0.2180\n",
            "Epoch 137/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1038 - mean_absolute_error: 0.1038 - val_loss: 0.2054 - val_mean_absolute_error: 0.2054\n",
            "Epoch 138/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0995 - mean_absolute_error: 0.0995 - val_loss: 0.2096 - val_mean_absolute_error: 0.2096\n",
            "Epoch 139/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1051 - mean_absolute_error: 0.1051 - val_loss: 0.2119 - val_mean_absolute_error: 0.2119\n",
            "Epoch 140/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1013 - mean_absolute_error: 0.1013 - val_loss: 0.1952 - val_mean_absolute_error: 0.1952\n",
            "Epoch 141/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0905 - mean_absolute_error: 0.0905 - val_loss: 0.2283 - val_mean_absolute_error: 0.2283\n",
            "Epoch 142/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0892 - mean_absolute_error: 0.0892 - val_loss: 0.2288 - val_mean_absolute_error: 0.2288\n",
            "Epoch 143/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1150 - mean_absolute_error: 0.1150 - val_loss: 0.1967 - val_mean_absolute_error: 0.1967\n",
            "Epoch 144/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0875 - mean_absolute_error: 0.0875 - val_loss: 0.2150 - val_mean_absolute_error: 0.2150\n",
            "Epoch 145/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1043 - mean_absolute_error: 0.1043 - val_loss: 0.2068 - val_mean_absolute_error: 0.2068\n",
            "Epoch 146/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0746 - mean_absolute_error: 0.0746 - val_loss: 0.1876 - val_mean_absolute_error: 0.1876\n",
            "Epoch 147/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1067 - mean_absolute_error: 0.1067 - val_loss: 0.1953 - val_mean_absolute_error: 0.1953\n",
            "Epoch 148/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0987 - mean_absolute_error: 0.0987 - val_loss: 0.1944 - val_mean_absolute_error: 0.1944\n",
            "Epoch 149/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1029 - mean_absolute_error: 0.1029 - val_loss: 0.1719 - val_mean_absolute_error: 0.1719\n",
            "Epoch 150/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0887 - mean_absolute_error: 0.0887 - val_loss: 0.1928 - val_mean_absolute_error: 0.1928\n",
            "Epoch 151/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0963 - mean_absolute_error: 0.0963 - val_loss: 0.1940 - val_mean_absolute_error: 0.1940\n",
            "Epoch 152/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0888 - mean_absolute_error: 0.0888 - val_loss: 0.2204 - val_mean_absolute_error: 0.2204\n",
            "Epoch 153/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1097 - mean_absolute_error: 0.1097 - val_loss: 0.1806 - val_mean_absolute_error: 0.1806\n",
            "Epoch 154/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1039 - mean_absolute_error: 0.1039 - val_loss: 0.1962 - val_mean_absolute_error: 0.1962\n",
            "Epoch 155/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1114 - mean_absolute_error: 0.1114 - val_loss: 0.1875 - val_mean_absolute_error: 0.1875\n",
            "Epoch 156/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0930 - mean_absolute_error: 0.0930 - val_loss: 0.1951 - val_mean_absolute_error: 0.1951\n",
            "Epoch 157/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1095 - mean_absolute_error: 0.1095 - val_loss: 0.2064 - val_mean_absolute_error: 0.2064\n",
            "Epoch 158/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1197 - mean_absolute_error: 0.1197 - val_loss: 0.1919 - val_mean_absolute_error: 0.1919\n",
            "Epoch 159/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0877 - mean_absolute_error: 0.0877 - val_loss: 0.1860 - val_mean_absolute_error: 0.1860\n",
            "Epoch 160/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0948 - mean_absolute_error: 0.0948 - val_loss: 0.1621 - val_mean_absolute_error: 0.1621\n",
            "Epoch 161/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0947 - mean_absolute_error: 0.0947 - val_loss: 0.1819 - val_mean_absolute_error: 0.1819\n",
            "Epoch 162/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0995 - mean_absolute_error: 0.0995 - val_loss: 0.1869 - val_mean_absolute_error: 0.1869\n",
            "Epoch 163/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0979 - mean_absolute_error: 0.0979 - val_loss: 0.1790 - val_mean_absolute_error: 0.1790\n",
            "Epoch 164/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0899 - mean_absolute_error: 0.0899 - val_loss: 0.2035 - val_mean_absolute_error: 0.2035\n",
            "Epoch 165/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1093 - mean_absolute_error: 0.1093 - val_loss: 0.2080 - val_mean_absolute_error: 0.2080\n",
            "Epoch 166/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0779 - mean_absolute_error: 0.0779 - val_loss: 0.1926 - val_mean_absolute_error: 0.1926\n",
            "Epoch 167/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1033 - mean_absolute_error: 0.1033 - val_loss: 0.1895 - val_mean_absolute_error: 0.1895\n",
            "Epoch 168/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.2098 - val_mean_absolute_error: 0.2098\n",
            "Epoch 169/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1047 - mean_absolute_error: 0.1047 - val_loss: 0.2125 - val_mean_absolute_error: 0.2125\n",
            "Epoch 170/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0901 - mean_absolute_error: 0.0901 - val_loss: 0.1787 - val_mean_absolute_error: 0.1787\n",
            "Epoch 171/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0963 - mean_absolute_error: 0.0963 - val_loss: 0.1780 - val_mean_absolute_error: 0.1780\n",
            "Epoch 172/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0998 - mean_absolute_error: 0.0998 - val_loss: 0.1743 - val_mean_absolute_error: 0.1743\n",
            "Epoch 173/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0865 - mean_absolute_error: 0.0865 - val_loss: 0.1892 - val_mean_absolute_error: 0.1892\n",
            "Epoch 174/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0898 - mean_absolute_error: 0.0898 - val_loss: 0.1930 - val_mean_absolute_error: 0.1930\n",
            "Epoch 175/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0959 - mean_absolute_error: 0.0959 - val_loss: 0.1913 - val_mean_absolute_error: 0.1913\n",
            "Epoch 176/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0890 - mean_absolute_error: 0.0890 - val_loss: 0.2102 - val_mean_absolute_error: 0.2102\n",
            "Epoch 177/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0965 - mean_absolute_error: 0.0965 - val_loss: 0.2092 - val_mean_absolute_error: 0.2092\n",
            "Epoch 178/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0984 - mean_absolute_error: 0.0984 - val_loss: 0.2058 - val_mean_absolute_error: 0.2058\n",
            "Epoch 179/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0918 - mean_absolute_error: 0.0918 - val_loss: 0.2120 - val_mean_absolute_error: 0.2120\n",
            "Epoch 180/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1004 - mean_absolute_error: 0.1004 - val_loss: 0.1896 - val_mean_absolute_error: 0.1896\n",
            "Epoch 181/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0817 - mean_absolute_error: 0.0817 - val_loss: 0.2022 - val_mean_absolute_error: 0.2022\n",
            "Epoch 182/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0973 - mean_absolute_error: 0.0973 - val_loss: 0.2114 - val_mean_absolute_error: 0.2114\n",
            "Epoch 183/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0859 - mean_absolute_error: 0.0859 - val_loss: 0.1904 - val_mean_absolute_error: 0.1904\n",
            "Epoch 184/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0842 - mean_absolute_error: 0.0842 - val_loss: 0.2048 - val_mean_absolute_error: 0.2048\n",
            "Epoch 185/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0957 - mean_absolute_error: 0.0957 - val_loss: 0.2053 - val_mean_absolute_error: 0.2053\n",
            "Epoch 186/300\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1004 - mean_absolute_error: 0.1004 - val_loss: 0.1980 - val_mean_absolute_error: 0.1980\n",
            "Epoch 187/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0915 - mean_absolute_error: 0.0915 - val_loss: 0.2001 - val_mean_absolute_error: 0.2001\n",
            "Epoch 188/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0767 - mean_absolute_error: 0.0767 - val_loss: 0.1992 - val_mean_absolute_error: 0.1992\n",
            "Epoch 189/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0889 - mean_absolute_error: 0.0889 - val_loss: 0.1916 - val_mean_absolute_error: 0.1916\n",
            "Epoch 190/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0784 - mean_absolute_error: 0.0784 - val_loss: 0.1831 - val_mean_absolute_error: 0.1831\n",
            "Epoch 191/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0753 - mean_absolute_error: 0.0753 - val_loss: 0.1885 - val_mean_absolute_error: 0.1885\n",
            "Epoch 192/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0701 - mean_absolute_error: 0.0701 - val_loss: 0.1941 - val_mean_absolute_error: 0.1941\n",
            "Epoch 193/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0846 - mean_absolute_error: 0.0846 - val_loss: 0.2043 - val_mean_absolute_error: 0.2043\n",
            "Epoch 194/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0883 - mean_absolute_error: 0.0883 - val_loss: 0.2062 - val_mean_absolute_error: 0.2062\n",
            "Epoch 195/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0802 - mean_absolute_error: 0.0802 - val_loss: 0.1928 - val_mean_absolute_error: 0.1928\n",
            "Epoch 196/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.2217 - val_mean_absolute_error: 0.2217\n",
            "Epoch 197/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0907 - mean_absolute_error: 0.0907 - val_loss: 0.2226 - val_mean_absolute_error: 0.2226\n",
            "Epoch 198/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.2197 - val_mean_absolute_error: 0.2197\n",
            "Epoch 199/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0758 - mean_absolute_error: 0.0758 - val_loss: 0.2081 - val_mean_absolute_error: 0.2081\n",
            "Epoch 200/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0992 - mean_absolute_error: 0.0992 - val_loss: 0.1978 - val_mean_absolute_error: 0.1978\n",
            "Epoch 201/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0994 - mean_absolute_error: 0.0994 - val_loss: 0.1906 - val_mean_absolute_error: 0.1906\n",
            "Epoch 202/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0887 - mean_absolute_error: 0.0887 - val_loss: 0.1986 - val_mean_absolute_error: 0.1986\n",
            "Epoch 203/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0845 - mean_absolute_error: 0.0845 - val_loss: 0.2087 - val_mean_absolute_error: 0.2087\n",
            "Epoch 204/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0992 - mean_absolute_error: 0.0992 - val_loss: 0.1968 - val_mean_absolute_error: 0.1968\n",
            "Epoch 205/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0803 - mean_absolute_error: 0.0803 - val_loss: 0.1968 - val_mean_absolute_error: 0.1968\n",
            "Epoch 206/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0818 - mean_absolute_error: 0.0818 - val_loss: 0.2138 - val_mean_absolute_error: 0.2138\n",
            "Epoch 207/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0814 - mean_absolute_error: 0.0814 - val_loss: 0.2028 - val_mean_absolute_error: 0.2028\n",
            "Epoch 208/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0852 - mean_absolute_error: 0.0852 - val_loss: 0.2013 - val_mean_absolute_error: 0.2013\n",
            "Epoch 209/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0812 - mean_absolute_error: 0.0812 - val_loss: 0.2071 - val_mean_absolute_error: 0.2071\n",
            "Epoch 210/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0796 - mean_absolute_error: 0.0796 - val_loss: 0.2059 - val_mean_absolute_error: 0.2059\n",
            "Epoch 211/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0980 - mean_absolute_error: 0.0980 - val_loss: 0.2010 - val_mean_absolute_error: 0.2010\n",
            "Epoch 212/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1120 - mean_absolute_error: 0.1120 - val_loss: 0.2123 - val_mean_absolute_error: 0.2123\n",
            "Epoch 213/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0965 - mean_absolute_error: 0.0965 - val_loss: 0.2120 - val_mean_absolute_error: 0.2120\n",
            "Epoch 214/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0956 - mean_absolute_error: 0.0956 - val_loss: 0.2073 - val_mean_absolute_error: 0.2073\n",
            "Epoch 215/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0919 - mean_absolute_error: 0.0919 - val_loss: 0.1804 - val_mean_absolute_error: 0.1804\n",
            "Epoch 216/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0912 - mean_absolute_error: 0.0912 - val_loss: 0.1846 - val_mean_absolute_error: 0.1846\n",
            "Epoch 217/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0811 - mean_absolute_error: 0.0811 - val_loss: 0.2081 - val_mean_absolute_error: 0.2081\n",
            "Epoch 218/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0964 - mean_absolute_error: 0.0964 - val_loss: 0.2122 - val_mean_absolute_error: 0.2122\n",
            "Epoch 219/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0896 - mean_absolute_error: 0.0896 - val_loss: 0.2095 - val_mean_absolute_error: 0.2095\n",
            "Epoch 220/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0938 - mean_absolute_error: 0.0938 - val_loss: 0.1964 - val_mean_absolute_error: 0.1964\n",
            "Epoch 221/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0876 - mean_absolute_error: 0.0876 - val_loss: 0.1927 - val_mean_absolute_error: 0.1927\n",
            "Epoch 222/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0930 - mean_absolute_error: 0.0930 - val_loss: 0.1980 - val_mean_absolute_error: 0.1980\n",
            "Epoch 223/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0838 - mean_absolute_error: 0.0838 - val_loss: 0.1818 - val_mean_absolute_error: 0.1818\n",
            "Epoch 224/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0806 - mean_absolute_error: 0.0806 - val_loss: 0.1692 - val_mean_absolute_error: 0.1692\n",
            "Epoch 225/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.1940 - val_mean_absolute_error: 0.1940\n",
            "Epoch 226/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0912 - mean_absolute_error: 0.0912 - val_loss: 0.2036 - val_mean_absolute_error: 0.2036\n",
            "Epoch 227/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0807 - mean_absolute_error: 0.0807 - val_loss: 0.1961 - val_mean_absolute_error: 0.1961\n",
            "Epoch 228/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0945 - mean_absolute_error: 0.0945 - val_loss: 0.2041 - val_mean_absolute_error: 0.2041\n",
            "Epoch 229/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0853 - mean_absolute_error: 0.0853 - val_loss: 0.2160 - val_mean_absolute_error: 0.2160\n",
            "Epoch 230/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0924 - mean_absolute_error: 0.0924 - val_loss: 0.1853 - val_mean_absolute_error: 0.1853\n",
            "Epoch 231/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0806 - mean_absolute_error: 0.0806 - val_loss: 0.1886 - val_mean_absolute_error: 0.1886\n",
            "Epoch 232/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0911 - mean_absolute_error: 0.0911 - val_loss: 0.1816 - val_mean_absolute_error: 0.1816\n",
            "Epoch 233/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.1808 - val_mean_absolute_error: 0.1808\n",
            "Epoch 234/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0885 - mean_absolute_error: 0.0885 - val_loss: 0.1516 - val_mean_absolute_error: 0.1516\n",
            "Epoch 235/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0863 - mean_absolute_error: 0.0863 - val_loss: 0.1603 - val_mean_absolute_error: 0.1603\n",
            "Epoch 236/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0917 - mean_absolute_error: 0.0917 - val_loss: 0.1569 - val_mean_absolute_error: 0.1569\n",
            "Epoch 237/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0759 - mean_absolute_error: 0.0759 - val_loss: 0.1879 - val_mean_absolute_error: 0.1879\n",
            "Epoch 238/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0771 - mean_absolute_error: 0.0771 - val_loss: 0.2125 - val_mean_absolute_error: 0.2125\n",
            "Epoch 239/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.2025 - val_mean_absolute_error: 0.2025\n",
            "Epoch 240/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0697 - mean_absolute_error: 0.0697 - val_loss: 0.1835 - val_mean_absolute_error: 0.1835\n",
            "Epoch 241/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1019 - mean_absolute_error: 0.1019 - val_loss: 0.1911 - val_mean_absolute_error: 0.1911\n",
            "Epoch 242/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0897 - mean_absolute_error: 0.0897 - val_loss: 0.2159 - val_mean_absolute_error: 0.2159\n",
            "Epoch 243/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0949 - mean_absolute_error: 0.0949 - val_loss: 0.2042 - val_mean_absolute_error: 0.2042\n",
            "Epoch 244/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0920 - mean_absolute_error: 0.0920 - val_loss: 0.1864 - val_mean_absolute_error: 0.1864\n",
            "Epoch 245/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0922 - mean_absolute_error: 0.0922 - val_loss: 0.1853 - val_mean_absolute_error: 0.1853\n",
            "Epoch 246/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0787 - mean_absolute_error: 0.0787 - val_loss: 0.1753 - val_mean_absolute_error: 0.1753\n",
            "Epoch 247/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0947 - mean_absolute_error: 0.0947 - val_loss: 0.1812 - val_mean_absolute_error: 0.1812\n",
            "Epoch 248/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0774 - mean_absolute_error: 0.0774 - val_loss: 0.1959 - val_mean_absolute_error: 0.1959\n",
            "Epoch 249/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0962 - mean_absolute_error: 0.0962 - val_loss: 0.1686 - val_mean_absolute_error: 0.1686\n",
            "Epoch 250/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0994 - mean_absolute_error: 0.0994 - val_loss: 0.1981 - val_mean_absolute_error: 0.1981\n",
            "Epoch 251/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1002 - mean_absolute_error: 0.1002 - val_loss: 0.2009 - val_mean_absolute_error: 0.2009\n",
            "Epoch 252/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0961 - mean_absolute_error: 0.0961 - val_loss: 0.1682 - val_mean_absolute_error: 0.1682\n",
            "Epoch 253/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0796 - mean_absolute_error: 0.0796 - val_loss: 0.1705 - val_mean_absolute_error: 0.1705\n",
            "Epoch 254/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0961 - mean_absolute_error: 0.0961 - val_loss: 0.1679 - val_mean_absolute_error: 0.1679\n",
            "Epoch 255/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0785 - mean_absolute_error: 0.0785 - val_loss: 0.1681 - val_mean_absolute_error: 0.1681\n",
            "Epoch 256/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0860 - mean_absolute_error: 0.0860 - val_loss: 0.1628 - val_mean_absolute_error: 0.1628\n",
            "Epoch 257/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0744 - mean_absolute_error: 0.0744 - val_loss: 0.2059 - val_mean_absolute_error: 0.2059\n",
            "Epoch 258/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0975 - mean_absolute_error: 0.0975 - val_loss: 0.1757 - val_mean_absolute_error: 0.1757\n",
            "Epoch 259/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1070 - mean_absolute_error: 0.1070 - val_loss: 0.1579 - val_mean_absolute_error: 0.1579\n",
            "Epoch 260/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0929 - mean_absolute_error: 0.0929 - val_loss: 0.2113 - val_mean_absolute_error: 0.2113\n",
            "Epoch 261/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1010 - mean_absolute_error: 0.1010 - val_loss: 0.1846 - val_mean_absolute_error: 0.1846\n",
            "Epoch 262/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0900 - mean_absolute_error: 0.0900 - val_loss: 0.1624 - val_mean_absolute_error: 0.1624\n",
            "Epoch 263/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0901 - mean_absolute_error: 0.0901 - val_loss: 0.1608 - val_mean_absolute_error: 0.1608\n",
            "Epoch 264/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0807 - mean_absolute_error: 0.0807 - val_loss: 0.1793 - val_mean_absolute_error: 0.1793\n",
            "Epoch 265/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0774 - mean_absolute_error: 0.0774 - val_loss: 0.1687 - val_mean_absolute_error: 0.1687\n",
            "Epoch 266/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0786 - mean_absolute_error: 0.0786 - val_loss: 0.1765 - val_mean_absolute_error: 0.1765\n",
            "Epoch 267/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0775 - mean_absolute_error: 0.0775 - val_loss: 0.2045 - val_mean_absolute_error: 0.2045\n",
            "Epoch 268/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.1821 - val_mean_absolute_error: 0.1821\n",
            "Epoch 269/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0974 - mean_absolute_error: 0.0974 - val_loss: 0.1848 - val_mean_absolute_error: 0.1848\n",
            "Epoch 270/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0783 - mean_absolute_error: 0.0783 - val_loss: 0.1691 - val_mean_absolute_error: 0.1691\n",
            "Epoch 271/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0897 - mean_absolute_error: 0.0897 - val_loss: 0.1950 - val_mean_absolute_error: 0.1950\n",
            "Epoch 272/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.1971 - val_mean_absolute_error: 0.1971\n",
            "Epoch 273/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0717 - mean_absolute_error: 0.0717 - val_loss: 0.1989 - val_mean_absolute_error: 0.1989\n",
            "Epoch 274/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.2042 - val_mean_absolute_error: 0.2042\n",
            "Epoch 275/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0879 - mean_absolute_error: 0.0879 - val_loss: 0.1997 - val_mean_absolute_error: 0.1997\n",
            "Epoch 276/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0868 - mean_absolute_error: 0.0868 - val_loss: 0.1942 - val_mean_absolute_error: 0.1942\n",
            "Epoch 277/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0944 - mean_absolute_error: 0.0944 - val_loss: 0.1893 - val_mean_absolute_error: 0.1893\n",
            "Epoch 278/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.1986 - val_mean_absolute_error: 0.1986\n",
            "Epoch 279/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0736 - mean_absolute_error: 0.0736 - val_loss: 0.2004 - val_mean_absolute_error: 0.2004\n",
            "Epoch 280/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0790 - mean_absolute_error: 0.0790 - val_loss: 0.2001 - val_mean_absolute_error: 0.2001\n",
            "Epoch 281/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.1754 - val_mean_absolute_error: 0.1754\n",
            "Epoch 282/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0800 - mean_absolute_error: 0.0800 - val_loss: 0.1966 - val_mean_absolute_error: 0.1966\n",
            "Epoch 283/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0847 - mean_absolute_error: 0.0847 - val_loss: 0.1772 - val_mean_absolute_error: 0.1772\n",
            "Epoch 284/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.1715 - val_mean_absolute_error: 0.1715\n",
            "Epoch 285/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0817 - mean_absolute_error: 0.0817 - val_loss: 0.1800 - val_mean_absolute_error: 0.1800\n",
            "Epoch 286/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0942 - mean_absolute_error: 0.0942 - val_loss: 0.1963 - val_mean_absolute_error: 0.1963\n",
            "Epoch 287/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0879 - mean_absolute_error: 0.0879 - val_loss: 0.1883 - val_mean_absolute_error: 0.1883\n",
            "Epoch 288/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0803 - mean_absolute_error: 0.0803 - val_loss: 0.1889 - val_mean_absolute_error: 0.1889\n",
            "Epoch 289/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0861 - mean_absolute_error: 0.0861 - val_loss: 0.2087 - val_mean_absolute_error: 0.2087\n",
            "Epoch 290/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0780 - mean_absolute_error: 0.0780 - val_loss: 0.1604 - val_mean_absolute_error: 0.1604\n",
            "Epoch 291/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0809 - mean_absolute_error: 0.0809 - val_loss: 0.1688 - val_mean_absolute_error: 0.1688\n",
            "Epoch 292/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0867 - mean_absolute_error: 0.0867 - val_loss: 0.1750 - val_mean_absolute_error: 0.1750\n",
            "Epoch 293/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1012 - mean_absolute_error: 0.1012 - val_loss: 0.1920 - val_mean_absolute_error: 0.1920\n",
            "Epoch 294/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0976 - mean_absolute_error: 0.0976 - val_loss: 0.1802 - val_mean_absolute_error: 0.1802\n",
            "Epoch 295/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0743 - mean_absolute_error: 0.0743 - val_loss: 0.1758 - val_mean_absolute_error: 0.1758\n",
            "Epoch 296/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0764 - mean_absolute_error: 0.0764 - val_loss: 0.1927 - val_mean_absolute_error: 0.1927\n",
            "Epoch 297/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0934 - mean_absolute_error: 0.0934 - val_loss: 0.1923 - val_mean_absolute_error: 0.1923\n",
            "Epoch 298/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1008 - mean_absolute_error: 0.1008 - val_loss: 0.1743 - val_mean_absolute_error: 0.1743\n",
            "Epoch 299/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0956 - mean_absolute_error: 0.0956 - val_loss: 0.1576 - val_mean_absolute_error: 0.1576\n",
            "Epoch 300/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0814 - mean_absolute_error: 0.0814 - val_loss: 0.1917 - val_mean_absolute_error: 0.1917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[-5.6445756]], shape=(1, 1), dtype=float32)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 46)                276       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 34)                1598      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 28)                980       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 33)                957       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 33)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 34        \n",
            "=================================================================\n",
            "Total params: 3,845\n",
            "Trainable params: 3,845\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'drop_rate': 0.1,\n",
              " 'num_layers': 4,\n",
              " 'optimizer': 'adam',\n",
              " 'units_0': 46,\n",
              " 'units_1': 34,\n",
              " 'units_2': 28,\n",
              " 'units_3': 33}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uaPNNwPNy0tY",
        "outputId": "2094dc13-7052-4f9b-f866-92fbdaba6eff"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# upload the data base at the certain path\n",
        "data = pd.read_csv('/content/traincmp.csv')\n",
        "\n",
        "\n",
        "x = data.loc[0:119, ['A','B','C','D','E']]\n",
        "x =np.array(x)\n",
        "x_mean = np.mean(x,axis=0)\n",
        "x_std = np.std(x,axis=0)\n",
        "x = (x-x_mean)/x_std\n",
        "x_test = x[110:119,:]\n",
        "x = x [0:110,:]\n",
        "\n",
        "\n",
        "y = data.loc[0:119, ['target']]\n",
        "y=np.array(y)\n",
        "y_target= y[110:119,:]\n",
        "y_mean = np.mean(y,axis=0)\n",
        "y_std = np.std(y,axis=0)\n",
        "y = (y-y_mean)/y_std\n",
        "y = y [0:110,:]\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(3)\n",
        "np.random.shuffle(x)\n",
        "np.random.seed(3)\n",
        "np.random.shuffle(y)\n",
        "\n",
        "x_train = x[0:100,:]\n",
        "x_val = x[100:110,:]\n",
        "y_train = y[0:100,:]\n",
        "y_val = y[100:110,:]\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(5,1)),\n",
        "        tf.keras.layers.Dense(46, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(34, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(28, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(33, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "#SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
        "#RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)\n",
        "#Adagrad(lr=0.01, epsilon=1e-06)\n",
        "#Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
        "          loss='mae',\n",
        "          metrics=['mae'])\n",
        "\n",
        "history=model.fit(x_train, y_train, batch_size=16, epochs=300, validation_data=(x_val,y_val), validation_freq=1, shuffle=False)\n",
        "#history=model.fit(x_train, y_train, batch_size=16, epochs=200, validation_split=0.2, validation_freq=1,shuffle=False)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "epochs = len(history.history['loss'])\n",
        "plt.plot(np.arange(len(history.history['loss'])),history.history['loss'],label='training')\n",
        "plt.plot(np.arange(len(history.history['val_loss'])),history.history['val_loss'],label='validation')\n",
        "plt.legend(fontsize=10)\n",
        "plt.title('learning curve',fontsize=15)\n",
        "plt.xlabel('iteration',fontsize=15)\n",
        "plt.ylabel('error',fontsize=15)\n",
        "plt.show()\n",
        "y_test=model(x_test)\n",
        "y_mid= tf.multiply(y_test,y_std)\n",
        "y_test= tf.add(y_mid, y_mean)\n",
        "error= tf.abs(tf.subtract(y_test, y_target))\n",
        "error_percentage = tf.divide(error, y_target)\n",
        "print(error)\n",
        "print(error_percentage)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "7/7 [==============================] - 1s 26ms/step - loss: 0.7842 - mae: 0.7842 - val_loss: 0.9316 - val_mae: 0.9316\n",
            "Epoch 2/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6944 - mae: 0.6944 - val_loss: 0.8698 - val_mae: 0.8698\n",
            "Epoch 3/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6084 - mae: 0.6084 - val_loss: 0.7960 - val_mae: 0.7960\n",
            "Epoch 4/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5485 - mae: 0.5485 - val_loss: 0.7657 - val_mae: 0.7657\n",
            "Epoch 5/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.5091 - mae: 0.5091 - val_loss: 0.7319 - val_mae: 0.7319\n",
            "Epoch 6/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4615 - mae: 0.4615 - val_loss: 0.6972 - val_mae: 0.6972\n",
            "Epoch 7/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4252 - mae: 0.4252 - val_loss: 0.6753 - val_mae: 0.6753\n",
            "Epoch 8/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4134 - mae: 0.4134 - val_loss: 0.6476 - val_mae: 0.6476\n",
            "Epoch 9/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3632 - mae: 0.3632 - val_loss: 0.6219 - val_mae: 0.6219\n",
            "Epoch 10/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3522 - mae: 0.3522 - val_loss: 0.5828 - val_mae: 0.5828\n",
            "Epoch 11/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3134 - mae: 0.3134 - val_loss: 0.5779 - val_mae: 0.5779\n",
            "Epoch 12/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.3169 - mae: 0.3169 - val_loss: 0.5424 - val_mae: 0.5424\n",
            "Epoch 13/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2739 - mae: 0.2739 - val_loss: 0.5102 - val_mae: 0.5102\n",
            "Epoch 14/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2802 - mae: 0.2802 - val_loss: 0.4848 - val_mae: 0.4848\n",
            "Epoch 15/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2432 - mae: 0.2432 - val_loss: 0.4838 - val_mae: 0.4838\n",
            "Epoch 16/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.4360 - val_mae: 0.4360\n",
            "Epoch 17/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2557 - mae: 0.2557 - val_loss: 0.4585 - val_mae: 0.4585\n",
            "Epoch 18/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2379 - mae: 0.2379 - val_loss: 0.3686 - val_mae: 0.3686\n",
            "Epoch 19/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2217 - mae: 0.2217 - val_loss: 0.3878 - val_mae: 0.3878\n",
            "Epoch 20/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2050 - mae: 0.2050 - val_loss: 0.3951 - val_mae: 0.3951\n",
            "Epoch 21/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1967 - mae: 0.1967 - val_loss: 0.3775 - val_mae: 0.3775\n",
            "Epoch 22/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1997 - mae: 0.1997 - val_loss: 0.4031 - val_mae: 0.4031\n",
            "Epoch 23/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2055 - mae: 0.2055 - val_loss: 0.3267 - val_mae: 0.3267\n",
            "Epoch 24/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2147 - mae: 0.2147 - val_loss: 0.2899 - val_mae: 0.2899\n",
            "Epoch 25/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2151 - mae: 0.2151 - val_loss: 0.3770 - val_mae: 0.3770\n",
            "Epoch 26/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1580 - mae: 0.1580 - val_loss: 0.3403 - val_mae: 0.3403\n",
            "Epoch 27/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1585 - mae: 0.1585 - val_loss: 0.3134 - val_mae: 0.3134\n",
            "Epoch 28/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1632 - mae: 0.1632 - val_loss: 0.2641 - val_mae: 0.2641\n",
            "Epoch 29/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1640 - mae: 0.1640 - val_loss: 0.3091 - val_mae: 0.3091\n",
            "Epoch 30/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1745 - mae: 0.1745 - val_loss: 0.3145 - val_mae: 0.3145\n",
            "Epoch 31/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1654 - mae: 0.1654 - val_loss: 0.2901 - val_mae: 0.2901\n",
            "Epoch 32/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1574 - mae: 0.1574 - val_loss: 0.3076 - val_mae: 0.3076\n",
            "Epoch 33/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1452 - mae: 0.1452 - val_loss: 0.2439 - val_mae: 0.2439\n",
            "Epoch 34/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1750 - mae: 0.1750 - val_loss: 0.2350 - val_mae: 0.2350\n",
            "Epoch 35/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1413 - mae: 0.1413 - val_loss: 0.2977 - val_mae: 0.2977\n",
            "Epoch 36/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1410 - mae: 0.1410 - val_loss: 0.2535 - val_mae: 0.2535\n",
            "Epoch 37/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1389 - mae: 0.1389 - val_loss: 0.2440 - val_mae: 0.2440\n",
            "Epoch 38/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1246 - mae: 0.1246 - val_loss: 0.2672 - val_mae: 0.2672\n",
            "Epoch 39/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1426 - mae: 0.1426 - val_loss: 0.2192 - val_mae: 0.2192\n",
            "Epoch 40/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1667 - mae: 0.1667 - val_loss: 0.2295 - val_mae: 0.2295\n",
            "Epoch 41/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1295 - mae: 0.1295 - val_loss: 0.2566 - val_mae: 0.2566\n",
            "Epoch 42/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1363 - mae: 0.1363 - val_loss: 0.2370 - val_mae: 0.2370\n",
            "Epoch 43/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1356 - mae: 0.1356 - val_loss: 0.1902 - val_mae: 0.1902\n",
            "Epoch 44/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1460 - mae: 0.1460 - val_loss: 0.1921 - val_mae: 0.1921\n",
            "Epoch 45/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1445 - mae: 0.1445 - val_loss: 0.2443 - val_mae: 0.2443\n",
            "Epoch 46/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1347 - mae: 0.1347 - val_loss: 0.1920 - val_mae: 0.1920\n",
            "Epoch 47/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1449 - mae: 0.1449 - val_loss: 0.2207 - val_mae: 0.2207\n",
            "Epoch 48/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1357 - mae: 0.1357 - val_loss: 0.1639 - val_mae: 0.1639\n",
            "Epoch 49/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1596 - mae: 0.1596 - val_loss: 0.2021 - val_mae: 0.2021\n",
            "Epoch 50/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1323 - mae: 0.1323 - val_loss: 0.1839 - val_mae: 0.1839\n",
            "Epoch 51/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1332 - mae: 0.1332 - val_loss: 0.1518 - val_mae: 0.1518\n",
            "Epoch 52/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1133 - mae: 0.1133 - val_loss: 0.2499 - val_mae: 0.2499\n",
            "Epoch 53/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1505 - mae: 0.1505 - val_loss: 0.1797 - val_mae: 0.1797\n",
            "Epoch 54/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1598 - mae: 0.1598 - val_loss: 0.1781 - val_mae: 0.1781\n",
            "Epoch 55/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1311 - mae: 0.1311 - val_loss: 0.2469 - val_mae: 0.2469\n",
            "Epoch 56/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1244 - mae: 0.1244 - val_loss: 0.1581 - val_mae: 0.1581\n",
            "Epoch 57/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1239 - mae: 0.1239 - val_loss: 0.2313 - val_mae: 0.2313\n",
            "Epoch 58/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1472 - mae: 0.1472 - val_loss: 0.1877 - val_mae: 0.1877\n",
            "Epoch 59/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1178 - mae: 0.1178 - val_loss: 0.1625 - val_mae: 0.1625\n",
            "Epoch 60/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1483 - mae: 0.1483 - val_loss: 0.1551 - val_mae: 0.1551\n",
            "Epoch 61/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1211 - mae: 0.1211 - val_loss: 0.2133 - val_mae: 0.2133\n",
            "Epoch 62/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1206 - mae: 0.1206 - val_loss: 0.2075 - val_mae: 0.2075\n",
            "Epoch 63/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1369 - mae: 0.1369 - val_loss: 0.1928 - val_mae: 0.1928\n",
            "Epoch 64/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1228 - mae: 0.1228 - val_loss: 0.1955 - val_mae: 0.1955\n",
            "Epoch 65/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1228 - mae: 0.1228 - val_loss: 0.1657 - val_mae: 0.1657\n",
            "Epoch 66/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.1624 - val_mae: 0.1624\n",
            "Epoch 67/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1385 - mae: 0.1385 - val_loss: 0.1789 - val_mae: 0.1789\n",
            "Epoch 68/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1283 - mae: 0.1283 - val_loss: 0.1834 - val_mae: 0.1834\n",
            "Epoch 69/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1149 - mae: 0.1149 - val_loss: 0.1825 - val_mae: 0.1825\n",
            "Epoch 70/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1176 - mae: 0.1176 - val_loss: 0.1766 - val_mae: 0.1766\n",
            "Epoch 71/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1340 - mae: 0.1340 - val_loss: 0.1656 - val_mae: 0.1656\n",
            "Epoch 72/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1187 - mae: 0.1187 - val_loss: 0.1717 - val_mae: 0.1717\n",
            "Epoch 73/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1191 - mae: 0.1191 - val_loss: 0.1774 - val_mae: 0.1774\n",
            "Epoch 74/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1171 - mae: 0.1171 - val_loss: 0.1616 - val_mae: 0.1616\n",
            "Epoch 75/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1051 - mae: 0.1051 - val_loss: 0.1820 - val_mae: 0.1820\n",
            "Epoch 76/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0991 - mae: 0.0991 - val_loss: 0.1501 - val_mae: 0.1501\n",
            "Epoch 77/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1236 - mae: 0.1236 - val_loss: 0.2124 - val_mae: 0.2124\n",
            "Epoch 78/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1008 - mae: 0.1008 - val_loss: 0.1893 - val_mae: 0.1893\n",
            "Epoch 79/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1158 - mae: 0.1158 - val_loss: 0.1710 - val_mae: 0.1710\n",
            "Epoch 80/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1026 - mae: 0.1026 - val_loss: 0.2415 - val_mae: 0.2415\n",
            "Epoch 81/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1154 - mae: 0.1154 - val_loss: 0.1712 - val_mae: 0.1712\n",
            "Epoch 82/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1157 - mae: 0.1157 - val_loss: 0.2088 - val_mae: 0.2088\n",
            "Epoch 83/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1059 - mae: 0.1059 - val_loss: 0.1569 - val_mae: 0.1569\n",
            "Epoch 84/300\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1124 - mae: 0.1124 - val_loss: 0.1768 - val_mae: 0.1768\n",
            "Epoch 85/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1074 - mae: 0.1074 - val_loss: 0.1597 - val_mae: 0.1597\n",
            "Epoch 86/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1232 - mae: 0.1232 - val_loss: 0.1682 - val_mae: 0.1682\n",
            "Epoch 87/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1027 - mae: 0.1027 - val_loss: 0.1476 - val_mae: 0.1476\n",
            "Epoch 88/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1361 - mae: 0.1361 - val_loss: 0.1651 - val_mae: 0.1651\n",
            "Epoch 89/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1081 - mae: 0.1081 - val_loss: 0.1699 - val_mae: 0.1699\n",
            "Epoch 90/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1225 - mae: 0.1225 - val_loss: 0.1580 - val_mae: 0.1580\n",
            "Epoch 91/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1051 - mae: 0.1051 - val_loss: 0.2215 - val_mae: 0.2215\n",
            "Epoch 92/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1255 - mae: 0.1255 - val_loss: 0.1687 - val_mae: 0.1687\n",
            "Epoch 93/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1212 - mae: 0.1212 - val_loss: 0.1575 - val_mae: 0.1575\n",
            "Epoch 94/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1111 - mae: 0.1111 - val_loss: 0.1867 - val_mae: 0.1867\n",
            "Epoch 95/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1015 - mae: 0.1015 - val_loss: 0.1530 - val_mae: 0.1530\n",
            "Epoch 96/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0945 - mae: 0.0945 - val_loss: 0.1459 - val_mae: 0.1459\n",
            "Epoch 97/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0770 - mae: 0.0770 - val_loss: 0.1491 - val_mae: 0.1491\n",
            "Epoch 98/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0867 - mae: 0.0867 - val_loss: 0.1526 - val_mae: 0.1526\n",
            "Epoch 99/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0981 - mae: 0.0981 - val_loss: 0.1796 - val_mae: 0.1796\n",
            "Epoch 100/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0966 - mae: 0.0966 - val_loss: 0.1828 - val_mae: 0.1828\n",
            "Epoch 101/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1030 - mae: 0.1030 - val_loss: 0.1967 - val_mae: 0.1967\n",
            "Epoch 102/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0933 - mae: 0.0933 - val_loss: 0.1624 - val_mae: 0.1624\n",
            "Epoch 103/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0937 - mae: 0.0937 - val_loss: 0.1642 - val_mae: 0.1642\n",
            "Epoch 104/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0977 - mae: 0.0977 - val_loss: 0.1471 - val_mae: 0.1471\n",
            "Epoch 105/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1207 - mae: 0.1207 - val_loss: 0.1566 - val_mae: 0.1566\n",
            "Epoch 106/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1114 - mae: 0.1114 - val_loss: 0.1845 - val_mae: 0.1845\n",
            "Epoch 107/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0922 - mae: 0.0922 - val_loss: 0.1740 - val_mae: 0.1740\n",
            "Epoch 108/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1082 - mae: 0.1082 - val_loss: 0.1608 - val_mae: 0.1608\n",
            "Epoch 109/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0926 - mae: 0.0926 - val_loss: 0.1526 - val_mae: 0.1526\n",
            "Epoch 110/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1073 - mae: 0.1073 - val_loss: 0.1873 - val_mae: 0.1873\n",
            "Epoch 111/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0881 - mae: 0.0881 - val_loss: 0.1557 - val_mae: 0.1557\n",
            "Epoch 112/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1063 - mae: 0.1063 - val_loss: 0.1922 - val_mae: 0.1922\n",
            "Epoch 113/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1246 - mae: 0.1246 - val_loss: 0.1848 - val_mae: 0.1848\n",
            "Epoch 114/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0925 - mae: 0.0925 - val_loss: 0.1607 - val_mae: 0.1607\n",
            "Epoch 115/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1013 - mae: 0.1013 - val_loss: 0.1684 - val_mae: 0.1684\n",
            "Epoch 116/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0842 - mae: 0.0842 - val_loss: 0.1447 - val_mae: 0.1447\n",
            "Epoch 117/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1212 - mae: 0.1212 - val_loss: 0.1476 - val_mae: 0.1476\n",
            "Epoch 118/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0976 - mae: 0.0976 - val_loss: 0.2048 - val_mae: 0.2048\n",
            "Epoch 119/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0942 - mae: 0.0942 - val_loss: 0.1517 - val_mae: 0.1517\n",
            "Epoch 120/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1079 - mae: 0.1079 - val_loss: 0.1764 - val_mae: 0.1764\n",
            "Epoch 121/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1039 - mae: 0.1039 - val_loss: 0.1624 - val_mae: 0.1624\n",
            "Epoch 122/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1101 - mae: 0.1101 - val_loss: 0.1436 - val_mae: 0.1436\n",
            "Epoch 123/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0892 - mae: 0.0892 - val_loss: 0.1610 - val_mae: 0.1610\n",
            "Epoch 124/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1061 - mae: 0.1061 - val_loss: 0.1512 - val_mae: 0.1512\n",
            "Epoch 125/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1009 - mae: 0.1009 - val_loss: 0.1519 - val_mae: 0.1519\n",
            "Epoch 126/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1193 - mae: 0.1193 - val_loss: 0.1612 - val_mae: 0.1612\n",
            "Epoch 127/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1071 - mae: 0.1071 - val_loss: 0.1846 - val_mae: 0.1846\n",
            "Epoch 128/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1181 - mae: 0.1181 - val_loss: 0.1486 - val_mae: 0.1486\n",
            "Epoch 129/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0920 - mae: 0.0920 - val_loss: 0.1440 - val_mae: 0.1440\n",
            "Epoch 130/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1157 - mae: 0.1157 - val_loss: 0.1673 - val_mae: 0.1673\n",
            "Epoch 131/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0938 - mae: 0.0938 - val_loss: 0.1558 - val_mae: 0.1558\n",
            "Epoch 132/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0945 - mae: 0.0945 - val_loss: 0.1551 - val_mae: 0.1551\n",
            "Epoch 133/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0790 - mae: 0.0790 - val_loss: 0.1717 - val_mae: 0.1717\n",
            "Epoch 134/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0997 - mae: 0.0997 - val_loss: 0.1665 - val_mae: 0.1665\n",
            "Epoch 135/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - mae: 0.0826 - val_loss: 0.1654 - val_mae: 0.1654\n",
            "Epoch 136/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0967 - mae: 0.0967 - val_loss: 0.1662 - val_mae: 0.1662\n",
            "Epoch 137/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - mae: 0.0824 - val_loss: 0.1689 - val_mae: 0.1689\n",
            "Epoch 138/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0877 - mae: 0.0877 - val_loss: 0.1684 - val_mae: 0.1684\n",
            "Epoch 139/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0969 - mae: 0.0969 - val_loss: 0.1667 - val_mae: 0.1667\n",
            "Epoch 140/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0826 - mae: 0.0826 - val_loss: 0.1484 - val_mae: 0.1484\n",
            "Epoch 141/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0751 - mae: 0.0751 - val_loss: 0.1503 - val_mae: 0.1503\n",
            "Epoch 142/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0788 - mae: 0.0788 - val_loss: 0.1736 - val_mae: 0.1736\n",
            "Epoch 143/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0926 - mae: 0.0926 - val_loss: 0.1854 - val_mae: 0.1854\n",
            "Epoch 144/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0849 - mae: 0.0849 - val_loss: 0.1779 - val_mae: 0.1779\n",
            "Epoch 145/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0802 - mae: 0.0802 - val_loss: 0.1541 - val_mae: 0.1541\n",
            "Epoch 146/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0889 - mae: 0.0889 - val_loss: 0.1679 - val_mae: 0.1679\n",
            "Epoch 147/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0989 - mae: 0.0989 - val_loss: 0.1611 - val_mae: 0.1611\n",
            "Epoch 148/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0810 - mae: 0.0810 - val_loss: 0.1497 - val_mae: 0.1497\n",
            "Epoch 149/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0895 - mae: 0.0895 - val_loss: 0.1579 - val_mae: 0.1579\n",
            "Epoch 150/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0832 - mae: 0.0832 - val_loss: 0.1683 - val_mae: 0.1683\n",
            "Epoch 151/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0881 - mae: 0.0881 - val_loss: 0.1678 - val_mae: 0.1678\n",
            "Epoch 152/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0906 - mae: 0.0906 - val_loss: 0.1662 - val_mae: 0.1662\n",
            "Epoch 153/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1127 - mae: 0.1127 - val_loss: 0.1739 - val_mae: 0.1739\n",
            "Epoch 154/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0929 - mae: 0.0929 - val_loss: 0.1730 - val_mae: 0.1730\n",
            "Epoch 155/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0988 - mae: 0.0988 - val_loss: 0.1642 - val_mae: 0.1642\n",
            "Epoch 156/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0803 - mae: 0.0803 - val_loss: 0.1884 - val_mae: 0.1884\n",
            "Epoch 157/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0896 - mae: 0.0896 - val_loss: 0.1512 - val_mae: 0.1512\n",
            "Epoch 158/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0864 - mae: 0.0864 - val_loss: 0.1580 - val_mae: 0.1580\n",
            "Epoch 159/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0805 - mae: 0.0805 - val_loss: 0.1647 - val_mae: 0.1647\n",
            "Epoch 160/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0916 - mae: 0.0916 - val_loss: 0.1685 - val_mae: 0.1685\n",
            "Epoch 161/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0912 - mae: 0.0912 - val_loss: 0.1572 - val_mae: 0.1572\n",
            "Epoch 162/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0897 - mae: 0.0897 - val_loss: 0.1529 - val_mae: 0.1529\n",
            "Epoch 163/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0960 - mae: 0.0960 - val_loss: 0.1543 - val_mae: 0.1543\n",
            "Epoch 164/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0814 - mae: 0.0814 - val_loss: 0.1619 - val_mae: 0.1619\n",
            "Epoch 165/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0742 - mae: 0.0742 - val_loss: 0.1769 - val_mae: 0.1769\n",
            "Epoch 166/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0975 - mae: 0.0975 - val_loss: 0.1478 - val_mae: 0.1478\n",
            "Epoch 167/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0758 - mae: 0.0758 - val_loss: 0.1642 - val_mae: 0.1642\n",
            "Epoch 168/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.1550 - val_mae: 0.1550\n",
            "Epoch 169/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0872 - mae: 0.0872 - val_loss: 0.1688 - val_mae: 0.1688\n",
            "Epoch 170/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0927 - mae: 0.0927 - val_loss: 0.1747 - val_mae: 0.1747\n",
            "Epoch 171/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0739 - mae: 0.0739 - val_loss: 0.1595 - val_mae: 0.1595\n",
            "Epoch 172/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0805 - mae: 0.0805 - val_loss: 0.1714 - val_mae: 0.1714\n",
            "Epoch 173/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1020 - mae: 0.1020 - val_loss: 0.1558 - val_mae: 0.1558\n",
            "Epoch 174/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0885 - mae: 0.0885 - val_loss: 0.1468 - val_mae: 0.1468\n",
            "Epoch 175/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0911 - mae: 0.0911 - val_loss: 0.1996 - val_mae: 0.1996\n",
            "Epoch 176/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0967 - mae: 0.0967 - val_loss: 0.1444 - val_mae: 0.1444\n",
            "Epoch 177/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0711 - mae: 0.0711 - val_loss: 0.1865 - val_mae: 0.1865\n",
            "Epoch 178/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0865 - mae: 0.0865 - val_loss: 0.1509 - val_mae: 0.1509\n",
            "Epoch 179/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0888 - mae: 0.0888 - val_loss: 0.1560 - val_mae: 0.1560\n",
            "Epoch 180/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0955 - mae: 0.0955 - val_loss: 0.1634 - val_mae: 0.1634\n",
            "Epoch 181/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0876 - mae: 0.0876 - val_loss: 0.1606 - val_mae: 0.1606\n",
            "Epoch 182/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0839 - mae: 0.0839 - val_loss: 0.1549 - val_mae: 0.1549\n",
            "Epoch 183/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0798 - mae: 0.0798 - val_loss: 0.1581 - val_mae: 0.1581\n",
            "Epoch 184/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0796 - mae: 0.0796 - val_loss: 0.1491 - val_mae: 0.1491\n",
            "Epoch 185/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0813 - mae: 0.0813 - val_loss: 0.1582 - val_mae: 0.1582\n",
            "Epoch 186/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0925 - mae: 0.0925 - val_loss: 0.1561 - val_mae: 0.1561\n",
            "Epoch 187/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0814 - mae: 0.0814 - val_loss: 0.1327 - val_mae: 0.1327\n",
            "Epoch 188/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0732 - mae: 0.0732 - val_loss: 0.1492 - val_mae: 0.1492\n",
            "Epoch 189/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0867 - mae: 0.0867 - val_loss: 0.1407 - val_mae: 0.1407\n",
            "Epoch 190/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0884 - mae: 0.0884 - val_loss: 0.1461 - val_mae: 0.1461\n",
            "Epoch 191/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0889 - mae: 0.0889 - val_loss: 0.1351 - val_mae: 0.1351\n",
            "Epoch 192/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0892 - mae: 0.0892 - val_loss: 0.1310 - val_mae: 0.1310\n",
            "Epoch 193/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0721 - mae: 0.0721 - val_loss: 0.1264 - val_mae: 0.1264\n",
            "Epoch 194/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0644 - mae: 0.0644 - val_loss: 0.1260 - val_mae: 0.1260\n",
            "Epoch 195/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0737 - mae: 0.0737 - val_loss: 0.1305 - val_mae: 0.1305\n",
            "Epoch 196/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0793 - mae: 0.0793 - val_loss: 0.1328 - val_mae: 0.1328\n",
            "Epoch 197/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0870 - mae: 0.0870 - val_loss: 0.1371 - val_mae: 0.1371\n",
            "Epoch 198/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0864 - mae: 0.0864 - val_loss: 0.1412 - val_mae: 0.1412\n",
            "Epoch 199/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0814 - mae: 0.0814 - val_loss: 0.1354 - val_mae: 0.1354\n",
            "Epoch 200/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0884 - mae: 0.0884 - val_loss: 0.1489 - val_mae: 0.1489\n",
            "Epoch 201/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1024 - mae: 0.1024 - val_loss: 0.1501 - val_mae: 0.1501\n",
            "Epoch 202/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.1529 - val_mae: 0.1529\n",
            "Epoch 203/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - mae: 0.0824 - val_loss: 0.1575 - val_mae: 0.1575\n",
            "Epoch 204/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0780 - mae: 0.0780 - val_loss: 0.1370 - val_mae: 0.1370\n",
            "Epoch 205/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0756 - mae: 0.0756 - val_loss: 0.1248 - val_mae: 0.1248\n",
            "Epoch 206/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0765 - mae: 0.0765 - val_loss: 0.1216 - val_mae: 0.1216\n",
            "Epoch 207/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0908 - mae: 0.0908 - val_loss: 0.1473 - val_mae: 0.1473\n",
            "Epoch 208/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0802 - mae: 0.0802 - val_loss: 0.1418 - val_mae: 0.1418\n",
            "Epoch 209/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0803 - mae: 0.0803 - val_loss: 0.1362 - val_mae: 0.1362\n",
            "Epoch 210/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0876 - mae: 0.0876 - val_loss: 0.1289 - val_mae: 0.1289\n",
            "Epoch 211/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0732 - mae: 0.0732 - val_loss: 0.1325 - val_mae: 0.1325\n",
            "Epoch 212/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.1410 - val_mae: 0.1410\n",
            "Epoch 213/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0753 - mae: 0.0753 - val_loss: 0.1592 - val_mae: 0.1592\n",
            "Epoch 214/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.1451 - val_mae: 0.1451\n",
            "Epoch 215/300\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0852 - mae: 0.0852 - val_loss: 0.1609 - val_mae: 0.1609\n",
            "Epoch 216/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0824 - mae: 0.0824 - val_loss: 0.1428 - val_mae: 0.1428\n",
            "Epoch 217/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1019 - mae: 0.1019 - val_loss: 0.1458 - val_mae: 0.1458\n",
            "Epoch 218/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0799 - mae: 0.0799 - val_loss: 0.1383 - val_mae: 0.1383\n",
            "Epoch 219/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0817 - mae: 0.0817 - val_loss: 0.1521 - val_mae: 0.1521\n",
            "Epoch 220/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0865 - mae: 0.0865 - val_loss: 0.1556 - val_mae: 0.1556\n",
            "Epoch 221/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0867 - mae: 0.0867 - val_loss: 0.1473 - val_mae: 0.1473\n",
            "Epoch 222/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0916 - mae: 0.0916 - val_loss: 0.1550 - val_mae: 0.1550\n",
            "Epoch 223/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0828 - mae: 0.0828 - val_loss: 0.1508 - val_mae: 0.1508\n",
            "Epoch 224/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0978 - mae: 0.0978 - val_loss: 0.1351 - val_mae: 0.1351\n",
            "Epoch 225/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0968 - mae: 0.0968 - val_loss: 0.1275 - val_mae: 0.1275\n",
            "Epoch 226/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0894 - mae: 0.0894 - val_loss: 0.1335 - val_mae: 0.1335\n",
            "Epoch 227/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0734 - mae: 0.0734 - val_loss: 0.1560 - val_mae: 0.1560\n",
            "Epoch 228/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0820 - mae: 0.0820 - val_loss: 0.1475 - val_mae: 0.1475\n",
            "Epoch 229/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1009 - mae: 0.1009 - val_loss: 0.1598 - val_mae: 0.1598\n",
            "Epoch 230/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0941 - mae: 0.0941 - val_loss: 0.1635 - val_mae: 0.1635\n",
            "Epoch 231/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0909 - mae: 0.0909 - val_loss: 0.1440 - val_mae: 0.1440\n",
            "Epoch 232/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0826 - mae: 0.0826 - val_loss: 0.1327 - val_mae: 0.1327\n",
            "Epoch 233/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1039 - mae: 0.1039 - val_loss: 0.1497 - val_mae: 0.1497\n",
            "Epoch 234/300\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.1344 - val_mae: 0.1344\n",
            "Epoch 235/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0732 - mae: 0.0732 - val_loss: 0.1281 - val_mae: 0.1281\n",
            "Epoch 236/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0816 - mae: 0.0816 - val_loss: 0.1322 - val_mae: 0.1322\n",
            "Epoch 237/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0814 - mae: 0.0814 - val_loss: 0.1355 - val_mae: 0.1355\n",
            "Epoch 238/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0761 - mae: 0.0761 - val_loss: 0.1176 - val_mae: 0.1176\n",
            "Epoch 239/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0860 - mae: 0.0860 - val_loss: 0.1261 - val_mae: 0.1261\n",
            "Epoch 240/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0790 - mae: 0.0790 - val_loss: 0.1548 - val_mae: 0.1548\n",
            "Epoch 241/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0838 - mae: 0.0838 - val_loss: 0.1493 - val_mae: 0.1493\n",
            "Epoch 242/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0857 - mae: 0.0857 - val_loss: 0.1267 - val_mae: 0.1267\n",
            "Epoch 243/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0864 - mae: 0.0864 - val_loss: 0.1515 - val_mae: 0.1515\n",
            "Epoch 244/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0798 - mae: 0.0798 - val_loss: 0.1426 - val_mae: 0.1426\n",
            "Epoch 245/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0848 - mae: 0.0848 - val_loss: 0.1532 - val_mae: 0.1532\n",
            "Epoch 246/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0883 - mae: 0.0883 - val_loss: 0.1494 - val_mae: 0.1494\n",
            "Epoch 247/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0820 - mae: 0.0820 - val_loss: 0.1446 - val_mae: 0.1446\n",
            "Epoch 248/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0700 - mae: 0.0700 - val_loss: 0.1523 - val_mae: 0.1523\n",
            "Epoch 249/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - mae: 0.0829 - val_loss: 0.1480 - val_mae: 0.1480\n",
            "Epoch 250/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0865 - mae: 0.0865 - val_loss: 0.1501 - val_mae: 0.1501\n",
            "Epoch 251/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0716 - mae: 0.0716 - val_loss: 0.1405 - val_mae: 0.1405\n",
            "Epoch 252/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0837 - mae: 0.0837 - val_loss: 0.1589 - val_mae: 0.1589\n",
            "Epoch 253/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0825 - mae: 0.0825 - val_loss: 0.1316 - val_mae: 0.1316\n",
            "Epoch 254/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0772 - mae: 0.0772 - val_loss: 0.1465 - val_mae: 0.1465\n",
            "Epoch 255/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0699 - mae: 0.0699 - val_loss: 0.1633 - val_mae: 0.1633\n",
            "Epoch 256/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0845 - mae: 0.0845 - val_loss: 0.1498 - val_mae: 0.1498\n",
            "Epoch 257/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0857 - mae: 0.0857 - val_loss: 0.1506 - val_mae: 0.1506\n",
            "Epoch 258/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0848 - mae: 0.0848 - val_loss: 0.1391 - val_mae: 0.1391\n",
            "Epoch 259/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0806 - mae: 0.0806 - val_loss: 0.1525 - val_mae: 0.1525\n",
            "Epoch 260/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0950 - mae: 0.0950 - val_loss: 0.1539 - val_mae: 0.1539\n",
            "Epoch 261/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0611 - mae: 0.0611 - val_loss: 0.1436 - val_mae: 0.1436\n",
            "Epoch 262/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0823 - mae: 0.0823 - val_loss: 0.1464 - val_mae: 0.1464\n",
            "Epoch 263/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0667 - mae: 0.0667 - val_loss: 0.1435 - val_mae: 0.1435\n",
            "Epoch 264/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0694 - mae: 0.0694 - val_loss: 0.1397 - val_mae: 0.1397\n",
            "Epoch 265/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0813 - mae: 0.0813 - val_loss: 0.1487 - val_mae: 0.1487\n",
            "Epoch 266/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0753 - mae: 0.0753 - val_loss: 0.1574 - val_mae: 0.1574\n",
            "Epoch 267/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0827 - mae: 0.0827 - val_loss: 0.1479 - val_mae: 0.1479\n",
            "Epoch 268/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - mae: 0.0826 - val_loss: 0.1563 - val_mae: 0.1563\n",
            "Epoch 269/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - mae: 0.0824 - val_loss: 0.1423 - val_mae: 0.1423\n",
            "Epoch 270/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0904 - mae: 0.0904 - val_loss: 0.1433 - val_mae: 0.1433\n",
            "Epoch 271/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0675 - mae: 0.0675 - val_loss: 0.1481 - val_mae: 0.1481\n",
            "Epoch 272/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0827 - mae: 0.0827 - val_loss: 0.1451 - val_mae: 0.1451\n",
            "Epoch 273/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0916 - mae: 0.0916 - val_loss: 0.1319 - val_mae: 0.1319\n",
            "Epoch 274/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0914 - mae: 0.0914 - val_loss: 0.1489 - val_mae: 0.1489\n",
            "Epoch 275/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0837 - mae: 0.0837 - val_loss: 0.1453 - val_mae: 0.1453\n",
            "Epoch 276/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0812 - mae: 0.0812 - val_loss: 0.1393 - val_mae: 0.1393\n",
            "Epoch 277/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0767 - mae: 0.0767 - val_loss: 0.1349 - val_mae: 0.1349\n",
            "Epoch 278/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0687 - mae: 0.0687 - val_loss: 0.1356 - val_mae: 0.1356\n",
            "Epoch 279/300\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0683 - mae: 0.0683 - val_loss: 0.1575 - val_mae: 0.1575\n",
            "Epoch 280/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0779 - mae: 0.0779 - val_loss: 0.1361 - val_mae: 0.1361\n",
            "Epoch 281/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0765 - mae: 0.0765 - val_loss: 0.1293 - val_mae: 0.1293\n",
            "Epoch 282/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0708 - mae: 0.0708 - val_loss: 0.1376 - val_mae: 0.1376\n",
            "Epoch 283/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0587 - mae: 0.0587 - val_loss: 0.1416 - val_mae: 0.1416\n",
            "Epoch 284/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0766 - mae: 0.0766 - val_loss: 0.1717 - val_mae: 0.1717\n",
            "Epoch 285/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0973 - mae: 0.0973 - val_loss: 0.1341 - val_mae: 0.1341\n",
            "Epoch 286/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0810 - mae: 0.0810 - val_loss: 0.1582 - val_mae: 0.1582\n",
            "Epoch 287/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0880 - mae: 0.0880 - val_loss: 0.1554 - val_mae: 0.1554\n",
            "Epoch 288/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0700 - mae: 0.0700 - val_loss: 0.1349 - val_mae: 0.1349\n",
            "Epoch 289/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0707 - mae: 0.0707 - val_loss: 0.1393 - val_mae: 0.1393\n",
            "Epoch 290/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0633 - mae: 0.0633 - val_loss: 0.1308 - val_mae: 0.1308\n",
            "Epoch 291/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0703 - mae: 0.0703 - val_loss: 0.1360 - val_mae: 0.1360\n",
            "Epoch 292/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0816 - mae: 0.0816 - val_loss: 0.1342 - val_mae: 0.1342\n",
            "Epoch 293/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0903 - mae: 0.0903 - val_loss: 0.1123 - val_mae: 0.1123\n",
            "Epoch 294/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0798 - mae: 0.0798 - val_loss: 0.1480 - val_mae: 0.1480\n",
            "Epoch 295/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0865 - mae: 0.0865 - val_loss: 0.1424 - val_mae: 0.1424\n",
            "Epoch 296/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0736 - mae: 0.0736 - val_loss: 0.1227 - val_mae: 0.1227\n",
            "Epoch 297/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0845 - mae: 0.0845 - val_loss: 0.1283 - val_mae: 0.1283\n",
            "Epoch 298/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0822 - mae: 0.0822 - val_loss: 0.1348 - val_mae: 0.1348\n",
            "Epoch 299/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0739 - mae: 0.0739 - val_loss: 0.1325 - val_mae: 0.1325\n",
            "Epoch 300/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.1476 - val_mae: 0.1476\n",
            "Model: \"sequential_77\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_77 (Flatten)         (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense_385 (Dense)            (None, 46)                276       \n",
            "_________________________________________________________________\n",
            "dense_386 (Dense)            (None, 34)                1598      \n",
            "_________________________________________________________________\n",
            "dense_387 (Dense)            (None, 28)                980       \n",
            "_________________________________________________________________\n",
            "dense_388 (Dense)            (None, 33)                957       \n",
            "_________________________________________________________________\n",
            "dropout_77 (Dropout)         (None, 33)                0         \n",
            "_________________________________________________________________\n",
            "dense_389 (Dense)            (None, 1)                 34        \n",
            "=================================================================\n",
            "Total params: 3,845\n",
            "Trainable params: 3,845\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[2.8446436 ]\n",
            " [0.77855563]\n",
            " [0.7050824 ]\n",
            " [0.58367705]\n",
            " [0.07188159]\n",
            " [0.4337213 ]\n",
            " [0.34739375]\n",
            " [0.13659263]\n",
            " [0.11441684]], shape=(9, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.17363387]\n",
            " [0.21042044]\n",
            " [0.145859  ]\n",
            " [0.12785916]\n",
            " [0.11196509]\n",
            " [0.16016297]\n",
            " [0.2086449 ]\n",
            " [0.04559166]\n",
            " [0.03972807]], shape=(9, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RwNZX0kAJdj",
        "outputId": "8349a4a1-c715-4040-96d6-6219c205bfdf"
      },
      "source": [
        "!pip3 install pygad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygad\n",
            "  Downloading pygad-2.16.0-py3-none-any.whl (52 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▏                         | 10 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30 kB 17.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pygad) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pygad) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->pygad) (1.15.0)\n",
            "Installing collected packages: pygad\n",
            "Successfully installed pygad-2.16.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5qMgWsiDAKJ6",
        "outputId": "c8547f60-5ca8-4265-8a48-a79a1f729f28"
      },
      "source": [
        "# Optimization for input features\n",
        "\n",
        "import numpy as np\n",
        "import pygad\n",
        "\n",
        "#initialization\n",
        "function_inputs = [0.5,0.5,0.5,0.5,0.5]\n",
        "\n",
        "#define fitness function\n",
        "def fitness_func(solution, solution_idx):\n",
        "    target = [1.5]\n",
        "    target = abs(y-y_mean)/y_std\n",
        "    output=model(np.array(solution*function_inputs).reshape(1,5)) # model is built in keras.tuner\n",
        "    output = abs(tf.subtract(abs(output), abs(target)))\n",
        "    fitness =((1/output)).numpy()[0]\n",
        "    #fitness =output.numpy()[0]\n",
        "    return fitness\n",
        "\n",
        "# Number of generations.\n",
        "num_generations = 100\n",
        "# Number of solutions to be selected as parents in the mating pool.\n",
        "num_parents_mating = 5 \n",
        "# Number of solutions in the population.\n",
        "sol_per_pop = 10 \n",
        "  \n",
        "# Type of parent selection.\n",
        "parent_selection_type = \"sss\"\n",
        "# Type of the crossover operator.\n",
        "crossover_type = \"single_point\" \n",
        "# Type of the mutation operator.\n",
        "mutation_type = \"random\"\n",
        "\n",
        "last_fitness = 0\n",
        "def callback_generation(ga_instance):\n",
        "    global last_fitness\n",
        "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
        "    print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
        "    print(\"Change     = {change}\".format(change=ga_instance.best_solution()[1] - last_fitness))\n",
        "    last_fitness = ga_instance.best_solution()[1]\n",
        "\n",
        "# Creating an instance of the GA class inside the ga module. Some parameters are initialized within the constructor.\n",
        "ga_instance = pygad.GA(\n",
        "     #Number of generations(iterations).\n",
        "     num_generations=num_generations,\n",
        "     num_parents_mating=num_parents_mating,\n",
        "     fitness_func=fitness_func,\n",
        "     sol_per_pop=sol_per_pop,\n",
        "     #the Number of parameters(the number of genes)\n",
        "     num_genes=5,\n",
        "     gene_space=[np.arange(-1.68,2.88,0.01).tolist(),np.arange(-1.34,1.73,0.01).tolist(),np.arange(-0.88,1.56,0.01).tolist(),np.arange(-0.99,1.32,0.01).tolist(),\n",
        "                 np.arange(-1.26,-0.392,0.01).tolist()],\n",
        "     \n",
        "     parent_selection_type=parent_selection_type,\n",
        "     keep_parents=1,\n",
        "     crossover_type=crossover_type,\n",
        "     mutation_percent_genes=50,\n",
        "     mutation_type=mutation_type,\n",
        "     callback_generation=callback_generation)\n",
        "\n",
        "# Running the GA to optimize the parameters of the function.\n",
        "ga_instance.run()\n",
        "\n",
        "\n",
        "# After the generations complete, some plots are showed that summarize the how the outputs/fitenss values evolve over generations.\n",
        "ga_instance.plot_result()\n",
        "\n",
        "# Returning the details of the best solution.\n",
        "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
        "solution = tf.multiply(solution,x_std)\n",
        "solution = tf.add(solution, x_mean)\n",
        "print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
        "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=1/solution_fitness))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pygad/pygad.py:731: UserWarning: Starting from PyGAD 2.6.0, the callback_generation parameter is deprecated and will be removed in a later release of PyGAD. Please use the on_generation parameter instead.\n",
            "  if not self.suppress_warnings: warnings.warn(\"Starting from PyGAD 2.6.0, the callback_generation parameter is deprecated and will be removed in a later release of PyGAD. Please use the on_generation parameter instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation = 1\n",
            "Fitness    = [3.5453439]\n",
            "Change     = [3.5453439]\n",
            "Generation = 2\n",
            "Fitness    = [3.5453439]\n",
            "Change     = [0.]\n",
            "Generation = 3\n",
            "Fitness    = [3.8000395]\n",
            "Change     = [0.25469565]\n",
            "Generation = 4\n",
            "Fitness    = [3.8000395]\n",
            "Change     = [0.]\n",
            "Generation = 5\n",
            "Fitness    = [3.8000395]\n",
            "Change     = [0.]\n",
            "Generation = 6\n",
            "Fitness    = [3.8000395]\n",
            "Change     = [0.]\n",
            "Generation = 7\n",
            "Fitness    = [3.8000395]\n",
            "Change     = [0.]\n",
            "Generation = 8\n",
            "Fitness    = [4.6114526]\n",
            "Change     = [0.81141305]\n",
            "Generation = 9\n",
            "Fitness    = [4.6114526]\n",
            "Change     = [0.]\n",
            "Generation = 10\n",
            "Fitness    = [4.6114526]\n",
            "Change     = [0.]\n",
            "Generation = 11\n",
            "Fitness    = [4.6114526]\n",
            "Change     = [0.]\n",
            "Generation = 12\n",
            "Fitness    = [4.6114526]\n",
            "Change     = [0.]\n",
            "Generation = 13\n",
            "Fitness    = [4.6114526]\n",
            "Change     = [0.]\n",
            "Generation = 14\n",
            "Fitness    = [4.6114526]\n",
            "Change     = [0.]\n",
            "Generation = 15\n",
            "Fitness    = [4.6114526]\n",
            "Change     = [0.]\n",
            "Generation = 16\n",
            "Fitness    = [4.6114526]\n",
            "Change     = [0.]\n",
            "Generation = 17\n",
            "Fitness    = [4.6114526]\n",
            "Change     = [0.]\n",
            "Generation = 18\n",
            "Fitness    = [4.6114526]\n",
            "Change     = [0.]\n",
            "Generation = 19\n",
            "Fitness    = [4.659613]\n",
            "Change     = [0.04816055]\n",
            "Generation = 20\n",
            "Fitness    = [4.659613]\n",
            "Change     = [0.]\n",
            "Generation = 21\n",
            "Fitness    = [4.659613]\n",
            "Change     = [0.]\n",
            "Generation = 22\n",
            "Fitness    = [4.659613]\n",
            "Change     = [0.]\n",
            "Generation = 23\n",
            "Fitness    = [4.659613]\n",
            "Change     = [0.]\n",
            "Generation = 24\n",
            "Fitness    = [4.659613]\n",
            "Change     = [0.]\n",
            "Generation = 25\n",
            "Fitness    = [4.659613]\n",
            "Change     = [0.]\n",
            "Generation = 26\n",
            "Fitness    = [4.659613]\n",
            "Change     = [0.]\n",
            "Generation = 27\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.06536341]\n",
            "Generation = 28\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 29\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 30\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 31\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 32\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 33\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 34\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 35\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 36\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 37\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 38\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 39\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 40\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 41\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 42\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 43\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 44\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 45\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 46\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 47\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 48\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 49\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 50\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 51\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 52\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 53\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 54\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 55\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 56\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 57\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 58\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 59\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 60\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 61\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 62\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 63\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 64\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 65\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 66\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 67\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 68\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 69\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 70\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 71\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 72\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 73\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 74\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 75\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 76\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 77\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 78\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 79\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 80\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 81\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 82\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 83\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 84\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 85\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 86\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 87\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 88\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 89\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 90\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 91\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 92\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 93\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 94\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 95\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 96\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 97\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 98\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 99\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n",
            "Generation = 100\n",
            "Fitness    = [4.7249765]\n",
            "Change     = [0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pygad/pygad.py:3105: UserWarning: Please use the plot_fitness() method instead of plot_result(). The plot_result() method will be removed in the future.\n",
            "  warnings.warn(\"Please use the plot_fitness() method instead of plot_result(). The plot_result() method will be removed in the future.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters of the best solution : [11.0507051   8.02409459 79.27108874 68.23396995  4.64843663]\n",
            "Fitness value of the best solution = [0.21164127]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXk_hHOoAwu8"
      },
      "source": [
        "save_path = r'E:\\model\\group10.h5'\n",
        "model.save(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX18Qyo3AxW0",
        "outputId": "d8f93ccc-4e3a-4f87-9267-03b1153b1a2d"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[13.538356 ]\n",
            " [ 2.9214444]\n",
            " [ 4.1289177]\n",
            " [ 3.981323 ]\n",
            " [ 0.5701184]\n",
            " [ 2.2742786]\n",
            " [ 1.3176062]\n",
            " [ 2.8594074]\n",
            " [ 2.994417 ]], shape=(9, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}